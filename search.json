[{"title":"CMU15-445笔记10——query execution","url":"/2022/09/02/CMU15-445%E7%AC%94%E8%AE%B010%E2%80%94%E2%80%94query-execution/","content":"Processing Model明确了如何执行一个查询计划。查询是从上往下还是从下往上，在每个operator之间，我们实际该传多少东西。\nApproach #1: Iterator Model也称为Volcano model或者Pipeline model。\nApproach #2: Materialization ModelIterator model只返回一个tuple，但materialization model则返回全部。\n\n适合于OLTP workloads，因为这类查询一次只会返回很小数量的tuples，这样开销很小（因为数据被读取在内存中时要考虑同步问题）。\n不适合于OLAP workloads，因为这会导致中间结果返回过多的tuples。\n\nApproach #3: Vectorized &#x2F; Batch Model当每次调用next函数时，传递的是一批次tuple而不是单个tuple，这样更为高效（因此其是对于iterator model的增强），同时避免了传递的数据过多的问题。\nPlan Processing DirectionApproach #1: top-to-bottom从根节点递归地调用函数。\nApproach #2: bottom-to-top从叶节点推数据到根节点中。\nAccess Methods如何在数据库系统的表中查找数据。\nApproach #1: Sequential Scan从buffer pool中读取每一个数据，之后遍历每一个tuple判断其是否需要读取。DBMS维护一个内部的游标来追踪最后一个被检查的page与slot。\nOptimization of Sequential Scan\nPrefetching\n\nBuffer pool bypass\n\nParallelization\n\nZone maps：预先计算一个page的一些属性并存储起来，之后读取可以不需要读取整个page而先读取page的这些属性值进行判断是否需要读取。（总是在OLAP中使用，而不是在OLTP中使用，因为这样维护成本过高。）\n\nLate materialization：延迟将数据从一个operator传播到下一个operator（延迟读操作），之后根据情况去读取具体的数据。\n\nheap clustering：利用聚簇索引，之前有介绍过。\n\n\nApproach #2: Index Scan数据库管理系统选择合适的索引去查找tuples（可能有多个索引可用）。\nApproach #3: Multi-Index &#x2F; “Bitmap” Scan通过不同的索引进行多次查找，并合并结果。\nIndex Scan Page Sorting对于非聚簇索引中的tuple，可能在索引上连续排列的tuple在物理位置上十分分散，因此数据库管理系统可以首先取到所有的tuples的page id并对它们进行排序，之后再进行读取。\nExpression EvaluationDBMS将where子句表示为一个表达式树。\n利用JIT（即时编译）来处理类似1&#x3D;&#x3D;1这种查询语句，这种语句总是编译为true这样的常量。\n","categories":["数据库"],"tags":["CMU 15-445","存储"]},{"title":"CMU15-445笔记1——Introduction","url":"/2022/06/02/CMU15-445%E7%AC%94%E8%AE%B01%E2%80%94%E2%80%94Introduction/","content":"1. 为什么需要数据库如果使用csv file而不使用数据库\n1.1 数据一致性\n多个csv文件中相关联的多条数据之间不冲突\n对于csv文件中字段进行非法的字符修改\n我们如何能够存储多个内容到一个字段（比如书的作者可能有多个，我们要存储所有这些作者名字到书的作者这一栏，但这会难以解析）\n\n1.2 实现\n如何在cvs file中找到一条特定的记录\n使用csv file对于不同应用需要不同的程序来读取数据\n多线程读写问题\n\n1.3 持久性\n存储csv file的机器在读写文件时宕机\n复制该csv file在多台机器上保证高可用性\n\n2. DBMS分析了使用csv file来存储数据，可以看出我们迫切需要数据库和DBMS。DBMS(Database Management System)是允许应用程序在数据库中存储和分析信息的软件，而广义的DBMS被设计来定义、创建、查询、更新和管理数据库，这也是该课程的项目所要做的东西。\n2.1 Data modeldata model是指如何组织数据的高层次概念。\n\nSQL - Relational\nNoSQL\nKey&#x2F;Value\nGraph\nDocument\nColumn-family\n\n\nOther\nArray&#x2F;Matrix（在机器学习中使用）\nHierarchical（过时的）\nNetwork（过时的）\n\n\n\n2.2 SchemeScheme是关于存储数据时所使用的定义，其是指使用给定数据模型对特定数据集合的描述。\n2.3 Data Manipulation Languages\nProcedural：这种请求指定了高层次的策略告诉DBMS应当如何去找到想要的结果。（关系代数）（关系型数据库需要关注的）\n\nNon-Procedural：这个请求只告诉DBMS想要什么数据而不是如何去找到它们。（关系演算）\n\n\n2.4 查询以及查询优化数据模型应当独立于查询语句。\n3. 关系数据模型论文：《A Relational Model of Data for Large Shared Data Banks》\n3.1 关系数据模型三要素：\n将关系转化为简单的数据结构然后存入数据库\n使用高级语言来获取数据、应用数据\n大型数据库的物理存储策略取决于数据库管理系统的实现\n\n3.2 关系数据模型的三个组成部分：\nStructure：我们在我们的关系中该定义什么，它们的内容是什么，类型是什么。\nIntegrity：关于数据的约束。\nManipulation：操作数据库中内容的方式。\n\n3.3 关系的组成：\ntuple：一个tuple表示关系数据模型中的一条记录，其对应了一组属性值。\nprimary key：主键某一个能够唯一标识一条记录的属性。\nforeign key：外键用于指定一张表中的属性必须存在于另一张表中，它用来维护不同表之间的数据一致性。\n\n3.4 最初的关系代数运算符：\nSelect：选择满足条件的子集\nProjection：生成一个新的输出关系，它里面只包含一个来自我们给定输入关系中的指定属性\nUnion：将两个关系组合生成一个新的关系，这其中包含了这两个关系中的全部tuple\nIntersection：生成一个包含了在两个关系中都出现过的tuple的输出关系\nDifference：只取在一个关系中出现的元素，而不取另一个关系中的元素\nProduct：笛卡尔积，生成两个输入关系中所有tuple的可能组合\nJoin：自然连接，对于一个关系中的每一个tuple，观察它与另一个关系是否具有相同名称，相同类型的所有属性匹配，如果有，那么这就是这两个关系共同拥有的元素，那么就可以进行连接操作（将对应的tuple连接起来，去除掉一份相同的部分）。要注意的是，该操作符和difference很像但是有区别，difference取的两个tuple必须关系属性以及关系属性的内容完全相同但是Join可以有不相同的关系属性（相同的关系属性其内容必须相同）。\n\n3.5 额外的关系代数运算符：\nRename\nAssignment\nDuplicate Elimination\nAggregation\nSorting\nDivision\n\n","categories":["数据库"],"tags":["CMU 15-445","存储"]},{"title":"CMU15-445笔记2——Advanced SQL","url":"/2022/06/02/CMU15-445%E7%AC%94%E8%AE%B02%E2%80%94%E2%80%94Advanced-SQL/","content":"Relational Languages\nData Manipulation Language：数据操作语言，例如insert、update、delete和select这些命令来操作存在于数据库中的数据。\nData Definition Language：通过定义scheme来创建表存储数据。\nData Control Language：关于安全性授权的语言，它用来控制哪些人可以读取哪些数据。\n\nSQL是基于bags的，bags允许重复，且其中的元素没有次序和固定的位置。\nSQL是一种标准，但是各种数据库会在标准上加入新的特性，如果一个数据库说它符合SQL标准，那么认为符合的是SQL-92标准。\n1. Aggregations + Group By1.1 Aggregations聚合函数是处理一组元组并返回单个值的函数：\n\nAVG(col)：返回平均值\nMIN(col)：返回最小值\nMAX(col)：返回最大值\nSUM(col)：返回总和数值\nCOUNT(col)：返回数量\n\n1.2 Group ByGroup By语句使在做数据库操作时可以根据特定属性进行分组。下面的代码块表示根据课程号(cid)和学生姓名(name)分别算出该课程的所有学生平均成绩和该学生的所有课程平均成绩。\nSELECT AVG(S.gpa), e.cid, s.name FROM enrolled AS e, student AS s WHERE e.sid = s.sid GROUP BY e.cid, s.name;\n\nHAVING语句可以用来过滤聚合操作的结果（GROUP BY特有的WHERE语句）。\nSELECT AVG(S.gpa) AS avg_gpa, e.cid FROM enrolled AS e, student AS s WHERE e.sid = s.sid GROUP BY e.cidHAVING avg_gpa &gt; 3.5;\n\n2. Stirng &#x2F; Date、Time Operations2.1 String Operation\n\n\n\nString Case\nString Quotes\n\n\n\nSQL-92\nSensitive\nSingle Only\n\n\nPostgres\nSensitive\nSingle Only\n\n\nMySQL\nInsensitive\nSingle&#x2F;Double\n\n\nSQLite\nSensitive\nSingle&#x2F;Double\n\n\nDB2\nSensitive\nSingle Only\n\n\nOracle\nSensitive\nSingle Only\n\n\n\nLike被用来匹配字符串\n%被用来匹配子字符串（包括空字符串）\n_被用来匹配任意一个字符\n\n\nSUBSTRING(name,0,5)：根据下标取子字符串\nLOWER(name)：使其中的字符小写\nUPPER(name)：使其中的字符大写\n拼接字符操作（有三种，标准是||）\n||\n\n\n\n\nCONCAT(s1,s2)\n\n\n\n2.2 Date、Time Operation\n获取当前时间\n\nNOW()：函数（postgresql，mysql）\nCURRENT_TIMESTAMP()：函数（mysql）\nCURRENT_TIMESTAMP：关键字（postgresql，mysql，sqlite）\n\n\n获取日期中的天数\n# postgresqlSELECT EXTRACT(DAY FROM DATE(&#x27;2018-08-29&#x27;));\n\n获取距离某一天过了多久\n# mysqlSELECT DATEDIFF(DATE(&#x27;2022-06-02&#x27;),DATE(&#x27;2000-05-14&#x27;)) AS days;# sqliteSELECT julianday(CURRENT_TIMESTAMP) - julianday(&#x27;2000-05-14&#x27;);\n\n3. Output Redirection + Control3.1 Output Redirection可以将查询结果的内容存储到另一张表中\n# sql-92SELECT DISTINCT cid INTO CourseIds FROM enrolled;# MysqlCREATE TABLE CourseIds(SELECT DISTINCT cid FROM enrolled);# CourseIds之前已经创建好了，必须保证属性一致INSERT INTO CourseIds(SELECT DISTINCT cid FROM enrolled);\n\n3.2 Output Control\n排序\nORDER BY &lt;column&gt; [ASC | DESC]\n\n限制输出的数量\n# offset表示的是开始输出的tuple的偏移# 比如一共有10条记录，count为4，offset为1，则从第2条记录开始输出，一直输出到第5条记录LIMIT &lt;count&gt; [offset]\n\n4. Nested Queries嵌套查询，将一个查询的输出作为另一个查询的输入条件。\n\nALL：子查询的所有行必须都满足条件。\nANY：只要子查询的一行满足条件就可以。\nIN：与ANY()语义相同。\nEXISTS：至少返回一行数据。\n\n这里有很多examples，我没有做记录，感兴趣可以看这个视频的后半段学习。\n5. Window Functions&#x3D;&#x3D;之后再补&#x3D;&#x3D;\n6. Common Table Expressions&#x3D;&#x3D;之后再补&#x3D;&#x3D;\n","categories":["数据库"],"tags":["CMU 15-445","存储","SQL"]},{"title":"CMU15-445笔记3——Database Storage","url":"/2022/06/02/CMU15-445%E7%AC%94%E8%AE%B03%E2%80%94%E2%80%94Database-Storage/","content":"1. 数据库系统设计数据库系统设计目标：给应用程序一个错觉，即我们能提供足够的内存将整个数据库存入内存中。\n1.1 整体的设计架构：\n图1：简单数据库的整体架构\n\n在硬盘中有数据库文件，其由目录和页（也可以说是块）组成；在内存中有一个缓存池，用来缓存数据库文件中的页。当一个运行引擎（查询引擎、执行引擎等）需要得到page 2中的内容，它会向缓冲池发送请求，如果page 2不在缓存池（内存）中，其会在硬盘的page目录中查找page，并将其读取到缓存池中，最后将数据交给运行引擎，运行引擎会对读取到的数据进行相应的操作。\n1.2 Why Buffer Pool为什么不依赖操作系统去管理内存，而要额外写一个buffer pool去管理内存呢？用户程序可以使用mmap系统调用让操作系统将文件页面映射到进程的地址空间中，其可以读写该内存页中的内容，操作系统会控制该内存内容，将更改内容写回到硬盘文件中。通过这种方式，操作系统控制了硬盘文件数据在内存中的缓存。\n但这会导致一些性能瓶颈，因为操作系统只是从操作系统的层面去考虑控制文件数据在内存中的缓存（如果内存满了，需要换出换入页，那么极有可能换出从DBMS层面来看不该换出的页）。虽然DBMS可以使用madvise告诉操作系统如何访问某些页面（顺序读取还是随即读取），可以使用mlock阻止pages被回收，可以使用msync告诉操作系统要将数据刷出到磁盘中。但是这样仍然可能会遇到性能瓶颈。所以我们要尽可能避免使用操作系统来管理这部分内存，而将这部分工作交给DBMS。\n从发展现状来看，大多数主流的数据库比如MySQL、Oracle、DB2以及SQL server都没有使用mmap。当然也有一部分数据库使用了或者部分使用了mmap，前者有levelDB、elasticsearch，后者有SQLite、mongoDB。\n2. 数据库存储——Problem 1数据库存储主要关注两个问题，问题1是DBMS如何表示磁盘中文件的数据。\n2.1 File Storage数据库可能将数据存储在一个或多个文件中，其所依赖的文件系统有可能是基于操作系统自带的一些文件系统或者是自己构建的。\n2.1.1 Storage Manager(存储管理器，存储引擎)数据库系统的一个组件，负责维护在磁盘上的数据库文件。\n2.1.2 Database Pages\npage里面的内容可以是元组、元数据、索引或者日志，分开存储不同类型的数据是一个好的方法（大多数系统都是这样做的，称为self-contained page）。\n每一个page都有一个独一无二的id号，利用id号可以索引到该页的物理位置（使用一个indirection layer）。\n\n三种不同的page概念：\n\nHardware Page（usually 4KB）：存储在持久化设备上的数据块（执行原子性读写的最小单位）\nOS Page（usually 4KB）：被操作系统读取，存在内存中的数据页\nDatabase Page（512B - 16KB）：DBMS处理的page，如果Database Page的大小大于Hardware Page的大小不一样，在读写发生异常时可能会出现问题，比如16KB的Database Page刚写了8KB到持久化设备中，这时设备宕机了，那么剩下的8KB还没有写完，而当读取数据库数据时，实际上已经有一部分数据被修改了，这就需要一些操作来保证数据一致性。而使用更大的Database Page的好处是更大的页大小可以使索引表中（类似TLB）的page id数更少（在总数据量相同的情况下），这可以使读取page位置的操作更加快速。\n\n2.1.3 Page Storage Architecture不同的DBMS使用不同的方式管理数据库文件中的页。关注的是页的组织形式，而不是页中的内容。\n1）Heap File Organizationheap file是一个无序的page集合，可以以随机的顺序把tuple保存在里面。（关系模型没有任何排序，如果一个接一个地插入tuple，不能保证它们是按照插入的顺序保存在磁盘上的。）这种架构还需要元数据去跟踪记录被使用的page和空闲的page。\nheap file有两种实现方法：\n实现方式1: Linked List（bad idea）在heap file的header中，用两个指针来分别指向空余page列表和被数据占据的page列表。当我想要插入数据时，我可以循环扫描查看每一个page，知道找到有足够空余空间的page为止。\n实现方式2: Page Directory在heap file的header有一个目录维护了page id和它们所处位置的映射关系，同时这个目录维护着某些额外的元数据。\n2）Sequential&#x2F;Sorted File Organization没讲\n3）Hashing File Organization没讲\n2.2 Page Layoutpage layout是指如何组织储存在page中的数据。\n2.2.1 Page Header\nPage Size\nChecksum\nDBMS version\nTransaction Visibility\nCompression Information\n\n2.2.2 Tuple-oriented1）a strawman idea在一个已有的tuple后面再接着插入一个新的tuple，同时更新header中记录的page中tuple的数量。\n缺点：删除后很容易产生外部碎片，同时维护header中的数据过于频繁。\n2）Slotted Pages这是常用的scheme。使用该方法存储数据，在头部除了存储元数据还要存储slot array，在尾部存储我们想要保存的tuple。Slot array将一个特定的slot映射到page上的某个偏移量上，根据这个偏移量，DBMS可以得到想要获取的那个tuple。（也有可能会产生空隙，DBMS可以压缩page中的空间。）\n\n图2：one slotted page\n\n每一个tuple可以用一个record id来唯一标识，最常用的record id为page id + slot offset。\n2.2.3 Log-structured该方法并不是把所有的tuple都存放到page中，而是去存储如何创建tuple以及如何修改tuple的相关信息（也就是日志记录）。（这其实和LFS这个文件系统思路一致。）\n优点：\n\n考虑了存储介质上顺序读写与随机读写的区别（这种结构有利于顺序读写）\n有利于回滚\n\n缺点：当读取数据时需要读取一堆记录来得到数据。\n2.3 Tuple Layouttuple其实就是一个字节序列。\n2.3.1 Tuple Header每个tuple前面都有一个包含元数据的header，我们可以通过一个header来追踪一些不同的东西，例如哪一个事务查询修改了这个tuple，以及对于空值的bitmap。但是通常我们不会将数据类型元数据保存在每个tuple中，而是会保存在tuple所在的page中，或者是另外的catalog page中（假设同一个表的tuple会在同一个page中）。\n2.3.2 Tuple Data关于tuple data的存储顺序，通常是根据创建表的时候类型的顺序来存储的。（对于内存型数据库，可能需要重新排序以此来保证字节对齐）\n2.3.3 Denormalized Tuple Data反范式化（范式化是尽可能地将一个表进行拆解，使其耦合性降低，反范式化是其反面）相关联的tuple，将它们存储在同一个page中。\n\n潜在地减少常见工作负载模式的IO量（因为只需要读一个page了）\n使更新数据变得昂贵的（数据量变大了）\n\n3. 数据库存储——Problem 2数据库存储关注的第二个问题是我们实际该如何管理内存以及在硬盘间来回移动数据。\n我们主要考虑的是面向磁盘的架构设计，这种DBMS假设首要的存储位置是在非易失性存储上。DBMS的组件管理着数据从非易失性存储（磁盘）移动到易失性存储（内存）上。\n3.1 Data Representation3.1.1 Storage of different data type\n图3：数据表示\n\n\nvariable-precision number（IEEE-754标准）：处理速度更快，但是有取舍的误差。\nfixed point decimal number：固定精度数字，利用元数据来存储确切的二进制表示（哪里是小数点，哪里是精度范围，哪里是四舍五入信息）。\n\n3.1.2  Store Large Values1）Overflow Page如何存储size比一页要大的值。DBMS可以使用额外的overflow page来存储这些页。如果一个tuple中有一个size比page size要大的值，该值会放在overflow page中，而该tuple中在该值的位置会存放一个指向overflow page中该值的指针（overflow page的page id + slot id）。\n如果该overflow page也无法存放该值，其会类似地将该值存放到其它page中，该overflow page存放指向那个位置的指针（和前面一样，也是个record id)。\n2）External value storage还有另一种方法，就是将大数据存放到外部文件中，而在tuple中的对应位置保存一个指针或者是一个文件路径指向能找到该数据的本地磁盘、网络存储或者是外部存储设备。但是DBMS没有办法修改外部文件的数据，没有一致性保护和事务保护。（可以用该方法存放视频文件等大数据，考虑性能和经济效益。）\n3.2 System CatalogsDBMS在目录中存放了关于数据库的元数据。很多DBMS都会将它们的catalog用另一张表来保存。在SQL标准中，使用INFORMATION_SCHEMA来访问该元数据。\n\n表名，索引，视图\n用户以及其权限\n内部统计数据\n\n# PostgreSQL\\d\\d+ $&#123;tableName&#125;# mysqlshow tables;show databases;describe $&#123;tableName&#125;;\n\n3.3 Storage Models3.3.1 Workload1）OLTPOLTP是指On-line Transaction Processing，联机事务处理。联机事务处理是指读&#x2F;更新一小部分关联到数据库中条目的数据。\n2）OLAPOLAP是指On-line Analytical Processing，联机分析处理。联机分析处理是指从收集到一大堆数据后，分析它们并且推断出新的信息。\n3）HTAPHTAP是指hyper transaction analytical processing混合事务分析处理，它混合了OLTP和OLAP。\nQ: SQL, NoSQL, newSQL3.3.2 N-Ary Storage Model（NSM）行存储，其基本思路是将单个tuple中的所有属性取出，并将它们连续地存储在我们的page中，这样我们取数据就可以以一行为粒度连续地读取。这种存储方式比较适用于OLTP这种workload，因为其通常只需要读&#x2F;更新一小部分数据（这些数据在行存储的page中通常是连续的）。\n优点：当我们访问整个tuple时，插入、更新以及删除数据时的速度很快。（针对的是想要获取单个或者多个tuple的全部属性）\n缺点：做OLAP工作的性能很糟糕，因为这通常需要去扫描整张表中的大部分内容。\n3.3.3 Decomposition Storage Model（DSM）列存储，将单个列（单种属性）所有值连续地保存在一起。每个page对应于一种属性。列存储的数据可以进行压缩，以此让一个page可以存储更多的数据？\n优点：适合做OLAP，相较于行存储其做OLAP无效的IO做得更少。更有利于查询处理和数据压缩。\n缺点：对于查询、插入、更新和删除一个tuple的操作，处理速度很慢。\n1）Tuple Identification如何从一个page中找到一个匹配项。\nFixed-length Offsets使用固定长度的偏移值。对于一列中的每个值来说，它们的长度始终是固定的（利用填充或者压缩属性值使其长度为统一长度）。offset * value size得到匹配项的位置。\nEmbedded Tuple Ids（废弃）每一个值与其tuple id一起存储，我们通过一个map来查找这个匹配项。\n3.3.4 Bifurcated Environment\nOLTP Data Silos（数据孤岛）\nOLAP Data Warehouse（数据仓库）\n\n1）OLTP + OLAP\n在每个数据孤岛上做OLTP，然后就可以进行被称为ETL的操作，该操作是指从前端数据库中取出数据，将数据进行清洗处理，接着将处理后的数据传入到后端的数据仓库。之后在后端的数据仓库进行OLAP，后端数据仓库可以将分析得到的结果存入到前端的数据孤岛上。\n2）HTAP\nHATP在前端的数据孤岛上既做OLTP，也做OLAP。\n3.3.5 Conclusion对症下药，混合是一个bad idea。\n\nOLTP &#x3D; Row Store\n\nOLAP &#x3D; Column Store\n\n\n3.4 Some Think想要最小化在磁盘上执行查询速度缓慢带来的影响。\n3.4.1 Spatial ControlSpatial Control是指我们实际将数据写入到了磁盘的哪里，我们应当尽可能地使要一起用的page在磁盘上的物理位置接近。\n3.4.2 Temporal ControlTemporal Control是指什么时候将数据读到内存之中，并且如果它们被修改了，我们什么时候将其回写到磁盘之中。其目标是减少我们必须要从磁盘中读取数据的次数。\n","categories":["数据库"],"tags":["CMU 15-445","存储"]},{"title":"CMU15-445笔记4——Buffer Pools","url":"/2022/06/20/CMU15-445%E7%AC%94%E8%AE%B04%E2%80%94%E2%80%94Buffer-Pools/","content":"1. Buffer Pool Manager1.1 Buffer Pool Organization我们为buffer pool分配一块大的内存，并将我们从磁盘中读取到的所有page放入里面。这段内存是由数据库系统来控制的，而不是操作系统。我们将buffer pool分为一个个frame来存放page。当执行引擎请求数据时，如果在buffer pool中找不到对应的数据，DBMS会从磁盘上取出相应的page存放到buffer pool中的frame中，page在frame中存放的顺序并不是按照其在磁盘上的顺序，因此我们需要一个indirection层来寻找相应的page。\n\n图1：Buffer Pool Organization\n\n1.1.1 Buffer Pool meta-data\n图2：Page Table of Buffer Pool\nPage Table用来追踪存放在内存中的page，Page table是一个hash table。如果我们想找一个特定的page，通过page表和page id，我们就可以知道这个page在哪个frame中。\n除了page table，DBMS还维护了一些额外的元数据来追踪当前Buffer Pool中page的状态：\n* Dirty Flag：该flag用来指示当我们从磁盘中读取到这个page后，这个page是否被修改。\n* Pin/Reference Counter：pin计数或者说是引用计数，它用来追踪想要使用该page的当前线程数量或者是正在查询该page的数量，这意味着DBMS不希望该page被移除或者是交换回磁盘。\n* Other meta data：比如使用日志来记录哪些page被修改。\n\n\n\n图3：Pin and Latch\n图中的pin表示DBMS不希望该page被移除，图中的锁用来解决同步互斥问题。\n\n1.1.2 Locks vs. Latches\nLocks\n\n用来保护数据库中的逻辑内容，例如：tuple，表和数据库\n事务会在运行的时候持有这个lock\n需要支持回滚（rollback）\n\n\nLatches\n\n用来保护DBMS的关键部分，例如保护数据结构和保护内存区域\n执行操作的时候会持有该latch，执行完该操作后释放\n无需考虑回滚，因为latch是一个内部的东西\n\n\n\n1.1.3 Page Table vs. Page Directory\nPage Table\npage table保存的是page id到buffer pool中frame的映射\n不需要持久化\n\n\nPage Directory\npage directory保存的是page id到数据库文件中page位置的映射\n需要持久化在磁盘中\n\n\n\n1.2 Allocation PoliciesAllocation Policies是指如何为数据库中的buffer pool分配内存。\n1.2.1 Global Policies全局策略，这种策略能够使所有要执行的workload都受益。\n1.2.2 Local Policies局部策略，针对每个单个查询或者单个事务来进行。\n1.3 Buffer Pool Optimizations1.3.1 Multiple Buffer PoolsDBMS可以有多个buffer pool，每个buffer pool都有自己的page table。我们可以一种数据库对应一个buffer pool，也可以一个数据表对应一个buffer pool。\n优点：\n\n这样可以在每个buffer pool使用不同的策略。\n这样做可以减少那些试图访问buffer pool的不同线程争抢latch的情况发生。\n\n两种方式实现multiple buffer pools（如何将你要寻找的数据映射到某个buffer pool中的某个page上）：\n1）Object Id将object id嵌入到record id，之后维护一个object到特定buffer pool的映射。\n2）Hashing将page id做hash操作来选择access哪个buffer pool。\n1.3.2 Pre-Fetching根据请求计划预取数据来减少停顿（将磁盘中的数据读取到内存中会产生停顿）。DBMS相比于操作系统知道更多查询的细节，其预取page能够做更好的优化。\n1.3.3 Scan Sharing扫描共享，有一些请求的数据（page）可以重用。这与result caching不同，result caching是重用相同的查询的结果。扫描共享将一个查询的游标附着在另一个做相似查询的游标上，并且记录已经扫描的buffer pool的位置，这样就可以避免重复的扫描。（关于buffer pool中的page会被移除和回写的问题，不用担心，pin counter会对其进行阻止。）\n1.3.4 Buffer Pool Bypass我们分配一小块内存给执行查询的那条线程，之后该线程读取某数据时，如果该数据不在buffer pool中，那么从磁盘中拿到该page后将其放入到本地内存中（而非buffer pool中），当查询执行完后，这些内存中的page被丢弃。\n优点：\n\n减少了很大一部分的开销（page table的查询开销，以及latch）\n很适合读取在磁盘上连续存储的页\n可以被用于一些临时的数据（中间结果），比如sorting，joins\n\n缺点：\n\n数据量过大的时候不适合使用\n\n1.4 OS page cache操作系统读写文件时会有缓存，大多数DBMS会使用direct IO来避免产生操作系统的缓存。目前来看，使用操作系统缓存的DBMS只有Postgres。\n\n如果使用操作系统缓存，那么就相当于两份page，一份在buffer pool中，一份在操作系统的缓存中，这会导致冗余。当buffer pool中的page被修改了，缓存中的page就毫无用处了。\n\n保证跨操作系统的管理一致性。\n\n\n2. Replacement PoliciesBuffer Pool替换策略是指决定buffer pool中的哪个frame被换出以此为换入的page提供空间。\nGoals：\n\n正确性：如果某个数据我们并没有真正地使用完，那么我们不想将它写出或移除。\n准确性：希望能够确保所移除的page是在未来不太会被使用到的那些page。\n速度：希望该策略的执行是较为快速的。\n元数据的开销：希望元数据的开销尽可能的小。\n\n2.1 Least Recently UsedLeast recently used策略是指最近最少使用策略，该策略记录page的时间戳（每次access会更新时间戳），优先替换时间戳最老的page。\n2.2 ClockClock是一种类似于LRU的策略，该策略无须去追踪每个单个page的时间戳，而需要去追踪每个page的标志位（reference bit），这个标志位指示的是这个page是否被访问了。将page组织成一个环形的buffer，然后有一个能够旋转的指针去检查每个page的该标志位是1还是0，如果其为0,那么就表示自从上次被检查后，该page没有在被访问了，因此将该page从这个环形buffer中移除，如果其为1，我们将其设置为0，并访问下一个page的该标志位。\nSequential FloodingLRU与Clock策略都会受到sequential flooding的影响，如果一个查询是顺序地读取每个page，那么这个查询会导致buffer pool被只使用一次的page所污染，而真正之后需要的page被移除了。\n2.3 LRU-K被访问了k次的page会被记入缓存队列，同时根据时间戳计算出某个page多久没被使用来决定哪个page被移除。\n2.4 Localization使用多个buffer pool，使每个查询之间相互独立，每个查询的缓存page存入到对应查询的buffer pool中。例如Postgres就为查询维护了一个私有的、小的环形buffer pool。\n2.5 Priority HintsDBMS在查询执行时能够知道每个page的上下文信息，因此其能够提供给buffer pool某些page的重要性。\n2.6 Dirty Pages每个page有一个dirty bit来指示该page在被读入buffer pool后是否被修改，而在替换page时需要考虑这一点，有两种关于dirty page的替换策略：\n\nFAST：如果buffer pool中的页不脏，DBMS直接移除它。\nSLOW：如果buffer pool中的页是脏的，DBMS必须首先将内存中的page写回到磁盘中，之后在移除它。\n\n在具体的替换策略中，需要在替换最近可能被使用+非脏页和最近不会被使用+脏页中进行权衡。\nBackground Writing后台写操作，DBMS中有一条执行定时任务的线程，它会去buffer pool中找出那些被标记为dirty的page并将它们写出到磁盘上，以此将page的状态由dirty变为clean。要注意在回写前首先写操作日志到磁盘上。\n3. Other Memory Pools除了用于tuple和indexes的内存空间，DBMS需要其它的内存池。\n\nSorting+Join Buffer\nQuery Caches\nMaintenance Buffers\nLog Buffers\nDictionary Caches\n\n","categories":["数据库"],"tags":["CMU 15-445","存储"]},{"title":"CMU15-445笔记5——Hash Table","url":"/2022/08/22/CMU15-445%E7%AC%94%E8%AE%B05%E2%80%94%E2%80%94Hash-Table/","content":"Hash Tablehash table或者b+树等数据结构在数据库中的作用：\n\n内部元数据（meta internal data）：page表或者page目录\n核心数据存储（core data storage）：此时数据结构的值就是tuple，memcache用的是page tabe，mysql的innodb引擎用的是b+树\n临时数据（temporary data structures）\n表索引（table indexs）：是能够快速找到想要的元素\n\n1. Hash Function\nhow to map a large key space into a smaller domain.\nTrade-off between being fast vs. collision rate.\n\n知名的hash函数：\n\nCRC-64\nMurmurHash\nGoogle CityHash\nFacebook XXHash（仍在不断改进，其最快）\nGoogle FarmHash\n\n2. Hashing Scheme\nhow to handle key collisions after hashing.\nTrade-off between allocating a large hash table vs. additional instructions to find&#x2F;insert keys.\n\n2.1 Static Hashing SchemesStatic Hashing Schemes是指提前知道我想要保存的key的大概数量。\n1) Linear Probe Hashing解决hash碰撞的方法是，如果我们进行hash计算所得到的slot位置上已经有数据在上面了，如果我试着往里面插入数据，我们会挨着这条数据往下扫描，直到我们遇到下一个能够插入的空slot为止，然后我们将我们试着添加的那个entry插到这个slot上。当我们做查找的时候，我会先找到hash函数所计算出的那个offset所在的地方，接着我会继续往下扫描，直到我找到一个空slot。（hash table的每个条目会存储hash key和hash value，正常是不需要放hash key的值的）\n当对hash table中的数据进行删除时，有这么几种策略，一种是在删除数据的位置放一个墓碑标志（tombstone）表示该位置逻辑上无效；一种是移动数据，将下面的数据向上移动（这可能会导致错误）。\n2) Robin Hood Hashing罗宾汉，劫富济贫，平均财富。\npoor key会从rich key偷取slot，poor或是rich由存储位置与第一次进行hash所计算出的位置间的距离差来决定。其根本思想就是试着对整个hash table进行平衡，试着让每个key尽可能地靠近它原本所在的位置。\n3) Cuckoo Hashing使用两个hash table，这两个hash table可以使用相同的hash function但是它们的seed不相同，如果两个hash function得到的位置结果都是空的话，那么随机选择；如果得到的结果有一个为空，一个不为空，则填充到空的位置；如果两个都为非空，则随机选择一个位置进行抢占，被抢占的元素递归地再次进行之前的流程。这个方法也有无法完全解决碰撞的可能性，此时就要进行扩容操作（该操作会改变hash function中的相应数值）。\n2.2 Dynamic Hashing Schemes1) Chained Hashingjava中默认的hashmap实现，它会维护一个包含了buckets的链表，通过将相同hash key的所有元素放入相同的bucket解决冲突。做插入操作时，只是将slot array插入到bucket中，如果bucket满了的话就在末尾再添加一个bucket。这些bucket相当于是page，添加bucket相当于是分配新的page，DBMS通过page id来遍历它们。\n\n2) Extendible Hashing为了避免chained hashing这样没有限制的增长（这会导致最后的查询复杂度变为O(n)），我们选择对overflow的bucket做拆分。该方法的hash table基本结构和chained hashing很类似，不过有一些额外的信息，有一个global counter和每个bucket都有一个local counter，其中global counter表示需要考虑几个bit，local counter中记录的数字表示的意思是需要看几个bit才能找到该slot的位置。如果有某个bucket溢出了，那么就引入更多的bit来确定slot的位置（global counter和local counter都会变化），hash table包含的链表数量也会变化。（需要补充的是，这里的hash function的结果是一串二进制数字，因此每一位为一个bit。）\n3) Linear HashingExtendible Hashing每一次扩容都会变成原来的两倍大小（每多考虑一个bit，相当于乘以2），此时hash table需要加锁导致不能被其它线程访问，这会导致性能的瓶颈，因此Linear Hashing提出了一种方法，其只需要去分配那些溢出的bucket（这样扩容的量就少了？）。其有一个split pointer指向hash table中的链表头，如果有一个bucket有溢出的现象，DBMS就在hash table的末尾加上一个新的链表指向一个新的bucket，将split pointer指向的bucket的slots一分为二到新的bucket中，之后添加一个新的hash function（如果原来的hash function为key%n，现在就是key%2n），同时split pointer下移。split pointer用于指示我们应该使用哪种hash funciton，当我们查找一个slot时，如果使用第一个hash function的结果在split pointer上方分割线的上面的bucket中，那么就表明该查找的slot所在的bucket被拆分了，这时就可以视情况使用第二个hash function了。\n","categories":["数据库"],"tags":["CMU 15-445","存储","hash table"]},{"title":"CMU15-445笔记6——B plus tree","url":"/2022/08/22/CMU15-445%E7%AC%94%E8%AE%B06%E2%80%94%E2%80%94B-plus-tree/","content":"一、B+树和B树b+树是一个自平衡树，当我们插入数据时，其会保证数据的有效性；b+树插入、删除和查询的算法复杂度为O(log n)。\n\n介绍B+树和B树的概念以及查询、插入、删除操作：https://segmentfault.com/a/1190000020416577\n为什么数据库中，B+树更加受欢迎：\nhttps://zhuanlan.zhihu.com/p/422639017\nhttps://www.zhihu.com/question/57466414\n\n\n\n二、数据库索引table indexes用于快速找到数据，每次insert或者select操作会自动更新索引。数据库索引技术中大量使用到b+树和b树。\n聚簇索引（clustered indexes）聚簇索引会对page中tuple的物理布局进行匹配排序（对磁盘上实际数据重新组织以按指定的一个或多个列的值排序，这里的值是主键的值）。\n查询的情况B+树可以进行复合查询，比如查询两个属性的值，一个值为A，一个值为B；而hash table不行。\n对于查找key&#x3D;（A，*）的情况，除了根据原有的查找方式查找外，还需要沿着叶子结点的链表做顺序遍历，直到找到不匹配的值才结束。\n对于查找key&#x3D;（*，B）的情况，先找到大致的范围（找到可能相符合的叶子结点），之后对每一个叶子结点中的key进行匹配。\nB+树在数据库中的设计1. Node Size存储设备的速度越慢，节点尺寸越大。\n\nHDD：～1MB\nSSD：～10KB\nIn-Memory：~512B\n\n最优的节点尺寸大小还依赖于具体的workload，对于叶子节点的扫描， DBMS使用的是耗时长的顺序扫描，通常情况下这更适合大小更大的节点，因为我们可以进行更多的顺序扫描；如果DBMS所进行的查找、遍历需要进行大量的随机I&#x2F;O，我想要的是体积更小的节点。\n2. Merge Threshold因为B+树的插入和删除操作极有可能导致B+树越来越趋向于不平衡，在实战中我们不会立即合并半满的叶子节点（当然拆分是立即执行的），而是会在之后统一重新平衡整一棵树。\n3. Variable Length Keys（如何处理可变长度的key）\n方式一（pointers）：不将key本身存放在节点中，我们所保存的指向其的指针，当查找时访问指针所指向的地址进行匹配。\n方式二（variable length nodes）：可变空间大小的节点，但这需要很小心的内存管理。\n方式三（padding）：填充key使该key的长度等于该key类型的最大可能长度。\n方式四（Key Map &#x2F; Indirection）：微优化，避免不必要的磁盘访问。其将key的指针存放在key数组中，我们这里的指针实际上是两个在该叶子节点中对应的offset值（类似于之前学的slotted page），而不是指向其它任何page。在叶子节点的存储结构上来看，key的指针从节点的头开始排列，而key+values从节点的尾部开始排列。\n\nNon-Unique indexesApproach #1: Duplicate keys在Key Map &#x2F; Indirection的设计下，有多个相同的key对应各自的value。（有两种处理方式，一种是在key后面加上key所在的这个tuple的record id；一种是在原有的叶子节点下面添加一个新的节点，存储重复的key以及其对应的值，有点像hash table中的bucket链表）\nApproach #2: Value Lists在Key Map &#x2F; Indirection的设计下，一个key对应一个value list。\nIntra-Node search（节点内搜索）Approach #1: Linear线性查找\nApproach #2: Binary二分查找\nApproach #3: Interpolation根据已知key的分布做插值查找\nOptimizationsPrefix Compression前缀压缩，因为近似的key总会被放在一个叶子节点中，因此可以查提取相同的前缀进行压缩。\nSuffix Truncation后缀压缩，压缩原理与前缀压缩类似，做这种压缩在做搜索的时候可以避免一些不必要的比较。\nBulk Insert首先拿到所有的key并进行排序，之后我们将其排列在叶子节点上，将它们正确填入到叶子节点中。之后我们只需要使用中间的key来填充中间节点并生成指针。\nPointer Swizzling用page指针代替page id来做索引，这适用于被固定于内存中的page，这样的好处就是不需要再使用page id来访问buffer pool了，而可以直接使用指针访问该page对应的内存。\nPartial Indexes（部分索引）只关联部分字段的索引，使用这种索引进行查询时无法读取到没有被关联的字段（因为其相当于只读取buffer pool中的索引而不读取持久化的page）。\nCovering Indexes（覆盖索引）覆盖索引指的是响应查询需求结果所需的所有字段都能在索引本身找到。可以使用index include columns技术在索引中嵌入额外的列来支持索引查询，这个额外的列只存储在叶子节点中但是不是key的一部分。\nFunctional&#x2F;Expression Indexes使用这种索引可以不通过key的自身值进行查找，而是通过该key所衍生出的某些值来进行查找。\nTrie Index使用digit（数字，字符）来表示keys来一个个地检查前缀而不是比较整个key。它也被称为prefix tree或者digital search tree。它的所有操作的算法复杂度为O(k)，其中k是key的长度。\nRadix Index如果一个path上只有一个子节点，可以将该path上的不用于区分路径的节点进行合并。\nmore tree details in CMU 15-826：R-tree，Quad-Tree，KD-tree\nInverted Index（倒排索引）more details in CMU 11-442\n该索引存储词语和包含这些词语的属性之间的映射，其也被称为full-text search index或concordance。\n该索引可以做一些在b+树无法进行的搜索：\n\nphrase searches：包含某个词组\nproximity searches：近似\nwildcard searches：通配符搜索\n\nDecision #1: what to save\n这个索引至少要保存记录包含的词语\n同时也可以保存词频，词语位置和其它元数据\n\nDecision #2: when to update使用辅助数据去更新，考虑使用定期更新、分批更新\n","categories":["数据库"],"tags":["CMU 15-445","存储","B+树"]},{"title":"CMU15-445笔记7——多线程","url":"/2022/08/25/CMU15-445%E7%AC%94%E8%AE%B07%E2%80%94%E2%80%94%E5%A4%9A%E7%BA%BF%E7%A8%8B/","content":"concurrency control\n\nLogical correctness\nPhysical correctness\n\nLatch\n\n\n\nLocks\nLatches\n\n\n\nSeparate\nUser transactions\nThreads\n\n\nProtect\nDatabase contents\nIn-memory Data Structures\n\n\nDuring\nEntire Transactions\nCritical Sections\n\n\nModes\nShared, Exclusive, Update, Intention\nRead, Write\n\n\nDeadLock\nDetection &amp; Resolution\nAvoidance\n\n\n… by …\nWaits-for, Timeout, Aborts\nCoding Discipline\n\n\nkept in …\nLock Manager\nProtected Data Structure\n\n\nLatch ImplementationApproach #1: Blocking OS Mutexstd::mutex m;...m.lock();//Do something specialm.unlock();\n\nApproach #2: Test-and-Set Spin Latch(TAS)std::atomic_flag latch;...while(latch.test_and_set(...))&#123;  //Retry?Yield?Abort&#125;\n\nApproach #3: Read-Writer Latch正常的读写锁逻辑\nHashing table latching不会发生死锁，因为扫描顺序都是从hash table的头到尾。\nApproach #1: Page Latches在每一个page上，使用一个read&#x2F;write latch。\nApproach #2: Slot Latches使用粒度更小的latch，即你可以在每个slot上使用latch。\nB+ Tree Concurrency ControlTwo problems needs to be protected：\n\n多个线程尝试去同时修改一个节点中的内容\n一个线程在遍历树的时候，另一个线程在分割&#x2F;合并节点\n\nApproach #1: Latch Crabbing&#x2F;Coupling这种技术允许多条线程在同一时间访问B+ tree。\nsafe node是指当插入时不是满的，当删除时节点中的key数大于容量的一半。\n\nFind操作：从根节点开始往下走，需要子节点上的read latch，之后解开父节点的锁。\nInsert&#x2F;Delete操作：从根节点开始往下走，使节点获得write latch，一旦子节点被锁上了，检查它是否安全，如果安全就解开所有祖宗节点的latch。（尽可能先释放更靠近root的节点）\n\nApproach #2: Better Latching Algorithm由于之前的方法并发操作效率很低，我们使用一个优化的方法来实现线程同步。我们假设叶子节点是安全的，DBMS使用read latch去接近叶子节点（去除父节点的latch和latch crabbing中find case的操作一致），并且验证它是否是安全的。如果叶子节点不是安全的，那我们使用上面的latch crabbing方法（用的是write latch）。在现实的数据库系统中，需要做拆分和合并的概率很小。\nLeaf Node Scan叶节点扫描需要去考虑死锁的问题。\ncase 1: 读遇上读两个叶子节点交换锁。\ncase 2: 读遇上写读线程restart，这样可以避免死锁，不过这可能会导致饥饿。\nDelayed Parent Updates当一个节点溢出的时候，我们必须更新至少三个节点：\n\n该叶节点必须被拆分\n要创建一个新的叶节点\n修改父节点使其容纳新的key\n\n延迟更新父节点是一种对于这种情况的优化技术。当插入新的值时，只会更新子节点而不更新父节点，但是会在一个全局变量中表明父节点需要更改的内容，当下一次获取到该父节点的write latch时再更新该父节点。（这样方便还有个原因是因为一开始更新操作之前的节点使用的都是read latch）\n","categories":["数据库"],"tags":["CMU 15-445","存储","多线程"]},{"title":"CMU15-445笔记8——Sorting&Aggregations","url":"/2022/08/26/CMU15-445%E7%AC%94%E8%AE%B08%E2%80%94%E2%80%94Sorting-Aggregations/","content":"面临的问题：我们设计的这个数据库是基于磁盘的，而实际处理数据需要用到内存，因此我们的算法需要去考虑我们此时想得到的数据可能不在内存中而在磁盘中。\nExternal Merge Sort外部归并排序。\n排序算法将我们想要排序的数据集分成更小的数据块，称之为runs，然后其对runs单独排序。之后该算法会对runs进行合并得到更大的runs，直到最后整个数据集变为有序的。\n\nPhase #1：我们会将尽可能多的数据块放入内存，并对它们进行排序，然后将排完序的结果写回磁盘。\nPhase #2：我们会将排完序的runs结合。\n\n2-way External Merge SortN为page数量。\nnumber of passes &#x3D; 1 + $\\log_2N$\ntotal I&#x2F;O cost &#x3D; 2N·(# of passes)\nDouble Buffering Optimization当系统在排序当前的run时，预取下一个要用到的run到另一个buffer中，这样可以减少对于IO请求的等待时间。![2-way external merge sort-0](images&#x2F;2-way external merge sort-0.png)\nGeneral External Merge SortPass #0\n\nUse B buffer pages\nProduce $\\lceil N&#x2F;B \\rceil$ sorted runs of size B\n\nPass #1,2,3,…\n\nMerge B-1 runs，因为有一个buffer pool用来保存输出结果\n\nNumber of passes: 1+ $\\lceil \\log_{B-1} \\lceil N&#x2F;B \\rceil \\rceil$\nTotal I&#x2F;O cost: 2N·(# of passes)\n![2-way external merge sort](images&#x2F;2-way external merge sort.png)\nUsing B+ tree for sorting如果数据表对于要排序的属性已经拥有一个b+树的索引，那么我们可以直接使用b+树来加速排序，DBMS只需要遍历b+树的叶子节点以此获得按特定顺序排列的tuple。对于b+树索引，有两种情况需要考虑，分别是clustered b+ tree和unclustered b+ tree。对于前者，其叶子节点的tuple按顺序排列在相近的page上，因此io消耗很小，但是对于后者由于不是聚簇索引，读取tuples所需要消耗的io成本过大，因此通常只使用clustered b+ tree。\nAggregations聚合操作就是我们拿到一堆值，然后将它们合并起来生成一个标量值。\nSorting Aggregation根据排序更快地去除一些重复值。\nHashing Aggregation当对数据表进行扫描时，维护一个临时的hash table（只用于本次查询），对于每一个记录，检查该hash table中是否已经有一个相同key的条目，根据不同的聚合操作（distinct，group by），做不同的处理。\nExternal Hashing Aggregatehash table所需的内存可能不够，此时就要将部分数据写到磁盘上。对于这种情况，我们为了查询的速度，应当进行相应的处理。\nPhase #1 - Partition首先将数据拆分开到一个个的bucket中（基于hash key），当某个page满时将它们写到磁盘上。\n假设我们拥有B个buffer，我们将使用B-1个buffer用于分区，1个buffer用于输入数据。\nPhase #2 - ReHash对每个分区中的数据重新做hash操作得到一个新的hash table，最后根据hash table得到最终结果。（为什么这样比sorting更高效呢？）\n","categories":["数据库"],"tags":["CMU 15-445","存储","排序","聚合"]},{"title":"CMU15-445笔记9——Join Algorithms","url":"/2022/08/29/CMU15-445%E7%AC%94%E8%AE%B09%E2%80%94%E2%80%94Join-Algorithms/","content":"Join Algorithms1. Nested Loop Join1.1 Simple &#x2F; Stupidforeach tuple r 属于 R:  foreach tuple s 属于 S:    emit, if r and s match\n\n// M是外层表的page数，m是外层表的tuple数量；N是内层表的page数。IO cost =  M + m*N\n\n1.2 Block每一次读取内层表中的每一个page作为一个block和外层表一起处理，此时相当于是让外层表和内层表的page进行join（而不是像上面的stupid方式一样按照tuple进行join），此时的IO cost如下所示：\nIO cost = M + M*N\n\n如果我们使用B-2个buffer来扫描外部表（另两个buffer用于扫描内部表，两个交替来减少io时间开销）\nIO cost &#x3D; M + ($ \\lceil {M&#x2F;(B-2)} \\rceil $ * N )\n1.3 Index利用一些其它信息进一步降低开销，比如索引（这个索引可以是之前就建立好的，或者临时建立一个用于join操作）。\n// C是平均每次索引查询操作的复杂度IO cost = M + (m * C)\n\n2. Sort-Merge Join// R是外层表，S是内层表sort R,S on join keyscursor_r &lt;- R_sorted, cursor_s &lt;- S_sortedwhile cursor_r and cursor_s:  if cursor_r &gt; cursor_s:     increment cursor_s  if cursor_r &lt; cursor_s:     increment cursot_r  elif cursor_r and cursor_s match:     emit     increment cursor_s\n\n有可能会触发回溯操作，比如外部表有两个特定key相同的tuple，由于匹配后内部表指针会自增，第二个tuple匹配的情况会被忽略。所以当我移动外部表的游标，并且它匹配内部表刚看到的最后一个tuple，那么就对内部表进行回溯操作。\nSort Cost(R): 2M * (logM / logB)Sort Cost(S): 2N * (logN / logB)Merge Cost: (M+N)Total cost: Sort Cost + Merge Cost\n\n最糟糕的情况是两个表中所有的tuple都相同。\n如果两个表的聚簇索引的键正好是join操作需要的键，那么就不需要做排序操作了。\n3. Hash Joinbuild hash table HT_r for R:  // build phaseforeach tuple s 属于 S:       // probe phase   output, if h(s) 属于 HT_r\n\nHash table values\nApproach #1: Full Tuple\n\nApproach #2: Tuple Identifier\n\n\nProbe phase optimization创建一个bloom filter来预先检查一个key是否可能存在于hash table中。\nbloom filter是一个hash table，其每一位对应的是一个key被多个hash function分别映射得到的结果。当查询一个key是否在一个hash table中时，如果该key被hash table映射的bit有一个不为1，则表示该key不存在于该hash table中；但是如果映射的每个bit都为1，则只能表示该key可能存在于该hash table中。\nGrace Hash JoinJoin each pair of matching buckets between table R and S。\n理想情况是所有buckets都能放进内存里，但是当数据量太大时，bucket往往无法放进内存里，此时就要做拆分，当一个bucket的大小超过某个阈值的时候，可以使用recursive partitioning来对数据进行递归分区，如下图所示：\n\n当所有数据都在一个bucket且难以拆分时，此时就只能使用最普通的nested loop join了。\nCost of hash join: 3(M+N)Partition phase: 2(M+N)Probing Phase: M+N\n\n","categories":["数据库"],"tags":["CMU 15-445","存储","Join"]},{"title":"MIT6.824笔记1——Introduction","url":"/2022/06/03/MIT6-824%E7%AC%94%E8%AE%B01%E2%80%94%E2%80%94Introduction/","content":"Introduction分布式系统的特点：\n\nparallelism\n\nfault tolerance\n\nphysical\n\nsecurity &#x2F; isolated\n\n\n分布式系统面临的挑战：\n\nconcurrency\npartial failure\nperformance\n\n分布式系统在基础架构的使用：\n\nStorage\nCommunication\nComputation\n\n分布式系统的实现工具:\n\nRPC\nthreads\nconcurrency lock\n\n分布式系统需要考虑的：\n\nScalability：两倍的计算机数量能让我获得两倍的性能\nAvailability：发生故障时的可用能力\nRecoverability：从故障中恢复的能力，依靠非易失性存储和副本\nconsistency：一致性，考虑它的原因是，在分布式系统中，经常有不只一份数据\n强一致性：很耗时\n弱一致性\n\n\n\nMapReducepaper of map reduce\n1. OverviewMapReduce是一个分布式的框架，其主体处理部分为map function和reduce function。其一整个处理流程为一个job，它是由一系列的map task和reduce task组成的。在该架构中，master负责任务的调度，worker负责map和reduce任务的执行。\n\n我们可以通过一个统计文档中词频的任务来理解MapReduce这个框架，处理的流程如下图所示，输入的Input是一个文档，我们假设在第一个文档中统计到词语a出现了1次，词语b出现了1次，第二个文档中词语b出现了1次，第三个文档中词语a出现了1次，词语c出现了1次。Map function处理后也就得到了中间结果key&#x2F;value键值对，之后Reduce function根据key的种类进行操作，最后分别得到不同词语的出现总次数。\n\n下面的代码块表示的是词频统计任务中的Map function和Reduce function。\n/* Map函数的k是文件名；v是输入文件的内容。*/Map(k,v)  split v into words  for each word w:\temit(w,&quot;1&quot;)\n\n/* Reduce函数的k是单词；v是一个vector，统计的词数,在最简单的例子中，元素值都为1 */Reduce(k,v)  emit(len(v))\n\nMapReduce中间结果的存储（Map函数的处理结果）先存储到本地，之后被Reduce function读取（涉及网络传输）。但是MapReduce的输入和输出文件的存储依赖于GFS这个文件系统（google三驾马车之一）。\n","categories":["分布式系统"],"tags":["MIT6.824","分布式"]},{"title":"Prometheus Histogram分位线计算","url":"/2024/09/21/Prometheus-Histogram%E5%88%86%E4%BD%8D%E7%BA%BF%E8%AE%A1%E7%AE%97/","content":"Prometheus有四种指标类型，分别是Counter、Gauge、Histogram以及Summary。\n其中Counter是一个累加的计数值，Gauge是一个瞬时值，Histogram以及Summary是对一段时间内数值做一个汇总统计，Histogram使用分桶统计指标数值的分布（比如不同耗时的请求，每个耗时区间有多少数量的请求），Summary则是在客户端直接计算得到总和、平均值以及分位线。\n分位线（Quantile）是用于将数据分成等量部分的统计量。它的作用是将一个数据集按一定比例分割，并标志这些分割点。比如在可观测领域常用的P99分位线，用在黄金指标的耗时指标中，其的含义就是最慢的那百分之一请求的耗时最小值是多少。Summary的分位线直接在客户端计算，而Histogram的分位线是在服务端进行计算，这里主要讲一下计算的逻辑。\nHistogram使用一个个桶来标识不同区间数据的数量，每个桶有两个属性，分别是上界（upperBound）和数量（count），也就是Histogram指标统计的所有数据小于该上界的数量。那么当我们想要求某一个分位线时，比如P99，我们就是求比Histogram中99%的数据都要大的数值，我们可以用百分数去乘以该桶的总数量，也就是比我们要求的值小的数据数量，之后根据该求得的数量rank找到所在桶的位置，之后使用线性插值法求得rank在该桶中大致的位置，也就得到了我们想要的分位数。\ntype bucket struct &#123;\tupperBound float64\tcount      float64&#125;// buckets implements sort.Interface.type buckets []bucket\n\nfunc bucketQuantile(q float64, buckets buckets) float64 &#123;\tif math.IsNaN(q) &#123;\t\treturn math.NaN()\t&#125;\tif q &lt; 0 &#123;\t\treturn math.Inf(-1)\t&#125;\tif q &gt; 1 &#123;\t\treturn math.Inf(+1)\t&#125;\tslices.SortFunc(buckets, func(a, b bucket) int &#123;\t\t// We don&#x27;t expect the bucket boundary to be a NaN.\t\tif a.upperBound &lt; b.upperBound &#123;\t\t\treturn -1\t\t&#125;\t\tif a.upperBound &gt; b.upperBound &#123;\t\t\treturn +1\t\t&#125;\t\treturn 0\t&#125;)\tif !math.IsInf(buckets[len(buckets)-1].upperBound, +1) &#123;\t\treturn math.NaN()\t&#125;\tbuckets = coalesceBuckets(buckets)\tensureMonotonic(buckets)\tif len(buckets) &lt; 2 &#123;\t\treturn math.NaN()\t&#125;\tobservations := buckets[len(buckets)-1].count\tif observations == 0 &#123;\t\treturn math.NaN()\t&#125;  // 位置 = 百分比 * 总数量\trank := q * observations  // 找到其所在的桶位置\tb := sort.Search(len(buckets)-1, func(i int) bool &#123; return buckets[i].count &gt;= rank &#125;)\tif b == len(buckets)-1 &#123;\t\treturn buckets[len(buckets)-2].upperBound\t&#125;\tif b == 0 &amp;&amp; buckets[0].upperBound &lt;= 0 &#123;\t\treturn buckets[0].upperBound\t&#125;\tvar (\t\tbucketStart float64\t\tbucketEnd   = buckets[b].upperBound\t\tcount       = buckets[b].count\t)  // 使用线性插值法计算在该桶中的估算位置\tif b &gt; 0 &#123;\t\tbucketStart = buckets[b-1].upperBound\t\tcount -= buckets[b-1].count\t\trank -= buckets[b-1].count\t&#125;\treturn bucketStart + (bucketEnd-bucketStart)*(rank/count)&#125;\n\n","categories":["可观测"],"tags":["prometheus","histogram"]},{"title":"gdb入门系列2","url":"/2021/11/22/gdb%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%972/","content":"GDB入门系列2一、help命令的使用ubuntu@VM-0-14-ubuntu:~/learn_gdb$ gdb\n(gdb) helpList of classes of commands:aliases -- Aliases of other commands.breakpoints -- Making program stop at certain points.data -- Examining data.files -- Specifying and examining files.internals -- Maintenance commands.obscure -- Obscure features.running -- Running the program.stack -- Examining the stack.status -- Status inquiries.support -- Support facilities.--Type &lt;RET&gt; for more, q to quit, c to continue without paging--ctracepoints -- Tracing of program execution without stopping the program.user-defined -- User-defined commands.Type &quot;help&quot; followed by a class name for a list of commands in that class.Type &quot;help all&quot; for the list of all commands.Type &quot;help&quot; followed by command name for full documentation.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;.Type &quot;apropos -v word&quot; for full documentation of commands related to &quot;word&quot;.Command name abbreviations are allowed if unambiguous.\n(gdb) help breakpointsMaking program stop at certain points.List of commands:awatch -- Set a watchpoint for an expression.break -- Set breakpoint at specified location.break-range -- Set a breakpoint for an address range.catch -- Set catchpoints to catch events.catch assert -- Catch failed Ada assertions, when raised.catch catch -- Catch an exception, when caught.catch exception -- Catch Ada exceptions, when raised.catch exec -- Catch calls to exec.--Type &lt;RET&gt; for more, q to quit, c to continue without paging--c\n二、关于Tab自动补全\n补全用于命令（输入字符后按两下Tab，显示所有该字符开头的命令）(gdb) bbacktrace    bookmark     break        break-range  bt\n(gdb) nnew-ui           next             nexti            ni              nosharedlibrary\n补全用于函数名（输入b ma后按下Tab会自动补全为b main）\n\n三、在GDB中运行unix的shell程序shell \n(gdb) shell lstst  tst.c\n四、其它关于GDB调试1. 设置程序运行参数为了尝试设置运行参数，我更改了tst的代码，更改的部分如下所示。\n......main(int argc, char *argv[])&#123;    for(int index = 1; index&lt;argc; index++)&#123;        printf(&quot;argv[%d]: %s\\n&quot;,index,argv[index]);    &#125;......\n(gdb) set args yemufi pdzhu(gdb) rStarting program: /home/ubuntu/learn_gdb/tst yemufi pdzhuargv[1]: yemufiargv[2]: pdzhuresult[1-100] = 5050 /nresult[1-250] = 31125 /n[Inferior 1 (process 2986037) exited normally](gdb) show argsArgument list to give program being debugged when it is started is &quot;yemufi pdzhu&quot;.\n2. 设置运行环境path &lt;dir&gt; 可设定程序的运行路径。show paths 查看程序的运行路径。set environment varname [=value] 设置环境变量。如：set env USER=hchenshow environment [varname] 查看环境变量。\n(gdb) show pathsExecutable and object file path: /home/ubuntu/.vscode-server/bin/ccbaa2d27e38e5afa3e5c21c1c7bef4657064247/bin:/home/ubuntu/.vscode-server/bin/ccbaa2d27e38e5afa3e5c21c1c7bef4657064247/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games(gdb) show environmentSHELL=/bin/bashCOLORTERM=truecolorTERM_PROGRAM_VERSION=1.62.3HISTSIZE=1000LANGUAGE=en_US.utf8:HISTTIMEFORMAT=%F %T PWD=/home/ubuntu/learn_gdbLOGNAME=ubuntuXDG_SESSION_TYPE=ttyVSCODE_GIT_ASKPASS_NODE=/home/ubuntu/.vscode-server/bin/ccbaa2d27e38e5afa3e5c21c1c7bef4657064247/nodeMOTD_SHOWN=pamHOME=/home/ubuntu--Type &lt;RET&gt; for more, q to quit, c to continue without paging--\n3. 设置工作目录(gdb) cd dirAWorking directory /home/ubuntu/learn_gdb/dirA.(gdb) pwdWorking directory /home/ubuntu/learn_gdb/dirA.(gdb) cd ..Working directory /home/ubuntu/learn_gdb.(gdb) pwdWorking directory /home/ubuntu/learn_gdb.\n4. 程序的输入输出info terminal 显示你程序用到的终端的模式。使用重定向控制程序输出。如：run &gt; outfiletty命令可以指写输入输出的终端设备。如：tty /dev/ttyb\n(gdb) set args yemufi pdzhu big(gdb) run &gt; outfileStarting program: /home/ubuntu/learn_gdb/tst &gt; outfile[Inferior 1 (process 2988331) exited normally]\n以下是outfile的内容（之前代码最后的&#x2F;n我已经改成了\\n）,很奇怪没有打印出输入参数相关的内容！\nresult[1-100] = 5050 result[1-250] = 31125\n5. 调试已经运行的程序1、在UNIX下用ps查看正在运行的程序的PID（进程ID），然后用gdb  PID格式挂接正在运行的程序。2、先用gdb 关联上源代码，并进行gdb，在gdb中用attach命令来挂接进程的PID。并用detach来取消挂接的进程。\n6. 断点相关6.1设置断点\nbreak 在进入指定函数时停住。C++中可以使用class::function或function(type,type)格式来指定函数名。\n\nbreak 在指定行号停住。\n\nbreak +offset在当前行号的前面的offset行停住。offiset为自然数。\n\nbreak -offset在当前行号的后面的offset行停住。offiset为自然数。\n\nbreak filename:linenum在源文件filename的linenum行处停住。\n\nbreak filename:function在源文件filename的function函数的入口处停住。\n\nbreak *address在程序运行的内存地址处停住。\n\nbreakbreak命令没有参数时，表示在下一条指令处停住。\n\nbreak … if …可以是上述的参数，condition表示条件，在条件成立时停住。比如在循环境体中，可以设置break if i&#x3D;100，表示当i为100时停住程序。\n\n\n6.2 查看断点时(n表示断点号）\ninfo breakpoints [n]\ninfo break [n]\n\n6.3 维护停止点\nclear清除所有的已定义的停止点。\nclear 清除所有设置在函数上的停止点。\nclear filename:function清除所有设置在函数上的停止点。\nclear 清除所有设置在指定行上的停止点。\nclear filename:linenum清除所有设置在指定行上的停止点。\ndelete [breakpoints] [range…]删除指定的断点，breakpoints为断点号。如果不指定断点号，则表示删除所有的断点。range 表示断点号的范围（如：3-7）。其简写命令为d。\ndisable [breakpoints] [range…]比删除更好的一种方法是disable停止点，disable了的停止点，GDB不会删除，当你还需要时，enable即可，就好像回收站一样。disable所指定的停止点，breakpoints为停止点号。如果什么都不指定，表示disable所有的停止点。简写命令是dis.\nenable [breakpoints] [range…]enable所指定的停止点，breakpoints为停止点号。\nenable [breakpoints] once range…enable所指定的停止点一次，当程序停止后，该停止点马上被GDB自动disable。\nenable [breakpoints] delete range…enable所指定的停止点一次，当程序停止后，该停止点马上被GDB自动删除。(gdb) break 20Breakpoint 1 at 0x11d7: file tst.c, line 20.(gdb) break 30Breakpoint 2 at 0x1210: file tst.c, line 30.(gdb) info breakpointsNum     Type           Disp Enb Address            What1       breakpoint     keep y   0x00000000000011d7 in main at tst.c:202       breakpoint     keep y   0x0000000000001210 in main at tst.c:30(gdb) disable breakpoints 1(gdb) info breakpointsNum     Type           Disp Enb Address            What1       breakpoint     keep n   0x00000000000011d7 in main at tst.c:202       breakpoint     keep y   0x0000000000001210 in main at tst.c:30(gdb) disable breakpoints 1-2(gdb) info breakpointsNum     Type           Disp Enb Address            What1       breakpoint     keep n   0x00000000000011d7 in main at tst.c:202       breakpoint     keep n   0x0000000000001210 in main at tst.c:30(gdb) enable breakpoints once 1-2(gdb) info breakpointsNum     Type           Disp Enb Address            What1       breakpoint     dis  y   0x00000000000011d7 in main at tst.c:202       breakpoint     dis  y   0x0000000000001210 in main at tst.c:30(gdb) break 31Breakpoint 3 at 0x1228: file tst.c, line 31.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main (argc=1, argv=0x7fffffffe148) at tst.c:2020          j = 1;(gdb) cContinuing.Breakpoint 2, main (argc=1, argv=0x7fffffffe148) at tst.c:3030          printf(&quot;result[1-100] = %d \\n&quot;, result);(gdb) cContinuing.result[1-100] = 5050 Breakpoint 3, main (argc=1, argv=0x7fffffffe148) at tst.c:3131          printf(&quot;result[1-250] = %d \\n&quot;, func(250));(gdb) info breakpointsNum     Type           Disp Enb Address            What1       breakpoint     dis  n   0x00005555555551d7 in main at tst.c:20        breakpoint already hit 1 time2       breakpoint     dis  n   0x0000555555555210 in main at tst.c:30        breakpoint already hit 1 time3       breakpoint     keep y   0x0000555555555228 in main at tst.c:31        breakpoint already hit 1 time(gdb) cContinuing.result[1-250] = 31125 [Inferior 1 (process 2996651) exited normally](gdb) info breakpointsNum     Type           Disp Enb Address            What1       breakpoint     dis  n   0x00005555555551d7 in main at tst.c:20        breakpoint already hit 1 time2       breakpoint     dis  n   0x0000555555555210 in main at tst.c:30        breakpoint already hit 1 time3       breakpoint     keep y   0x0000555555555228 in main at tst.c:31        breakpoint already hit 1 time(gdb) clear 31(gdb) info breakpointsDeleted breakpoint 3 Num     Type           Disp Enb Address            What1       breakpoint     dis  n   0x00005555555551d7 in main at tst.c:20        breakpoint already hit 1 time2       breakpoint     dis  n   0x0000555555555210 in main at tst.c:30        breakpoint already hit 1 time(gdb) delete breakpoint 1(gdb) info breakpointsNum     Type           Disp Enb Address            What2       breakpoint     dis  n   0x0000555555555210 in main at tst.c:30        breakpoint already hit 1 time(gdb) clearNo breakpoint at this line.(gdb) delete 1-10No breakpoint number 1.No breakpoint number 3.No breakpoint number 4.No breakpoint number 5.No breakpoint number 6.No breakpoint number 7.No breakpoint number 8.No breakpoint number 9.No breakpoint number 10.(gdb) info breakpointsNo breakpoints or watchpoints.\n\n6.4 停止条件维护\ncondition  修改断点号为bnum的停止条件为expression。\ncondition 清除断点号为bnum的停止条件。\nignore  表示忽略断点号为bnum的停止条件count次。\n\n6.5 为停止点设定运行命令为断点号bnum指写一个命令列表。当程序被该断点停住时，gdb会依次运行命令列表中的命令。    commands [bnum]    … command-list …    end\n(gdb) break 23Breakpoint 1 at 0x11ec: file tst.c, line 24.(gdb) commands 1Type commands for breakpoint(s) 1, one per line.End with a line saying just &quot;end&quot;.&gt;printf &quot;mufiye: it is broken at line 23\\n&quot;&gt;end(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main (argc=1, argv=0x7fffffffe148) at tst.c:2424          long result = 0;mufiye: it is broken at line 23\n6.6 断点菜单在C++中，由于函数重载的存在，断点指定函数名可能会有多个函数与之对应。此时如果在该函数设置断点，会弹出菜单让你选择设置断点的具体函数。\n6.7 恢复程序运行和单步调试当程序被停住了，你可以用continue命令恢复程序的运行直到程序结束，或下一个断点到来。也可以使用step或next命令单步跟踪程序。\n\ncontinue [ignore-count]，c [ignore-count]，fg [ignore-count]  恢复程序运行，直到程序结束，或是下一个断点到来。ignore-count表示忽略其后的断点次数。continue，c，fg三个命令都是一样的意思。\nstep   单步跟踪，如果有函数调用，他会进入该函数。进入函数的前提是，此函数被编译有debug信息。很像VC等工具中的step in。后面可以加count也可以不加，不加表示一条条地执行，加表示执行后面的count条指令，然后再停住。\nnext   同样单步跟踪，如果有函数调用，他不会进入该函数。很像VC等工具中的step over。后面可以加count也可以不加，不加表示一条条地执行，加表示执行后面的count条指令，然后再停住。\nset step-mode on打开step-mode模式，于是，在进行单步跟踪时，程序不会因为没有debug信息而不停住。这个参数有很利于查看机器码。\nset step-mod off关闭step-mode模式。\nfinish  运行程序，直到当前函数完成返回。并打印函数返回时的堆栈地址和返回值及参数值等信息。\nuntil 或 u  当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体。\nstepi 或 si，nexti 或 ni  以上两条都是单步跟踪一条机器指令！一条程序代码有可能由数条机器指令完成，stepi和nexti可以单步执行机器指令。与之一样有相同功能的命令是“display&#x2F;i $pc” ，当运行完这个命令后，单步跟踪会在打出程序代码的同时打出机器指令（也就是汇编代码）\n\n一个小lab很好奇next的跳过函数是什么（现在发现这个问题好蠢），next的跳过函数只是把这个函数的运行当作一条语句来处理，实际上还是进入了这个函数。\n......    int sum = 0;    sum = func(10);    printf(&quot;result[1-100] = %d \\n&quot;, result);    printf(&quot;result[1-250] = %d \\n&quot;, func(250));&#125;\n(gdb) break 29Breakpoint 1 at 0x1210: file tst.c, line 30.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main (argc=1, argv=0x7fffffffe148) at tst.c:3030          int sum = 0;(gdb) n31          sum = func(10);(gdb) n32          printf(&quot;result[1-100] = %d \\n&quot;, result);(gdb) print sum$1 = 45\n6.8 信号6.9 线程7. 观察点相关设置观察点\nwatch 为表达式（变量）expr设置一个观察点。一量表达式值有变化时，马上停住程序。\nrwatch 当表达式（变量）expr被读时，停住程序。\nawatch 当表达式（变量）的值被读或被写时，停住程序。\n\n查看观察点\ninfo watchpoints列出当前所设置了的所有观察点。\n\n观察点的实验不知道为什么设置观察点以后continue，程序确实暂停了但是不会跳出gdb命令行让你继续输入命令，在我输入ctrl+z之后才会弹出来（就是其中的^Z之后）。\n(gdb) break 24Breakpoint 1 at 0x11ec: file tst.c, line 24.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main (argc=1, argv=0x7fffffffe148) at tst.c:2424          long result = 0;(gdb) watch i=3Watchpoint 2: i=3(gdb) info watchpointsNum     Type           Disp Enb Address            What2       watchpoint     keep y                      i=3(gdb) cContinuing.^ZProgram received signal SIGTSTP, Stopped (user).main (argc=1, argv=0x7fffffffe148) at tst.c:2727              result += i;(gdb) p i$1 = 3\n8. 设置捕捉点\ncatch 当event发生时，停住程序。\ntcatch 只设置一次捕捉点，当程序停住以后，应点被自动删除。\nevent是什么？1、throw 一个C++抛出的异常。（throw为关键字）2、catch 一个C++捕捉到的异常。（catch为关键字）3、exec 调用系统调用exec时。（exec为关键字，目前此功能只在HP-UX下有用）4、fork 调用系统调用fork时。（fork为关键字，目前此功能只在HP-UX下有用）5、vfork 调用系统调用vfork时。（vfork为关键字，目前此功能只在HP-UX下有用）6、load 或 load  载入共享库（动态链接库）时。（load为关键字，目前此功能只在HP-UX下有用）7、unload 或 unload  卸载共享库（动态链接库）时。（unload为关键字，目前此功能只在HP-UX下有用）\n\n","categories":["操作系统内核"],"tags":["gdb"]},{"title":"gdb入门系列3","url":"/2021/11/24/gdb%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%973/","content":"GDB入门系列3查看栈信息概要\nbacktrace（缩写为bt）打印当前的函数调用栈的所有信息。\nbacktrace   n是一个正整数，表示只打印栈顶上n层的栈信息。\nbacktrace &lt;-n&gt;  -n表一个负整数，表示只打印栈底下n层的栈信息。\nframe   n是一个从0开始的整数，是栈中的层编号。比如：frame 0，表示栈顶，frame 1，表示栈的第二层。\nup   表示向栈的上面移动n层，可以不打n，表示向上移动一层。\ndown   表示向栈的下面移动n层，可以不打n，表示向下移动一层。\n上面的命令，都会打印出移动到的栈层的信息。如果你不想让其打出信息。你可以使用这三个命令：select-frame  对应于 frame 命令，up-silently  对应于 up 命令，down-silently  对应于 down 命令。\nframe 或 f  会打印出这些信息：栈的层编号，当前的函数名，函数参数值，函数所在文件及行号，函数执行到的语句。\ninfo frame  这个命令会打印出更为详细的当前栈层的信息，只不过，大多数都是运行时的内内地址。比如：函数地址，调用函数的地址，被调用函数的地址，目前的函数是由什么样的程序语言写成的、函数参数地址及值、局部变量的地址等等。\ninfo args  打印出当前函数的参数名及其值。\ninfo locals  打印出当前函数中所有局部变量及其值。\ninfo catch  打印出当前的函数中的异常处理信息。\n\n实验(gdb) backtraceNo stack.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst result[1-100] = 5050 result[1-250] = 31125 [Inferior 1 (process 3011899) exited normally](gdb) backtraceNo stack.(gdb) break funcBreakpoint 1 at 0x555555555149: file tst.c, line 4.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, func (n=0) at tst.c:44       &#123;(gdb) bt#0  func (n=0) at tst.c:4#1  0x0000555555555221 in main (argc=1, argv=0x7fffffffe148) at tst.c:31(gdb) bt 1#0  func (n=0) at tst.c:4(More stack frames follow...)(gdb) bt -1#1  0x0000555555555221 in main (argc=1, argv=0x7fffffffe148) at tst.c:31(gdb) bt 2#0  func (n=0) at tst.c:4#1  0x0000555555555221 in main (argc=1, argv=0x7fffffffe148) at tst.c:31(gdb) bt -2#0  func (n=0) at tst.c:4#1  0x0000555555555221 in main (argc=1, argv=0x7fffffffe148) at tst.c:31(gdb) frame 1#1  0x0000555555555221 in main (argc=1, argv=0x7fffffffe148) at tst.c:3131          sum = func(10);(gdb) up 1#1  0x0000555555555221 in main (argc=1, argv=0x7fffffffe148) at tst.c:3131          sum = func(10);(gdb) down 1#0  func (n=0) at tst.c:44       &#123;(gdb) frame#0  func (n=0) at tst.c:44       &#123;(gdb) up 1#1  0x0000555555555221 in main (argc=1, argv=0x7fffffffe148) at tst.c:3131          sum = func(10);(gdb) frame#1  0x0000555555555221 in main (argc=1, argv=0x7fffffffe148) at tst.c:3131          sum = func(10);(gdb) info frameStack level 1, frame at 0x7fffffffe060: rip = 0x555555555221 in main (tst.c:31); saved rip = 0x7ffff7df30b3 caller of frame at 0x7fffffffe020 source language c. Arglist at 0x7fffffffe018, args: argc=1, argv=0x7fffffffe148 Locals at 0x7fffffffe018, Previous frame&#x27;s sp is 0x7fffffffe060 Saved registers:  rbp at 0x7fffffffe050, rip at 0x7fffffffe058(gdb) down 1#0  func (n=0) at tst.c:44       &#123;(gdb) info frameStack level 0, frame at 0x7fffffffe020: rip = 0x555555555149 in func (tst.c:4); saved rip = 0x555555555221 called by frame at 0x7fffffffe060 source language c. Arglist at 0x7fffffffe010, args: n=0 Locals at 0x7fffffffe010, Previous frame&#x27;s sp is 0x7fffffffe020 Saved registers:  rip at 0x7fffffffe018(gdb) info localssum = -8137i = 32767(gdb) info argsn = 0(gdb) info catchUndefined info command: &quot;catch&quot;.  Try &quot;help info&quot;.\n查看源程序显示源代码\nlist   显示程序第linenum行的周围的源程序。\nlist   显示函数名为function的函数的源程序。\nlist  显示当前行后面的源程序。\nlist -  显示当前行前面的源程序。\nset listsize   设置一次显示源代码的行数。\nshow listsize  查看当前listsize的设置。\nlist ,   显示从first行到last行之间的源代码。\nlist ,   显示从当前行到last行之间的源代码。\nlist +  往后显示源代码。\n\n搜索源代码\nforward-search&#x2F;search 从当前行向后查找匹配某个字符串的程序行\nreverse-search 从当前行向后查找匹配某个字符串的程序行\n\n指定源文件的路径某些时候，用-g编译过后的执行程序中只是包括了源文件的名字，没有路径名。GDB提供了可以让你指定源文件的路径的命令，以便GDB进行搜索。\n\ndirectory &lt;dirname … &gt;，dir &lt;dirname … &gt;  加一个源文件路径到当前路径的前面。如果你要指定多个路径，UNIX下你可以使用“:”，Windows下你可以使用“;”。\ndirectory  清除所有的自定义的源文件搜索路径信息。\nshow directories  显示定义了的源文件搜索路径。\n\n源代码的内存\ninfo line可以查看源代码在内存中的地址\ndisassemble指令可以查看源程序的当前执行时的机器码(gdb) break funcBreakpoint 1 at 0x1149: file tst.c, line 4.(gdb) info line tst.c:funcLine 4 of &quot;tst.c&quot; starts at address 0x1149 &lt;func&gt; and ends at 0x1154 &lt;func+11&gt;.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, func (n=0) at tst.c:44       &#123;(gdb) cContinuing.result[1-100] = 5050 Breakpoint 1, func (n=10) at tst.c:44       &#123;(gdb) cContinuing.result[1-250] = 31125 [Inferior 1 (process 3016500) exited normally](gdb) info line tst.c:funcLine 4 of &quot;tst.c&quot; starts at address 0x555555555149 &lt;func&gt; and ends at 0x555555555154 &lt;func+11&gt;.(gdb) disassemble funcDump of assembler code for function func:   0x0000555555555149 &lt;+0&gt;:     endbr64    0x000055555555514d &lt;+4&gt;:     push   %rbp   0x000055555555514e &lt;+5&gt;:     mov    %rsp,%rbp   0x0000555555555151 &lt;+8&gt;:     mov    %edi,-0x14(%rbp)   0x0000555555555154 &lt;+11&gt;:    movl   $0x0,-0x8(%rbp)   0x000055555555515b &lt;+18&gt;:    movl   $0x0,-0x4(%rbp)   0x0000555555555162 &lt;+25&gt;:    jmp    0x55555555516e &lt;func+37&gt;   0x0000555555555164 &lt;+27&gt;:    mov    -0x4(%rbp),%eax   0x0000555555555167 &lt;+30&gt;:    add    %eax,-0x8(%rbp)   0x000055555555516a &lt;+33&gt;:    addl   $0x1,-0x4(%rbp)   0x000055555555516e &lt;+37&gt;:    mov    -0x4(%rbp),%eax--Type &lt;RET&gt; for more, q to quit, c to continue without paging--c   0x0000555555555171 &lt;+40&gt;:    cmp    -0x14(%rbp),%eax   0x0000555555555174 &lt;+43&gt;:    jl     0x555555555164 &lt;func+27&gt;   0x0000555555555176 &lt;+45&gt;:    mov    -0x8(%rbp),%eax   0x0000555555555179 &lt;+48&gt;:    pop    %rbp   0x000055555555517a &lt;+49&gt;:    retq   End of assembler dump.\n\n","categories":["操作系统内核"],"tags":["gdb"]},{"title":"gdb入门系列4","url":"/2021/11/26/gdb%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%974/","content":"GDB入门系列4查看运行时数据在你调试程序时，当程序被停住时，你可以使用print命令（简写命令为p），或是同义命令inspect来查看当前程序的运行数据。print命令的格式是：print &#x2F; 。\n一、表达式    print和许多GDB的命令一样，可以接受一个表达式，GDB会根据当前的程序运行的数据来计算这个表达式，既然是表达式，那么就可以是当前程序运行中的const常量、变量、函数等内容。可惜的是GDB不能使用你在程序中所定义的宏。表达式的语法应该是当前所调试的语言的语法。\n\n二、程序变量    如果你的程序编译时开启了优化选项，那么在用GDB调试被优化过的程序时，可能会发生某些变量不能访问，或是取值错误码的情况。这个是很正常的，因为优化程序会删改你的程序，整理你程序的语句顺序，剔除一些无意义的变量等，所以在GDB调试这种程序时，运行时的指令和你所编写指令就有不一样，也就会出现你所想象不到的结果。对付这种情况时，需要在编译程序时关闭编译优化。一般来说，几乎所有的编译器都支持编译优化的开关，例如，GNU的C/C++编译器GCC，你可以使用“-gstabs”选项来解决这个问题。关于编译器的参数，还请查看编译器的使用说明文档。\n\n三、数组    有时候，你需要查看一段连续的内存空间的值。比如数组的一段，或是动态分配的数据的大小。你可以使用GDB的“@”操作符，“@”的左边是第一个内存的地址的值，“@”的右边则你你想查看内存的长度。\n\n    @的左边是数组的首地址的值，也就是变量array所指向的内容，右边则是数据的长度，其保存在变量len中。\n\nrun(gdb) p *array@len$1 = &#123;2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40&#125;\n四、输出格式\nx  按十六进制格式显示变量。\nd  按十进制格式显示变量。\nu  按十六进制格式显示无符号整型。\no  按八进制格式显示变量。\nt  按二进制格式显示变量。\na  按十六进制格式显示变量。\nc  按字符格式显示变量。\nf  按浮点数格式显示变量。run(gdb) p i$21 = 101          (gdb) p/a i$22 = 0x65       (gdb) p/c i$23 = 101 &#x27;e&#x27;       (gdb) p/f i$24 = 1.41531145e-43       (gdb) p/x i$25 = 0x65       (gdb) p/t i$26 = 1100101\n\n五、查看内存你可以使用examine命令（简写是x）来查看内存地址中的值。x命令的语法如下所示：x&#x2F;&lt;n&#x2F;f&#x2F;u&gt; \n\nn、f、u是可选的参数。\nn 是一个正整数，表示显示内存的长度，也就是说从当前地址向后显示几个地址的内容。\nf 表示显示的格式，参见上面。如果地址所指的是字符串，那么格式可以是s，如果地十是指令地址，那么格式可以是i。\nu 表示从当前地址往后请求的字节数，如果不指定的话，GDB默认是4个bytes。u参数可以用下面的字符来代替，b表示单字节，h表示双字节，w表示四字节，g表示八字节。当我们指定了字节长度后，GDB会从指内存定的内存地址开始，读写指定字节，并把其当作一个值取出来。\n表示一个内存地址。x/3uh 0x54320 表示，从内存地址0x54320读取内容，h表示以双字节为一个单位，3表示三个单位，u表示按十六进制显示。\n\n六、自动显示你可以设置一些自动显示的变量，当程序停住时，或是在你单步跟踪时，这些变量会自动显示。相关的GDB命令是display。\n\ndisplay&#x2F; ，display&#x2F;   expr是一个表达式，fmt表示显示的格式，addr表示内存地址，当你用display设定好了一个或多个表达式后，只要你的程序被停下来，GDB会自动显示你所设置的这些表达式的值。\nundisplay &lt;dnums…&gt;，delete display &lt;dnums…&gt;  删除自动显示，dnums意为所设置好了的自动显式的编号。如果要同时删除几个，编号可以用空格分隔，如果要删除一个范围内的编号，可以用减号表示（如：2-5）\ndisable display &lt;dnums…&gt;  使自动显示失效\nenable display &lt;dnums…&gt;  激活自动显示\ninfo display  查看display设置的自动显示的信息\n\nLab(gdb) break 24Breakpoint 1 at 0x11ec: file tst.c, line 24.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main (argc=1, argv=0x7fffffffe148) at tst.c:2424          long result = 0;(gdb) display i1: i = 21845(gdb) n25          for (i = 1; i &lt;= 100; i++)1: i = 21845(gdb) n27              result += i;1: i = 1(gdb) n25          for (i = 1; i &lt;= 100; i++)1: i = 1(gdb) n27              result += i;1: i = 2(gdb) n25          for (i = 1; i &lt;= 100; i++)1: i = 2(gdb) n27              result += i;1: i = 3(gdb) n25          for (i = 1; i &lt;= 100; i++)1: i = 3(gdb) n27              result += i;1: i = 4(gdb) n25          for (i = 1; i &lt;= 100; i++)1: i = 4\n七、设置显示选项没看\n八、历史记录    当你用GDB的print查看程序运行时的数据时，你每一个print都会被GDB记录下来。GDB会以$1, $2, $3 .....这样的方式为你每一个print命令编上号。于是，你可以使用这个编号访问以前的表达式，如$1。这个功能所带来的好处是，如果你先前输入了一个比较长的表达式，如果你还想查看这个表达式的值，你可以使用历史记录来访问，省去了重复输入。\n\n(gdb) break 26Breakpoint 1 at 0x1269: file tst.c, line 26.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main (argc=1, argv=0x7fffffffe148) at tst.c:2626          for(int k=0;k&lt;10;k++) (gdb) p *arr$1 = 0(gdb) p arr$2 = &#123;0, 11, 22, 33, 44, 55, 66, 77, 88, 99&#125;(gdb) p j$3 = 3(gdb) p i$4 = -8137(gdb) p result$5 = 0(gdb) p argc$6 = 1(gdb) show convenience$bpnum = 1$_gdb_minor = 2$_gdb_major = 9$_as_string = &lt;internal function _as_string&gt;$_regex = &lt;internal function _regex&gt;$_streq = &lt;internal function _streq&gt;$_strlen = &lt;internal function _strlen&gt;$_memeq = &lt;internal function _memeq&gt;$_any_caller_matches = &lt;internal function _any_caller_matches&gt;$_any_caller_is = &lt;internal function _any_caller_is&gt;$_caller_matches = &lt;internal function _caller_matches&gt;$_caller_is = &lt;internal function _caller_is&gt;--Type &lt;RET&gt; for more, q to quit, c to continue without paging--qQuit(gdb) p $1$7 = 0(gdb) set $1 = 11Left operand of assignment is not a modifiable lvalue.(gdb) p $1$8 = 0(gdb) cContinuing.result[1-100] = 5050 result[1-250] = 31125 [Inferior 1 (process 3039503) exited normally](gdb) p iNo symbol &quot;i&quot; in current context.(gdb) p $4$9 = -8137\n\n上面的实验说明，单纯的就是历史记录，而且该历史记录无法被修改（上面尝试赋值，但是提示Left operand of assignment is not a modifiable lvalue.），就算当初print的变量已经被销毁了，这条历史记录还是存在的，并且可以被打印出来。\n九、GDB环境变量    你可以在GDB的调试环境中定义自己的变量，用来保存一些调试程序中的运行数据。要定义一个GDB的变量很简单只需。使用GDB的set命令。GDB的环境变量和UNIX一样，也是以$起头。如：\n    set $foo = *object_ptr\n    使用环境变量时，GDB会在你第一次使用时创建这个变量，而在以后的使用中，则直接对其賦值。环境变量没有类型，你可以给环境变量定义任一的类型。包括结构体和数组。\n\nLab1(gdb) set $k = 0(gdb) break 21Breakpoint 1 at 0x124c: file tst.c, line 21.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main (argc=1, argv=0x7fffffffe148) at tst.c:2121          j = 1;(gdb) print arr[$k++]$1 = 0(gdb) $2 = 11(gdb) $3 = 22(gdb) $4 = 33(gdb) $5 = 44(gdb) $6 = 55(gdb) $7 = 66(gdb) $8 = 77(gdb) $9 = 88(gdb) $10 = 99(gdb) show convenience$bpnum = 1$k = 10$_gdb_minor = 2$_gdb_major = 9$_as_string = &lt;internal function _as_string&gt;$_regex = &lt;internal function _regex&gt;$_streq = &lt;internal function _streq&gt;$_strlen = &lt;internal function _strlen&gt;$_memeq = &lt;internal function _memeq&gt;$_any_caller_matches = &lt;internal function _any_caller_matches&gt;$_any_caller_is = &lt;internal function _any_caller_is&gt;$_caller_matches = &lt;internal function _caller_matches&gt;--Type &lt;RET&gt; for more, q to quit, c to continue without paging--\nLab2之前是对环境变量传了一个值，那么如果对环境变量传了一个指针会怎么样？\n(gdb) break 20Breakpoint 1 at 0x1245: file tst.c, line 20.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main (argc=1, argv=0x7fffffffe148) at tst.c:2020          int j=0;(gdb) set $ptr = arr(gdb) show convenience$ptr = (int *) 0x7fffffffe020$bpnum = 1$_gdb_minor = 2$_gdb_major = 9......(gdb) print *($num)Attempt to take contents of a non-pointer value.\n结论是可以赋值，就是赋值了一个地址。\n十、查看寄存器\ninfo registers  查看寄存器的情况。（除了浮点寄存器）\ninfo all-registers  查看所有寄存器的情况。（包括浮点寄存器）\ninfo registers &lt;regname …&gt;  查看所指定的寄存器的情况。\n\n","categories":["操作系统内核"],"tags":["gdb"]},{"title":"gdb入门系列5","url":"/2021/11/28/gdb%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%975/","content":"GDB入门系列5改变程序的执行一旦使用GDB挂上被调试程序，当程序运行起来后，你可以根据自己的调试思路来动态地在GDB中更改当前被调试程序的运行线路或是其变量的值，这个强大的功能能够让你更好的调试你的程序，比如，你可以在程序的一次运行中走遍程序的所有分支。\n一、修改变量值\nwhatis       打印该变量的类型\nset var &#x3D;47      设置该变量的值\n\nLab增加的代码：\nint val = 0;if(val == 0)&#123;    printf(&quot;go in the val0 case\\n&quot;);&#125;else if(val == 1)&#123;    printf(&quot;changed, go in the val1 case\\n&quot;);&#125;\n\ngdb调试：\n(gdb) break 27Breakpoint 1 at 0x1290: file tst.c, line 27.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main (argc=1, argv=0x7fffffffe148) at tst.c:2727          if(val == 0)&#123;(gdb) whatis valtype = int(gdb) set var val = 1(gdb) cContinuing.changed, go in the val1 caseresult[1-100] = 5050 result[1-250] = 31125 [Inferior 1 (process 3045980) exited normally]\n\n二、跳转执行\njump \n      指定下一条语句的运行点。&lt;linespce&gt;可以是文件的行号，可以是file:line格式，可以是+num这种偏移量格式。表式着下一条运行语句从哪里开始\n\n\njump \n      这里的&lt;address&gt;是代码行的内存地址。\n\n\nset $pc &#x3D; 0x485      熟悉汇编的人都知道，程序运行时，有一个寄存器用于保存当前代码所在的内存地址。所以，jump命令也就是改变了这个寄存器中的值。于是，你可以使用“set $pc”来更改跳转执行的地址。\n\n\nLab(gdb) break 25Breakpoint 1 at 0x1283: file tst.c, line 25.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main (argc=1, argv=0x7fffffffe148) at tst.c:2525          j++;(gdb) jump 27Continuing at 0x55555555528b.j is: 1go in the val0 caseresult[1-100] = 5050 result[1-250] = 31125 [Inferior 1 (process 3048823) exited normally]\n\n三、产生信号量\n    signal &lt;singal&gt;\n    使用singal命令，可以产生一个信号量给被调试的程序。如：中断信号Ctrl+C。这非常方便于程序的调试，可以在程序运行的任意位置设置断点，并在该断点用GDB产生一个信号量，这种精确地在某处产生信号非常有利程序的调试。UNIX的系统信号量通常从1到15。所以&lt;singal&gt;取值也在这个范围。\n\n\n\n四、强制函数返回\nreturn       如果你的调试断点在某个函数中，并还有语句没有执行完。你可以使用return命令强制函数忽略还没有执行的语句并返回。使用return命令取消当前函数的执行，并立即返回，如果指定了，那么该表达式的值会被认作函数的返回值。\n\nLab(gdb) break funcBreakpoint 1 at 0x1189: file tst.c, line 4.(gdb) rStarting program: /home/ubuntu/learn_gdb/tst go in the val0 caseresult[1-100] = 5050 Breakpoint 1, func (n=32767) at tst.c:44       &#123;(gdb) s5           int sum = 0, i;(gdb) s6           for (i = 0; i &lt; n; i++)(gdb) s8               sum += i;(gdb) s6           for (i = 0; i &lt; n; i++)(gdb) s8               sum += i;(gdb) s6           for (i = 0; i &lt; n; i++)(gdb) s8               sum += i;(gdb) s6           for (i = 0; i &lt; n; i++)(gdb) return 11Make func return now? (y or n) y#0  0x0000555555555316 in main (argc=1, argv=0x7fffffffe148) at tst.c:4444          printf(&quot;result[1-250] = %d \\n&quot;, func(250));(gdb) cContinuing.result[1-250] = 11 [Inferior 1 (process 3047076) exited normally]\n\n五、强制调用函数\n    call &lt;expr&gt;\n    表达式中可以一是函数，以此达到强制调用函数的目的。并显示函数的返回值，如果函数返回值是void，那么就不显示。\n    另一个相似的命令也可以完成这一功能——print，print后面可以跟表达式，所以也可以用他来调用函数，print和call的不同是，如果函数返回void，call则不显示，print则显示函数返回值，并把该值存入历史数据中。\n\n\n\nWhat’s Next\ngdb官方文档\ngdb user manual\ngdb internals manual\n\n","categories":["操作系统内核"],"tags":["gdb"]},{"title":"gdb牛刀小试","url":"/2021/11/21/gdb%E7%89%9B%E5%88%80%E5%B0%8F%E8%AF%95/","content":"gdb牛刀小试写在前面最近时间很多，我在努力做MIT6.S081这门课的Lab，但是经常会遇到一些让我难以理解并且无从入手的bug，因此愈加萌发了学习gdb的想法。也试着去看gdb的官方文档，但是那个pdf足足有将近900页，总感觉这样看书对于一个新手不是高效的学习方法（当然对于已经使用过一段时间gdb的程序员来说，平时抽点时间细水长流地去看官方文档肯定是很棒的），因此想要找一个好点的教程，带我入门gdb，于是翻到了大佬写的教程（真的很古早，2003年，我当时看到发表时间人懵了）。本文一是想记录一下自己的学习过程，二也是想做个教程上的翻新（可能教程太早，gdb也发生了一些变化）。\n测试代码#include &lt;stdio.h&gt;int func(int n)&#123;    int sum = 0, i;    for (i = 0; i &lt; n; i++)    &#123;        sum += i;    &#125;    return sum;&#125;main()&#123;    //new added    int j=0;    j = 1;    j = 2;    j = 3;    int i;    long result = 0;    for (i = 1; i &lt;= 100; i++)    &#123;        result += i;    &#125;    printf(&quot;result[1-100] = %d /n&quot;, result);    printf(&quot;result[1-250] = %d /n&quot;, func(250));&#125;\n\ngdb调试\n首先编译代码生成可执行文件（一定要加-g参数，这样才能把调试信息加到可执行文件中）\n\ncc -g tst.c -o tst\n\n\n然后启动gdb（$后为bash命令）\n\nubuntu@VM-0-14-ubuntu:~/learn_gdb$gdb......--Type &lt;RET&gt; for more, q to quit, c to continue without paging--c\n\n\n之后会跳出一大段关于gdb的描述，并问你是否继续，继续就输入c，退出就输入q\n进入我们想要调试的文件，注意是可执行文件，所以不需要带上文件后缀类型名（gdb后为输入的命令）\n\n(gdb) file tstReading symbols from tst...\n\n\n输入l命令查看源代码（一次默认显示10行，想看更多就按回车）\n\n(gdb) l   \n\n\n设置断点（设置两个断点，第一个设置在第16行，第二个设置在函数func的入口处）\n(gdb) break 16Breakpoint 1 at 0x1187: file tst.c, line 16.\n(gdb) break funcBreakpoint 2 at 0x1149: file tst.c, line 4.\n查看断点的信息\n(gdb) info break   Num     Type           Disp Enb Address            What1       breakpoint     keep y   0x0000000000001187 in main at tst.c:162       breakpoint     keep y   0x0000000000001149 in func at tst.c:4\n\n运行代码（r为run的缩写）\n(gdb) rStarting program: /home/ubuntu/learn_gdb/tst Breakpoint 1, main () at tst.c:1616          int j=0;\n执行单条语句（n为next的缩写）\n(gdb) n17          j = 1;(gdb) n18          j = 2;(gdb) n19          j = 3;\n\n继续运行程序（c为continue的缩写），这时发现程序运行到了第二个断点处\n(gdb) cContinuing.Breakpoint 2, func (n=21845) at tst.c:44       &#123;\n继续单步执行程序\n(gdb) n5           int sum = 0, i;(gdb) n6           for (i = 0; i &lt; n; i++)(gdb) n8               sum += i;\n打印一些变量的信息（p为print的缩写）\n(gdb) p i$1 = 0(gdb) p sum$2 = 0\n继续单步执行程序\n(gdb) n6           for (i = 0; i &lt; n; i++)(gdb) n8               sum += i;\n再查看一下变量的信息\n(gdb) p i$3 = 1(gdb) p sum$4 = 0\n查看函数栈\n(gdb) bt#0  func (n=250) at tst.c:8#1  0x00005555555551e9 in main () at tst.c:28\n退出当前的函数（也就是func函数）\n(gdb) finishRun till exit from #0  func (n=250) at tst.c:80x00005555555551e9 in main () at tst.c:2828          printf(&quot;result[1-250] = %d /n&quot;, func(250));Value returned is $5 = 31125\n继续运行程序（可以发现程序正常退出了）\n(gdb) cContinuing.result[1-100] = 5050 /nresult[1-250] = 31125 /n[Inferior 1 (process 2973774) exited normally]\n退出gdb调试\n(gdb) q\n\n一些疑问以及自己的解答\nbreak断点的设置是断在一个语句的之前还是之后的？（比如break 16，这个第16行的语句是执行了没有呢？）Answer：break断点的设置是断在一个语句之前的。也就是说第16行语句是没有执行的（可以通过print相关的变量验证）。\n\n参考大佬的gdb调试程序（一）\n","categories":["操作系统内核"],"tags":["gdb"]},{"title":"nfs环境搭建","url":"/2022/05/31/nfs%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","content":"nfs环境搭建我启动两台qemu虚拟机（linux kernel），一台作为服务器端，一台作为客户端搭建了NFS环境，并尝试进行了使用。\n\n在服务器端和客户端操作：安装nfs-server包（同时包括了客户端软件和服务器端软件）\napt-get install nfs-kernel-server -y\n\n编辑服务器端的&#x2F;etc&#x2F;exports配置文件\n# vim /etc/exports,加入以下内容/tmp/ *(rw,no_root_squash,fsid=0)/tmp/s_test/ *(rw,no_root_squash,fsid=1)\n\n在服务器端操作：将设备格式化为特定的文件系统格式\nmkfs.ext4 -b 4096 -F /dev/sda\n\n在服务器端操作：创建共享文件夹\nmkdir /tmp/s_test\n\n在服务器端操作：挂载文件系统\nmount -t ext4 /dev/sda /tmp/s_test\n\n在服务器端操作：设置最多可以打开的文件描述符数量\nulimit -n 65535\n\n在服务器端操作：重新共享所有目录（它使  &#x2F;var&#x2F;lib&#x2F;nfs&#x2F;xtab  和 &#x2F;etc&#x2F;exports 同步。 它將 &#x2F;etc&#x2F;exports中已删除的条目从 &#x2F;var&#x2F;lib&#x2F;nfs&#x2F;xtab 中删除，將内核共享表中任何不再有效的条目移除）\nexportfs -r\n\n在服务器端操作：关闭防火墙\nsystemctl stop firewalldsetenforce 0\n\n在服务器端操作：重启服务\nsystemctl restart nfs-server.servicesystemctl restart rpcbind\n\n在服务器端操作：修改文件操作权限，使三种用户都具有对该文件夹的可读可写可执行权限\nchmod 777 /tmp/s_test\n\n在客户端操作：挂载nfs文件系统\n# ip地址用ifconfig查看，如果提示没有这个命令使用sudo apt install net-tools安装相应软件包# nfsv4mount -t nfs -o v4.1 192.168.122.210:/s_test /mnt# nfsv3 要写完整的源路径mount -t nfs -o v3 192.168.122.210:/tmp/s_test /mnt# nfsv2, nfs server 需要修改 /etc/nfs.conf, [nfsd] vers2=ymount -t nfs -o v2 192.168.122.210:/tmp/s_test /mnt\n\n","categories":["操作系统内核"],"tags":["环境搭建","文件系统","nfs"]},{"title":"n皇后问题","url":"/2021/05/13/n%E7%9A%87%E5%90%8E%E9%97%AE%E9%A2%98/","content":"n皇后问题一、问题介绍n皇后问题借鉴了国际象棋中皇后的概念，此处我先介绍一下这里的皇后指的是什么。在国际象棋中，在一个棋盘上，皇后可以横着走、竖着走和斜着走。而n皇后问题指的就是，假设有n个皇后，在一张n*n的棋盘上，如何将这些皇后放在这张棋盘上，是这些皇后彼此不在对方的打击范围内，也就是怎么样放才能使她们都是安全的。\n二、算法在本文中，我将使用回溯算法来解决这个问题。回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。用回溯算法解决问题的一般步骤一是针对所给问题，定义问题的解空间，二是确定易于搜索的解空间结构,使得能用回溯法方便地搜索整个解空间，三是以深度优先的方式搜索解空间，并且在搜索过程中用剪枝函数避免无效搜索。\n针对n皇后问题，我们可以将棋盘表示为一个n行n列的矩阵，我们将这个矩阵初始化为一个全0的矩阵，假如这个棋盘的i行j列放了一个皇后，我们就将这个矩阵的i行j列的值设置为1。由题设，我们易知每一行有且只有一个皇后，我们可以用一个树的结构来表示整个搜索过程，因此我们可以将每一层树定义为将每一行的皇后放入棋盘中的某一列。之后我们进行深度优先搜索，如果某一次将皇后放入棋盘导致一些皇后不安全，那么我们就把这一次放置的情况作为根的树剪掉，并且回溯到之前的放法，直到遍历完整颗树。\n三、代码实现为了节省资源，我发现不用使用空间复杂度过大的矩阵而使用向量也能够表示将皇后放在棋盘的某个位置并完成搜索。因为为了保证每个皇后的安全，每一行有且只有一个皇后，那么我们可以用向量的第一个元素表示第一行的皇后放在哪一列，第二个元素表示第二行的皇后放在哪一列，第n个元素表示第n行的皇后放在哪一列。\n在具体的代码中，我使用了递归函数solveNQ来实现搜索，使用is_safe来判断放入某个皇后是否会导致某些皇后不安全，最后我定义了一个findAllNQ函数来实现保证搜索完了整一棵树，得到所有的解。以下为具体的代码及测试结果：\n代码：\ndef findAllNQ(n,solution):    row=1    vector=[0 for i in range(n)]    solveNQ(vector.copy(),row,solution)        def solveNQ(vector,row,solution):    index=row-1    if row&gt;len(vector):        solution.append(vector.copy())        return False    for col in range(1,len(vector)+1):        if is_safe(vector,row,col):            vector[index]=col            if solveNQ(vector,row+1,solution):                return True            else:                vector[index]=0    return False            def is_safe(vector,row,col):    for i in range(row-1):        if col==vector[i]:            return False    for i in range(row-1):       if (vector[i]+i+1)==(col+row):#左斜，和相等          return False       if abs(i+1-row)==abs(vector[i]-col):#右斜，差相等          return False    return True\n\n测试1：\nsolution=[]n=4findAllNQ(n,solution)print(&quot;-------------------------&quot;)print(&quot;the solutions are:&quot;)for i in solution:     print(i)print(&quot;the total number of the solutions is &#123;&#125;&quot;.format(len(solution)))\n\n结果1：\n-------------------------the solutions are:[2, 4, 1, 3][3, 1, 4, 2]the total number of the solutions is 2\n\n测试2：\nsolution=[]n=8findAllNQ(n,solution)print(&quot;-------------------------&quot;)print(&quot;the solutions are:&quot;)for i in solution:     print(i)print(&quot;the total number of the solutions is &#123;&#125;&quot;.format(len(solution)))\n\n结果2：\n-------------------------the solutions are:[1, 5, 8, 6, 3, 7, 2, 4][1, 6, 8, 3, 7, 4, 2, 5][1, 7, 4, 6, 8, 2, 5, 3][1, 7, 5, 8, 2, 4, 6, 3][2, 4, 6, 8, 3, 1, 7, 5][2, 5, 7, 1, 3, 8, 6, 4][2, 5, 7, 4, 1, 8, 6, 3][2, 6, 1, 7, 4, 8, 3, 5][2, 6, 8, 3, 1, 4, 7, 5][2, 7, 3, 6, 8, 5, 1, 4][2, 7, 5, 8, 1, 4, 6, 3][2, 8, 6, 1, 3, 5, 7, 4][3, 1, 7, 5, 8, 2, 4, 6][3, 5, 2, 8, 1, 7, 4, 6][3, 5, 2, 8, 6, 4, 7, 1][3, 5, 7, 1, 4, 2, 8, 6][3, 5, 8, 4, 1, 7, 2, 6][3, 6, 2, 5, 8, 1, 7, 4][3, 6, 2, 7, 1, 4, 8, 5][3, 6, 2, 7, 5, 1, 8, 4][3, 6, 4, 1, 8, 5, 7, 2][3, 6, 4, 2, 8, 5, 7, 1][3, 6, 8, 1, 4, 7, 5, 2][3, 6, 8, 1, 5, 7, 2, 4][3, 6, 8, 2, 4, 1, 7, 5][3, 7, 2, 8, 5, 1, 4, 6][3, 7, 2, 8, 6, 4, 1, 5][3, 8, 4, 7, 1, 6, 2, 5][4, 1, 5, 8, 2, 7, 3, 6][4, 1, 5, 8, 6, 3, 7, 2][4, 2, 5, 8, 6, 1, 3, 7][4, 2, 7, 3, 6, 8, 1, 5][4, 2, 7, 3, 6, 8, 5, 1][4, 2, 7, 5, 1, 8, 6, 3][4, 2, 8, 5, 7, 1, 3, 6][4, 2, 8, 6, 1, 3, 5, 7][4, 6, 1, 5, 2, 8, 3, 7][4, 6, 8, 2, 7, 1, 3, 5][4, 6, 8, 3, 1, 7, 5, 2][4, 7, 1, 8, 5, 2, 6, 3][4, 7, 3, 8, 2, 5, 1, 6][4, 7, 5, 2, 6, 1, 3, 8][4, 7, 5, 3, 1, 6, 8, 2][4, 8, 1, 3, 6, 2, 7, 5][4, 8, 1, 5, 7, 2, 6, 3][4, 8, 5, 3, 1, 7, 2, 6][5, 1, 4, 6, 8, 2, 7, 3][5, 1, 8, 4, 2, 7, 3, 6][5, 1, 8, 6, 3, 7, 2, 4][5, 2, 4, 6, 8, 3, 1, 7][5, 2, 4, 7, 3, 8, 6, 1][5, 2, 6, 1, 7, 4, 8, 3][5, 2, 8, 1, 4, 7, 3, 6][5, 3, 1, 6, 8, 2, 4, 7][5, 3, 1, 7, 2, 8, 6, 4][5, 3, 8, 4, 7, 1, 6, 2][5, 7, 1, 3, 8, 6, 4, 2][5, 7, 1, 4, 2, 8, 6, 3][5, 7, 2, 4, 8, 1, 3, 6][5, 7, 2, 6, 3, 1, 4, 8][5, 7, 2, 6, 3, 1, 8, 4][5, 7, 4, 1, 3, 8, 6, 2][5, 8, 4, 1, 3, 6, 2, 7][5, 8, 4, 1, 7, 2, 6, 3][6, 1, 5, 2, 8, 3, 7, 4][6, 2, 7, 1, 3, 5, 8, 4][6, 2, 7, 1, 4, 8, 5, 3][6, 3, 1, 7, 5, 8, 2, 4][6, 3, 1, 8, 4, 2, 7, 5][6, 3, 1, 8, 5, 2, 4, 7][6, 3, 5, 7, 1, 4, 2, 8][6, 3, 5, 8, 1, 4, 2, 7][6, 3, 7, 2, 4, 8, 1, 5][6, 3, 7, 2, 8, 5, 1, 4][6, 3, 7, 4, 1, 8, 2, 5][6, 4, 1, 5, 8, 2, 7, 3][6, 4, 2, 8, 5, 7, 1, 3][6, 4, 7, 1, 3, 5, 2, 8][6, 4, 7, 1, 8, 2, 5, 3][6, 8, 2, 4, 1, 7, 5, 3][7, 1, 3, 8, 6, 4, 2, 5][7, 2, 4, 1, 8, 5, 3, 6][7, 2, 6, 3, 1, 4, 8, 5][7, 3, 1, 6, 8, 5, 2, 4][7, 3, 8, 2, 5, 1, 6, 4][7, 4, 2, 5, 8, 1, 3, 6][7, 4, 2, 8, 6, 1, 3, 5][7, 5, 3, 1, 6, 8, 2, 4][8, 2, 4, 1, 7, 5, 3, 6][8, 2, 5, 3, 1, 7, 4, 6][8, 3, 1, 6, 2, 5, 7, 4][8, 4, 1, 3, 6, 2, 7, 5]the total number of the solutions is 92\n\n四、结论在本文中，我成功使用回溯算法解决了n皇后问题，回溯算法作为一种特殊的穷举算法，使用深度优先搜索和剪枝大大降低了算法复杂度，而在解决n皇后问题时，使用向量代替矩阵来表示解空间又大大降低了解决该问题的算法复杂度。\n","categories":["算法"],"tags":["n皇后","回溯算法"]},{"title":"skywalking-agent-tracer-api设计文档","url":"/2023/01/26/skywalking-agent-tracer-api%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/","content":"Skywalking-Agent-Tracer-API设计文档相关的issue\n已经被merge的pull request\n一、前景提要SkyWalking Java是一个强大的、实现完善的agent，其通过改变需要监控软件的字节码，在其中插桩来收集metric、trace、log以及event这四种监控数据的代码，并支持发送到各种各样的oap，比如skywalking原生的oap。对于skywalking-agent，一开始人们常常选择使用其支持的各种各样的自动插桩（比如对于spring、dubbo、rocketmq等等），但是随着其被越来越多的人使用，很多用户想要使用其来进行手动的插桩，即通过调用api的方式在其想要的问题收集数据。在过去我们支持使用opentracing的api，但是考虑到opentracing现在已经合并到了OpenTelemetry中去了，我们考虑构建属于skywalking自己的trace api。对于skywalking的trace指标，主要涉及到下面几种功能：\n\n创建span\n\n对于rpc tracing上下文信息的注入和提取\n\n捕捉和提取跨线程tracing的上下文\n\n为当前的span输入tag和log信息（tag是一个键值对，log是日志信息）\n\n跨线程span的异步准备和完成（类似于操作系统中wait和notify）\n\n\n二、设计方案2.1 遗弃的设计方案（基于注解的）\n对于span的创建，使用注解@LocalSpan, @EntrySpan, @ExitSpan来进行标注\n\n对于rpc tracing上下文信息的注入和提取，基于注解，使用某些方式去传递contextCarrier（也就是上下文信息）\n\n对于捕捉和提取跨线程tracing的上下文，定义capture() and continued()这两个api\n\n对于tag和log的功能，为span定义log()和tag()这两个api\n\n对于异步准备&#x2F;完成，使用prepareForAsync()和asyncFinish()\n\n\n遗弃原因：不希望基于注解，基于注解实现过于困难\n2.2 实行的设计方案（之后略有改动）\nSpan creating\npublic class TracerManager&#123;    public static void createEntrySpan(String operationName, Object message)&#123;&#125;    public static void createLocalSpan(String operationName)&#123;&#125;    public static void createExitSpan(String operationName, Object message, String remotePeer)&#123;&#125;    public static void createExitSpan(String operationName, String remotePeer)&#123;&#125;    public static void stopSpan()&#123;&#125;&#125;\n\nInject&#x2F;extract for RPC tracing\n// Question: how to pass the ContextCarrier// Answer: use message to encapsulate the ContextCarrierpublic class TracerManager&#123;    ...    public static void inject(Object message)&#123;&#125;    public static void extract(Object message)&#123;&#125;&#125;\n\nCapture&#x2F;continue for continue tracing context in the x-thread tracing\npublic class TracerManager&#123;    ...    public static ContextSnapshot capture()&#123;&#125;    public static void continued(ContextSnapshot snapshot)&#123;&#125;&#125;\n\nTag and log for the current span\npublic class CurrentSpan&#123;    public static void log(Throwable t)&#123;&#125;    public static void log(Map&lt;String, ?&gt; event)&#123;&#125;    public static void tag(String key, String value)&#123;&#125;    public static void tag(AbstractTag&lt;?&gt; tag, String value)&#123;&#125;&#125;\n\nAsync prepare&#x2F;finish for span crossing threads\npublic class newAsyncSpan&#123;    ...    public newAsyncSpan prepareForAsync();     public newAsyncSpan asyncFinish();&#125;\n\n2.3 方案的主要改进点使用一个指向span的引用来代替CurrentSpan这个类，这样就不用每次都调用activeSpan这个方法了。\n三、API介绍官方文档就是我写的，这里也就简单做个分类然后直接引用了。\n\n引入Tracer API的依赖\n\n使用Tracer API，这里包含了上面提到的五种功能\n\nTracing APIs目录下剩余的文档都是老的api介绍\n\nRead Tracing Context\nAnnotations\nUsing Correlation Context\nAcross Thread Solution\n\n\n\n","categories":["可观测"],"tags":["开源","api设计","tracer","skywalking"]},{"title":"skywalking监控airflow功能的设计文档","url":"/2023/03/03/skywalking%E7%9B%91%E6%8E%A7airflow%E5%8A%9F%E8%83%BD%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/","content":"Skywalking监控airflow相关的issue\n相关的pull request：\n\n适配累加类型为delta的Sum metric\n\n适配OpenTelemetry的Exponential Histogram\n\n\n一、前景提要apache airflow是一个流行的workflow调度程序，目前skywalking还不支持监控airflow，但是这一块是被期待实现的。airflow通过statsd来暴露自己的metrics，而skywalking oap想要监控airflow的话，本质就是要拿到airflow的metric数据并且进行对数据进行再处理和展示。\n二、Airflow Concepts更多详细的介绍可以查看airflow官方文档\n\nDAG：dag指的是有向无环图，它指定了任务之间的依赖关系，其决定了任务执行和运行重试的顺序。\nTask: 任务是airflow的基本执行单元。Task通过DAG进行分配，然后它们之间存在上下游的依赖关系，这表示了它们的执行顺序。\nScheduler：它处理触发预定的工作流，并提交任务到执行程序运行。\nExecutor: 其处理正在运行的任务。如果是默认的airflow配置，其将运行调度程序中所有内容，但大多数适合生产的执行程序实际上将任务执行推给workers。执行器是运行任务实例的机制。\n\n\n三、实现方案3.1 数据获取apache airflow定义的metrics使用的statsd的数据格式，而skywalking oap并不支持接收statsd格式的数据。不过openTelemetry collector的非官方版本支持接收statsd的数据格式，并且我们的skywalking oap支持接收opentelemetry的protocol，因此这一条数据接收链路就成功的建立了。\n但是目前仍存在几个问题：\n问题一：apache airflow定义的metrics没有tag这个概念在skywalking oap接收metrics数据进行处理的过程中，主要是根据metrics的tag来进行过滤、聚合等操作，对于metric的name没有办法进行过滤和聚合；而airflow将所有的tag都放在了metric的name中，这使得skywalking oap拿到airflow传来的metric数据无法进行处理。由于修改meter analyzer过于复杂，我们将目光聚焦到了otel collector上面，我们希望能够在otel collector端将数据转化为skywalking oap能够处理的形式。\nOpenTelemetry Collector能够接收各种形式的数据并将它们转化为各种形式的数据发送出去，其由三个模块组成，分别为collector、transformer和exporter，要对收集到的数据进行处理，我们需要查阅transformer的功能。我们尝试使用metrics transform processor, transform processor and attributes processor对收集到的数据进行处理，经过阅读文档和测试，我们发现通过set函数将metric name值设置为某个标签的值，之后对于标签的key使用replace_pattern函数剔除无用的字符，通过这种方式将metric name中的属性放入到tag中去，比如dag_id，task_id。同时对于sum和gauge类型的数据，combine函数可以自动将metric name中的一些属性变为标签。\n问题二：对于聚合类型为delta的Sum metric，skywalking oap无法处理在这里我解释一下Sum metric，更多信息也可以查阅promethus counter metric文档和opentelemetry sum metric文档。简单来说，sum就是表示从某个时间点开始某个事件的累加和，在promethus的定义中，sum只增加不减少，而根据聚合类型，sum metric又可以分为delta类型和cumulative类型，delta类型就是每个发送来的指标表示这段时间的变化量，而cumulative类型就是表示累加的量。在skywalking oap中，之前是默认不处理delta类型的sum数据的，只处理cumulative类型，我为其做了适配，并将得到的sum数据转换为gauge，因为delta数据其实此时和gauge更像，表示这段时间的变化量。而更麻烦的问题发生了，在airflow中并不严格遵守promethus中counter数据只增加不减少的定义，其定义的dag_processing.processes表示的是当前在运行的解析dag的进程数量，如果我们将收到的每次metric定义为目前变化的解析dag进程数，未免过于奇怪，不过也没有更好的办法。\n问题三： skywalking oap不适配opentelemetry Exponential Histogram类型metricapache airflow一共会产生三种类型的metrics，分别是counter（也就是sum）、gauge（仪表盘数据）、timer。OpenTelemetry Collector接收到数据后会将其转换为otel支持的data，counter转化为sum，gauge转化为gauge，而对于timer数据有两种选择，分别是Exponential Histogram和Summary，相比而言，histogram类型的数据能够提供更多的信息。而skywalking oap目前只适配histogram类型的metric，不支持较新的Exponential Histogram。从本质上来讲Exponential Histogram是对histogram的数据量进行了压缩，因为其使用传输底数和数组的index来表示boundary（做指数运算可以得到），我想这种数据形式相比于histogram更具有优势，未来可能会有更多的监控服务要使用到，因此对其进行了适配。\n3.2 数据处理Skywalking在收到metric数据后会将数据转换为自己定义的格式，关于skywalking metric的格式，可以参考该文档。转换之后，skywalking支持使用其定义的Meter Analysis Language来定义一系列的规则过滤和处理数据。下面介绍一些MAL常用的function：\nMetric level function在skywalking oap中，将指标的来源定义为service、instance、endpoint、process这几个级别。其中service表示为传入请求提供相同行为的一组工作负载；服务组中的每个工作负载都称为一个instance；endpoint表示服务中用于传入请求的路径，例如HTTP URI路径或gRPC服务类方法签名；process表示的是一个操作系统进程。该函数从metrics的label中提取出具体的level。\nmetric_1.service([svc_label1, svc_label2...], Layer)metric_2.instance([svc_label1, svc_label2...], [ins_label1, ins_label2...], Layer)metric_3.endpoint([svc_label1, svc_label2...], [ep_label1, ep_label2...])\n\nMetric Filter过滤metric用的，只有满足特定条件的metric才会被meter analysis language继续处理。\nfilter: &lt;closure&gt; # example: &#x27;&#123; tags -&gt; tags.job_name == &quot;vm-monitoring&quot; &#125;&#x27;\n\nTag filter该filter可以根据metrics的tag来提取特定的metric\ninstance_trace_count.tagMatch(&quot;region&quot;, &quot;us-west|asia-north&quot;).tagEqual(&quot;az&quot;, &quot;az-1&quot;)\n\nWhat’s more更多信息可以参考官方文档\n3.3 数据展示得益于skywalking强大的booster-ui，我们能够通过编写json文件定制化我们的dashboard，我们可以使用各式各样的图标来展示我们的数据。\n","categories":["可观测"],"tags":["skywalking","airflow","dashboard","otel","statsd"]},{"title":"使用Karger算法解决最小割问题","url":"/2021/05/06/%E4%BD%BF%E7%94%A8Karger%E7%AE%97%E6%B3%95%E8%A7%A3%E5%86%B3%E6%9C%80%E5%B0%8F%E5%89%B2%E9%97%AE%E9%A2%98/","content":"使用Karger算法解决最小割问题一、问题介绍把图 G&#x3D;(V, E) 的节点 V 分割成两个部分 S 和 S-V 的边的集合称为割，而最小割问题就是输⼊是⽆向图 G，求解把图 G 分割成两个部分的边数最⼩的割。而随机算法是指该算法中使用了随机函数，且随机函数的返回值直接或者间接的影响了算法的执行流程或执行结果。我们将使用随机算法中的Karger算法来解决最小割问题。\n二、算法Karger算法的基本思路是每次随机选择一条边，把边的两个端点合二为一。原来与这两个点邻接的点，现在把边连到合并后的节点去，把原来的点和边删除。当合并至只剩两个点时，相当于将原图的点划分成两个集合。这两个点之间的连边数就是形成的割的边数。Karger 算法属于蒙特卡洛随机算法，假设输⼊图有 n个节点，该算法能保证其得到正确解的概率为Pr(\\frac{2}{n^{2}})。\n三、代码实现我使用python实现了使用Karger算法解决最小割问题。我使用字典G存储了图的邻接列表作为输入，输出的是割的边数以及边的信息，在karger算法中，会不断合并图中的顶点，当最后只剩下两个顶点的时候，只需查看邻接列表中顶点的邻接节点数就可以得到割的边数。同时我定义了一个字典V用来记录和最后得到分割的两个图，每当顶点合并时，我就会更新这个字典。最后通过这个字典中存储的两个图的顶点来得到割的边。\n同时由于Karger算法不能保证得到最小割，我在实际实现中运行100次Karger算法来求最小割，在我的试验中，得到了最小割。\n代码：\nimport sysimport copyimport randomdef choose_random_key(G):    v1 = random.choice(list(G.keys()))    v2 = random.choice(list(G[v1]))    return v1, v2def karger(graph):    G=copy.deepcopy(graph)    keys=list(graph.keys())    V=&#123;&#125;    for key in keys:        V[key]=[]        V[key].append(key)    length = []    while len(G) &gt; 2:        v1, v2 = choose_random_key(G) # 随机选择两个节点        G[v1].extend(G[v2]) # 合并 v1 和 v2        # 根据合并调整边的连接        for x in G[v2]:            G[x].remove(v2)            G[x].append(v1)        while v1 in G[v1]:#去环            G[v1].remove(v1)        del G[v2]        V[v1].extend(V[v2])        del V[v2]    for key in G.keys(): # 得到最小割边的数量        length.append(len(G[key]))    return length[0],Vgraph=&#123;1:[2,3,4],      2:[1,3,4],      3:[1,2,4,5,6],      4:[1,2,3],      5:[3,6,7,8],      6:[3,5,7,8],      7:[5,6,8],      8:[5,6,7]&#125;currentLen=0currentV=&#123;&#125;shortestLen=sys.maxsizeshortestV=&#123;&#125;for i in range(100):   currentLen,currentV = karger(graph)   if currentLen&lt;shortestLen:        shortestLen=currentLen        shortestV=copy.deepcopy(currentV)cut_edge=[]keys=list(shortestV.keys())for i in shortestV[keys[0]]:    for j in shortestV[keys[1]]:        if j in graph[i]:            cut_edge.append([i,j])print(&quot;the shortest length of cut is &#123;&#125;&quot;.format(shortestLen))print(&quot;the cut edge is &#123;&#125;&quot;.format(cut_edge))\n\n结果：\nthe shortest length of cut is 2the cut edge is [[3, 6], [3, 5]]\n\n四、结论在本文中我成功地使用Karger算法解决了图的最小割问题，得到了一个图的最小割的边数，并通过一个字典来记录分割后的两个图的顶点信息，以此来得到割的边。同时由于Karger算法是一个随机算法，不能保证单次运行得到最小割，因此我循环多次Karger算法来尽可能地求得最小割。\n","categories":["算法"],"tags":["最小割","Karger"]},{"title":"关于最优停止问题的研究","url":"/2021/03/01/%E5%85%B3%E4%BA%8E%E6%9C%80%E4%BC%98%E5%81%9C%E6%AD%A2%E9%97%AE%E9%A2%98%E7%9A%84%E7%A0%94%E7%A9%B6/","content":"关于最优停止问题的研究摘要：本文就最优停止问题进行了研究，最优停止问题是博弈论中的一个经典问题，它可以具体描述为各种实际问题。本文采用理论分析与代码模拟的方式，从数学与计算机模拟两个角度来研究与解决这个问题，最终发现是该问题的解，也就是最优采样比率。同时还发现此时选取到最优值的概率也为。\n一、介绍在概率及博弈论上，最优停止问题是一系列问题的统称，它包括如捡稻草问题、恋爱问题、秘书问题等等。拿捡稻草问题举例，一片稻田上有n株稻草，每株稻草长度都不一样，你从稻田的这一头走到另一头，其中你捡一株稻草，但你不能回头，问如何尽可能地捡到最长的那根稻草。在这个问题中，我们的策略是先观察前k株稻草，但都不捡，记下前k株稻草中最长的那一株，之后观察后面的n-k株稻草，一旦遇到比前k株中最长的那一株要长的稻草就把这株稻草捡起来。最优停止问题所要求解的就是这个k与n的关系，也就是将多少株稻草作为样本空间去观察的问题。同样的策略求解也存在在于恋爱问题、秘书问题中。为了求解最优停止问题，我准备了数理的解决方式与代码模拟的解决方式，最终这两种方式得到了一致的结论。\n二、数理分析同样以稻草作为例子展开我们的数理分析。假设一共有株稻草，我们将株稻草作为样本空间进行观察。那么对于每一个，如果最长的稻草在第个位置(在到之间)，那么该稻草被选中当且仅当前株稻草中最长的那株稻草在前株稻草之中，其可能性为。所以我在下方给出放弃前个人，将这个人作为样本空间选到最优的人的概率。\n\n\n\n那么这道题就变成了求当为何值时，得最大值，其中且属于正整数。当较小时，可以用非线性规划求整数解，但我们的最优停止问题，考虑的是很大的情况。当很大时，可以观察出是将区间 分割成宽度为的小区间的黎曼和，令 ，易得。\n 为求最大值，令，则，同时得出一个附加的结论，此时  。\n综上所述，最优停止问题的解为 ,同时可以求出当为时选取到最大值的概率也为。\n三、代码模拟除了上面的数理分析，我还用代码模拟了最优停止问题，并输出了横坐标为观察的样本空间大小（也就是k值），纵坐标为得到最优解次数的图表。接下来我将讲解我的代码设计思路以及展示我的模拟结果。为了讲解更为生动形象，我同样以捡稻草作为例子。\n首先假设一共有100株稻草，稻草长度都不一样，在代码中我通过一个容纳正整数1到100的数组来表示这些稻草，同时定义一个有100个元素的score数组来记录各个观察样本数量选取到的最长的稻草的次数。之后是模拟选择的过程，对于k值也就是观察样本的数量，我设置了从0到99。每一次先得出并记录前k个数的最大值，在剩下的数字中，一旦有大于这个最大值的数字就记录这个数字并跳出循环。每一次模拟选择稻草的过程前先将数组中元素的次序打乱，对于每一次选取的结果，如果选到最大值，则更新score数组中相应下标的元素值。为了让结果尽量可信，我将选取的总次数也就是外循环的值设置地很大，设置为了10000。最终，通过python的matplotlib包，我将模拟的结果可视化，横坐标为选取作为观察样本的数量，纵坐标为成功选到最大值的次数。经过多次运行，我发现峰值总是出现在36与37之间，同时可以观察到纵坐标的最大值约为3700，而3700/10000与1/e又十分接近，这两点都与我数理分析得到的结论相一致。（代码详见附录）\n\n四、结论通过这次的研究，我通过数学的逻辑推理和计算机的模拟成功地解出了最优停止问题的答案，作为一个非常实用的概率、博弈论结论，最优停止问题的答案告诉我们的结论不仅告诉我们在具体的选择场景中先观察 1� 的样本再去进行选择，而且很抽象哲学地告诉我们在做事情时要先去观察、思考这件事物，不要盲目行事也不要不敢迈出步子。\n附录import timeimport randomimport matplotlib.pyplot as pltfrom matplotlib.ticker import MultipleLocator, FormatStrFormatterrandom.seed(time.time())chooseArray=[]score=[]for i in range(1,101):    chooseArray.append(i)for i in range(0,100):    score.append(0)for i in range(0,10000):    for k in range(0,100):         random.shuffle(chooseArray)         max=0         chooseFlag=False         choose=0         j=0         while j&lt;k:            if(chooseArray[j]&gt;max):                max=chooseArray[j]            j=j+1         while j&lt;100 and not chooseFlag:            if(chooseArray[j]&gt;max):                chooseFlag=True                choose=chooseArray[j]            j=j+1         if not chooseFlag:            choose=chooseArray[99]         if(choose==100):            score[k]+=1#结果可视化ax = plt.subplot(111)x=range(0,100)y=scoreplt.plot(x,y)xmajorLocator = MultipleLocator(20)  xmajorFormatter = FormatStrFormatter('%5.1f')ax.xaxis.set_major_locator(xmajorLocator)ax.xaxis.set_major_formatter(xmajorFormatter)xminorLocator = MultipleLocator(5)ax.xaxis.set_minor_locator(xminorLocator)ax.xaxis.grid(True, which='major')ax.set_title('Best Stop Problem')ax.set_xlabel('the number to observe')ax.set_ylabel('the times of choosing the best one')\n\n","categories":["算法"],"tags":["最优停止问题","数理分析"]},{"title":"关于求逆序对问题的研究","url":"/2021/03/10/%E5%85%B3%E4%BA%8E%E6%B1%82%E9%80%86%E5%BA%8F%E5%AF%B9%E9%97%AE%E9%A2%98%E7%9A%84%E7%A0%94%E7%A9%B6/","content":"关于求逆序对问题的研究一、问题介绍逆序对数经常用来评判两个数组相似度高低，其在很多评分网站得到了广泛的应用。假如你对五部电影进行打分，你的打分分别为[1,2,4,3,5],其中评者A的打分分别为[2,4,1,3,5],评者B的打分分别为[3,4,1,5,2]，那么在推荐评者或者评者的文章时，应该把评者A推荐给你还是评者B呢？应该是评者A。这其中就涉及到了求逆序对数问题，那么什么是逆序对数呢。对于一个输入序列，假如元素的索引$i&lt;j$且元素$a_{i}&gt;a_{j}$，那么$a_{i}$与$a_{j}$就是一对逆序对，该序列中所有逆序对的总数就是逆序对数。在上述的评分中，你的打分的序列的逆序对数为1，评者A评分的序列的逆序对数为2，评者B评分的序列的逆序对数为3，你的打分的逆序对数与评者A更为接近，所以将评者A推荐给你。那么假如给你一个序列，你要如何求出该序列的逆序对数以及其所有的逆序对呢。\n二、算法设计一个很简单的求解方式就是遍历该数组中的所有元素，判断在该元素右边的值是否比该元素小，如果比该元素小，这两个数就构成了逆序对。通过分析，很容易发现这种解法的时间复杂度为$O(n^{2})$，那么有没有更高效的求解方式呢？\n我发现该问题可以分解为更短序列的子问题，这不禁让我想要尝试使用分治算法求解该问题。那么首先我们将其分解为子问题，假定输入序列为A，将输入序列分为两个部分，左边的为LA，右边的为RA，那么可以发现，A与LA、RA只是序列元素数量的不同，求解A的逆序对与逆序对数的策略同样适用于LA与RA，那么剩下的问题就是如何求解与合并这些子问题。可以发现对于A的逆序对数等于LA的逆序对数加上RA的逆序对数再加上跨界情况下的逆序对数，所谓跨界情况就是指LA中的某一元素可能与RA中的某一元素构成逆序对。\n此时该问题的核心就变成了如何求跨界情况下的逆序对。假如每次归并都将AL中的元素与RA中的元素逐个比较，那么不难得出跨界情况下的时间复杂度为$O(n^{2})$，根据主方法可以发现此时使用分治算法的时间复杂度仍为 $O(n^{2})$。那么该如何处理跨界情况下的求解方式可以提高算法的时间复杂度呢？\n经过不断的分析与尝试，我将序列排序减少了跨界情况下的比较次数。假设LA与RA都是经过排序的列表，那我们分别从LA与RA取出一个元素$a_{i}$与$b_{j}$，如果$a_{i}&lt;b_{j}$，那么我们取$a_{i+1}$与$b_{j}$比较，但如果$a_{i}&gt;b_{j}$，那么可以得到 $a_{i}$以及LA中下标大于i的元素都与$b_{j}$构成逆序对数，之后我们就只需要继续比较$a_{i}$与$b_{j+1}$。但此时又有一个问题，就是排序会影响序列中的元素的顺序，会影响我们得到的逆序对数。那么此时我们就需要边排序边记录逆序对数。接下来的代码实现与归并排序十分相似，不过是在排序的过程中记录了逆序对。\n三、算法实现def find_inversion(A,inv_list):    lenA = len(A)    if lenA &lt;= 1:        return 0,A    mid = lenA//2    LA = A[:mid]    RA = A[mid:]    countLA,LA = find_inversion(LA,inv_list)    countRA,RA = find_inversion(RA,inv_list)    countLRA,mergedA = merge_inversion(LA,RA,inv_list)        return countLA+countRA+countLRA,mergedAdef merge_inversion(LA,RA,inv_list):    i,j,inv_count = 0,0,0    alist=[]    lenLA = len(LA)    lenRA = len(RA)    while i&lt;lenLA and j&lt;lenRA:        if LA[i]&lt;RA[j]:            alist.append(LA[i])            i+=1        else:            inv_count += lenLA-i            for index in range(i,lenLA):                inv_list.append([RA[j],LA[index]])            alist.append(RA[j])            j+=1    while i&lt;lenLA:        alist.append(LA[i])        i+=1    while j&lt;lenRA:        alist.append(RA[j])        j+=1    return inv_count,alistinv_list=[]A=[8,1,4,2,3]inv_count,sorted_list=find_inversion(A,inv_list)print(&quot;逆序对数量为&#123;&#125;，逆序对分别是&#123;&#125;&quot;.format(inv_count,inv_list))\n\n我定义了两个函数，分别为find_inversion与merge_inversion,对应的是分解子问题与归并。其中的find_inversion的输入参数inv_list用来记录结果，A为需要求解的序列。在父函数find_inversion中将父序列分解为两个子序列LA与RA传入子函数find_inversion中进行递归操作，最后使用merge_inversion进行归并操作。在merge_inversion中边排序边记录逆序对与逆序对数。通过观察可以发现merge_inversion可以发现merge_inversion中有三个循环，三个循环的时间复杂度均为$O(n)$，那么merge_inversion的时间复杂度为$O(n)$，也就是分治算法中的f(n)为$O(n)$。因此我可以得到以下的公式:\n$T(n) &#x3D; 2T(\\frac{n}{2})+O(n)$\n根据主方法，我们易得使用分治算法求解逆序对问题的时间复杂度为$O(nlogn)$。\n四、结论我研究并解决了逆序对问题，从最容易想到的两层遍历的穷举法，到想到使用分治算法进行求解，再到优化分治算法求解该问题的方式，最终我解决了这个问题，并将时间复杂度优化到了$O(nlogn)$。经过该问题的研究，我们可以发现对于可以分解为小问题的问题，我们使用分治算法常常能够简化该问题并且优化该问题的时间复杂度，同时对于优化比较的过程，排序常常能起到很好的效果。\n","categories":["算法"],"tags":["求逆序对"]},{"title":"关于稳定性计数排序的研究","url":"/2021/03/21/%E5%85%B3%E4%BA%8E%E7%A8%B3%E5%AE%9A%E6%80%A7%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F%E7%9A%84%E7%A0%94%E7%A9%B6/","content":"关于稳定性计数排序的研究一、介绍我们一开始接触的排序算法大都是如冒泡排序、插入排序和选择排序这类的基于比较的排序算法，这类基于比较的排序算法的时间复杂度限制在了$O(nlogn)$。那么有没有时间复杂度更优的排序算法呢，当然是有的，有这么一些算法不需要通过比较就进行排序，如计数排序、桶排序和基数排序，这些算法牺牲了空间复杂度换取了时间复杂度。在本文中，我们主要研究的是计数排序及其的排序稳定性。\n二、算法介绍计数排序是一种非基于比较的排序算法，它的优势在于在对一定范围内的整数排序时，它的算法复杂度为$O(n+k)$，其中k是整数的范围，此时计数排序快于任何比较排序算法。假定给定的排序数组为A，在计数排序中我们定义一个大小为数组A中最大值减去最小值的值的数组B，该数组B就是计数排序的关键，总的来说这个数组B的下标对应要求排序数组A中的元素值，而该数组B中的元素对应相应元素在数组A中出现次数的信息。定义完了数组B之后，我们该如何在数组B中记录信息来完成对于数组A的排序呢？这里的操作方式就涉及了计数排序的算法稳定性的问题，算法的稳定性是指相同大小的元素在经过排序后其相对位置不发生改变。\n我们首先介绍一下不稳定的排序方式，我们遍历数组A中的元素，对于相应数组B下标的元素数值加1，那么我们就记录下了A中各个元素的出现次数。排序的过程就是我们新建一个空的数组，正序遍历数组B，发现一个元素值不为空，就往空的数组中加入该下标对应的大小的A中元素，之后B相应的元素减1，循环往复直到该元素变为1，下标加一进行下一次查找，直到B中元素全为0。我们可以很容易地发现，这种算法没有考虑相同大小元素原先的位置关系，排序得到的结果原本相同大小的元素的相对位置关系可能是错误的，因此这是一种不稳定的排序方式，那么怎么才能做到保证稳定性呢？\n其实很简单，我们只需要在记录数组A中元素信息的数组B中加入记录相同大小元素的位置关系的信息就可以了。我们在上述不稳定排序给数组B赋值的基础上，使B中所有元素的值都等于其自身加上所有下标小于它元素的值，这相当于是记录了不同大小元素在排序完的数组中的位置。之后为了保证稳定性，也就是使相同大小元素的相对位置不发生改变，我们倒着遍历数组A中的下标，对于A中的元素找到数组B中其排序完时应所处的位置，找到后将数组B中相应元素的值减去1，这就实现了排序的稳定性。\n三、代码实现本文使用python实现了两种计数排序，分别定义了两种函数，其中counting_sort_unstable为不稳定的计数排序，counting_sort为稳定的计数排序，最终给出一个列表进行测试。我用这个例子解释一下为什么稳定的计数排序要倒序遍历数组A，可以发现A中有两个5，而通过计算可以发现在遍历开始前数组B中5对应的元素值为9，那么我们倒着遍历数组A，找到了下标较大的那个5，将其放在了SA的下标8的位置，此时数组B中的5对应的元素值减1变为8，而我们继续遍历会遍历到另一个下标较小的5，此时将其放在SA中下标为7的位置，可见如果顺着遍历就无法实现该算法的稳定性。\n#不稳定的计数排序def counting_sort_unstable(A):    if A==[]:        return []        lenA=len(A)    maxA=max(A)    minA=min(A)    SA=[]    B=[0 for i in range(minA,maxA+1)]        for num in A:        B[num-minA]+=1    for i in range(len(B)):        while B[i]&gt;0:           SA.append(i+minA)           B[i]-=1    return SA#稳定的计数排序def counting_sort(A):    if A==[]:        return []        lenA=len(A)    maxA=max(A)    minA=min(A)    SA=[0 for i in range(len(A))]    B=[0 for i in range(minA,maxA+1)]        for num in A:        B[num-minA]+=1    for i in range(1,len(B)):        B[i]=B[i]+B[i-1]    for i in reversed(range(0,len(A))): #reversed表示逆序遍历，为了使排序稳定        SA[B[A[i] - minA]-1] = A[i]#-1是因为下标从0开始的        B[A[i] - minA] -= 1 #每归位一个元素，就少一个元素    return SA\n\n四、结论在本文中，我实现了计数排序并且研究了稳定的计数排序和不稳定的计数排序，我总结得出计数排序的本质是记录数组的元素的位置信息来将其进行重构，而为了实现稳定的计数排序其本质就是不光要记录不同大小元素的位置信息还要记录相同大小元素的位置信息。\n","categories":["算法"],"tags":["排序算法","计数排序"]},{"title":"动态规划解决单背包问题","url":"/2021/04/15/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E8%A7%A3%E5%86%B3%E5%8D%95%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/","content":"动态规划解决单背包问题一、问题介绍单背包问题是指给定一个背包，一些物品，这个背包有承重上限这个属性，而这些物品有重量和价值这两个属性，而这个问题要求解得到的是一个放置物品的策略，要求背包中所放物品的价值总和尽可能的大，但是这个物品的重量总和不能超过背包的承重上限。在之前，我用一些启发式的算法，比如贪心算法、邻居搜索算法和禁忌搜索算法解决过这类问题，在这里我使用了动态规划来解决这个问题。\n二、算法所谓动态规划就是首先将大问题拆分为小问题，而其最关键的是避免了这些小问题的重复解决，而是保留这个小问题的解下一次直接使用。在使用动态规划时，最关键的就是其中的递推公式来得到动态规划表。\n在该问题中，我们使用二维的动态规划表来求解，该动态规划表的行表示的是不同的物品，列表示的是不同的背包容量，而填在表中的数值为该种情况下的最大价值。那么我们更新该动态规划表就有两种情况，一种是包的容量比当前的商品体积要小，因此装不下该商品，这时的价值与之前的价值是一样的。第二种情况就是包有足够的容量可以放下该物品，但是装了也不一定能够达到最优的价值，那么我们就要通过比较来决定装或者不装。所以可以得到如下的式子。W,V分别为物品的重量和价值的数组，F表示二维的动态规划表。\n$F(i,j) &#x3D; \\left{ \\begin{array}{ll} F(i-1,j) &amp; \\textrm{j&lt;W(i)}\\ max(F(i-1,j),F(i-1,j-W(i))+V(i)) &amp; \\textrm{j&gt;&#x3D;W(i)} \\end{array} \\right.$\n三、代码实现在具体的代码实现中，我定义了两个函数，分别为FindMax()与FindWhat(),他们分别是为了得到二维动态规划表和得到具体的物品放法。在FindMax函数中，我使用了如上述算法描述的方式更新二维动态规划表，在FindWhat函数中，我从二维动态规划表的末尾处开始遍历二维动态规划表中的内容，返回最优的物品放法。\n代码：\n#使用动态规划解决单背包问题#得到具体物品放法def FindWhat(i,j,dp,V,W,result):    if i&gt;=0:        if dp[i][j] == dp[i-1][j]:             result[i]=0             FindWhat(i-1,j,dp,V,W,result)        elif j-W[i]&gt;=0 and dp[i][j] == (dp[i-1][j-W[i]]+V[i]):             result[i]=1             FindWhat(i-1,j-W[i],dp,V,W,result)                #得到动态规划表def FindMax(dp,V,W,capacity):    for i in range(0,len(V)):        for j in range(0,capacity):            if j&lt;W[i]:                dp[i][j]=dp[i-1][j]            else:                if dp[i-1][j]&gt;(dp[i-1][j-W[i]]+V[i]):                    dp[i][j]=dp[i-1][j]                else:                    dp[i][j]=dp[i-1][j-W[i]]+V[i]V=[10, 40, 30, 50]W=[5, 4, 6, 3]capacity = 10number=4dp=[]result=[0 for i in range(0,number)]for i in range(0,number):    dp.append([])    for j in range(0,capacity):        dp[i].append(0)FindMax(dp,V,W,capacity)FindWhat(number-1,capacity-1,dp,V,W,result)print(result)\n\n结果：\n[0, 1, 0, 1]\n\n四、结论本文使用了动态规划的方法构造了二维的动态规划表来解决单背包问题，在具体的实现过程中，包括构造和更新二维动态规划表和遍历二维动态规划表返回单背包问题的解法。该解法作为一种最佳化算法而非启发式算法，保证能够得到全局最优解，同时动态规划的分解小问题，求解小问题以及重复利用小问题的解避免了重复求解小问题，提高了解法的性能。\n","categories":["算法"],"tags":["动态规划","单背包问题"]},{"title":"动态规划解决最长递增子序列问题","url":"/2021/04/05/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E8%A7%A3%E5%86%B3%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97%E9%97%AE%E9%A2%98/","content":"动态规划解决最长递增子序列问题一、问题介绍首先我来介绍一下什么是最长递增子序列问题，要知道什么是最长递增子序列问题，我们必须先明白一个概念，那就是什么是子序列，所谓子序列，就是将给定序列中零个或多个元素去掉之后得到的序列。那么递增的子序列就是指该序列中的元素数值是随着下标增大逐渐增大的。而其中最长的递增子序列的长度和该子序列就是我们这个问题需要求解的值。\n二、算法所谓动态规划就是首先将大问题拆分为小问题，而其最关键的是避免了这些小问题的重复解决，而是保留这个小问题的解下一次直接使用。在使用动态规划时，最关键的就是其中的递推公式。最长递增子序列的递推公式为 $F[i]&#x3D;max(1,F[j]+1) , a_{j}&lt;a_{i} &amp;&amp; j&lt;i$，$F[0]&#x3D;1$，其中$F[0]&#x3D;1$。假设有序列$\\lbrace a_{1}, a_{2},…a_{n} \\rbrace$，我们用 $F[i]$代表若递增子序列以$a_{i}$结束时它的最长长度，对于$F[0]$我们易知其值为1。那么对于任意一个$F[i]$，我们只需要在下标小于它的元素中找到数值小于它的最大的F值,那么最大的$F[i]$就相当于找到的F值加上1。之后遍历整个序列一遍就能够得到整个序列中每一个元素的以其结尾的最长递增子序列长度，那么我们自然也就得到了整个序列的最长递增子序列长度。同时我通过得到的动态规划表回溯得到其中的一个最长递增子序列。\n三、代码实现在代码实现中，我使用了python来实现这一个算法，使用一个字典来记录动态规划表，之后从头遍历序列中的每一个元素，对于每一个元素又要遍历其之前的元素值。最后遍历完成后返回字典中的值的最大值就找到了该序列的最长递增子序列的长度。之后我从字典其中的一个最大值的key开始回溯得到其中的一个最长递增子序列，其中回溯的条件是前面的值小于后面的值且记录F值的longest字典对应的值相差1。\n代码：\ndef solveLIS(A):    result=[]    longest=&#123;&#125;    longest[0]=1    for i in range(1,len(A)):        maxlen=-1        for j in range(0,i):            if A[i]&gt;A[j] and maxlen&lt;longest[j]:                maxlen = longest[j]            if maxlen &gt;= 1:                longest[i]=maxlen+1            else:                longest[i]=1                     maxlen = max(longest.values())    maxkey = 0    for i in range(len(A)-1,-1,-1):        if longest[i] == maxlen:            maxkey = i            break    result.append(A[maxkey])    maxlen=maxlen-1    for i in range(maxkey-1,-1,-1):        if result[-1] &gt; A[i] and longest[i] == maxlen:            maxlen=maxlen-1            result.append(A[i])        if maxlen&lt;=0:            break    result = result[::-1]    return max(longest.values()),resultA=[5,2,8,6,3,6,9,7]print(solveLIS(A))B=[3,2,5,6,7,1,8,9]print(solveLIS(B))\n\n结果：\n(4, [2, 3, 6, 7])(6, [2, 5, 6, 7, 8, 9])\n\n","categories":["算法"],"tags":["动态规划","子序列"]},{"title":"链路追踪采样策略","url":"/2024/09/22/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5/","content":"链路追踪数据量大，如果全采样不仅对于客户端的IO负担很大，而且对于采集侧的内存、IO压力巨大，因此需要采样策略来决定哪些链路数据需要采样，哪些不需要。本篇文章介绍了一些常见的链路追踪采样策略及其在业界的实现方式。\n概率采样概率采样是指只采集某一个概率&#x2F;比例的链路数据，保证只有一部分的数据被采样，减少数据量。常见的做法是使用trace id计算概率。\n\n使用trace id计算hash值，之后用该hash值作为生成随机数的seed，并与设定的采样概率做比较决定是否采样：\n\npublic class SamplingEvaluator &#123;    private static final Random random = new Random();     public static boolean shouldSample(double sampleRate) &#123;        return random.nextFloat() &lt; sampleRate;    &#125;     public static boolean shouldSample(String traceId, double sampleRate) &#123;        if (StringUtils.isBlank(traceId)) &#123;            return false;        &#125;         long hash = HashUtil.fnv64a(traceId);        float sampleValue = HashUtil.nextFloat(hash);        return sampleValue &lt; sampleRate;    &#125;&#125;\n\n\nopentelemetry对于概率采样的实现，opentelemetry的trace id中包含随机数，可以直接使用该随机数进行概率判断\n\n@Immutablefinal class TraceIdRatioBasedSampler implements Sampler &#123;    static TraceIdRatioBasedSampler create(double ratio) &#123;        if (ratio &lt; 0.0 || ratio &gt; 1.0) &#123;            throw new IllegalArgumentException(&quot;ratio must be in range [0.0, 1.0]&quot;);        &#125;        long idUpperBound;        // Special case the limits, to avoid any possible issues with lack of precision across        // double/long boundaries. For probability == 0.0, we use Long.MIN_VALUE as this guarantees        // that we will never sample a trace, even in the case where the id == Long.MIN_VALUE, since        // Math.Abs(Long.MIN_VALUE) == Long.MIN_VALUE.        if (ratio == 0.0) &#123;            idUpperBound = Long.MIN_VALUE;        &#125; else if (ratio == 1.0) &#123;            idUpperBound = Long.MAX_VALUE;        &#125; else &#123;            idUpperBound = (long) (ratio * Long.MAX_VALUE);        &#125;        return new TraceIdRatioBasedSampler(ratio, idUpperBound);    &#125;    @Override    public SamplingResult shouldSample(        Context parentContext,        String traceId,        String name,        SpanKind spanKind,        Attributes attributes,        List&lt;LinkData&gt; parentLinks) &#123;        return Math.abs(getTraceIdRandomPart(traceId)) &lt; idUpperBound        ? POSITIVE_SAMPLING_RESULT        : NEGATIVE_SAMPLING_RESULT;    &#125;&#125;\n\n头部采样头部采样是指在一条链路的开始决定该条链路是否要被采样，如果需要被采样则在上下文（context）中透传采样标记，表示全链路采样。OpenTelemetry Sdk实现了头部采样。\n@Immutablefinal class ParentBasedSampler implements Sampler &#123;    @Override    public SamplingResult shouldSample(        Context parentContext,        String traceId,        String name,        SpanKind spanKind,        Attributes attributes,        List&lt;LinkData&gt; parentLinks) &#123;        SpanContext parentSpanContext = Span.fromContext(parentContext).getSpanContext();        if (!parentSpanContext.isValid()) &#123;            return this.root.shouldSample(                parentContext, traceId, name, spanKind, attributes, parentLinks);        &#125;        if (parentSpanContext.isRemote()) &#123;            return parentSpanContext.isSampled()            ? this.remoteParentSampled.shouldSample(                parentContext, traceId, name, spanKind, attributes, parentLinks)            : this.remoteParentNotSampled.shouldSample(                parentContext, traceId, name, spanKind, attributes, parentLinks);        &#125;        return parentSpanContext.isSampled()        ? this.localParentSampled.shouldSample(            parentContext, traceId, name, spanKind, attributes, parentLinks)        : this.localParentNotSampled.shouldSample(            parentContext, traceId, name, spanKind, attributes, parentLinks);    &#125;&#125;\n\n头部概率采样头部采样加上概率是指在头部服务计算概率是否命中，如果命中则之后的链路数据全采样，否则不采样。如果采样命中，则其会在链路调用发生跨进程&#x2F;线程数据透传的时候，在上下文信息中带上采样标记，表示该链路数据需要被采样。\n\nif (traceConfig != null &amp;&amp; traceConfig.isEntrySampledOpen()) &#123;    Double entrySampledRate = traceConfig.getEntrySampledRate();    if (entrySampledRate != null) &#123;        if (entrySampledRate &gt;= 1.0) &#123;            dtc.addSamplingStrategy(SamplingStrategy.HEAD_ENTRY);        &#125; else if (entrySampledRate &gt; 0 &amp;&amp;                   SamplingEvaluator.shouldSample(traceContext.getTraceId(), entrySampledRate)) &#123;            dtc.addSamplingStrategy(SamplingStrategy.HEAD_ENTRY);        &#125;    &#125;&#125;\n\n入口固定数量采样每一条链路都有一个入口，该入口可能是一个Http Url，可能是一个服务接口，那么为了保证在一段时间内每一个入口都有一定数量的链路数据被采样到，我们设置了入口固定数量采样策略，使用计数器存储一个时间窗口内某一个入口的链路采样数量。其同样通过头部采样标记透传标识链路需要被采样。\nif (traceConfig != null &amp;&amp; traceConfig.isEntrySampledOpen()) &#123;    if ((traceContext.getSamplingStrategy() &amp; SamplingStrategy.HEAD_ENTRY.getValue()) == 0) &#123;        boolean headHit = false;        int keyCapacity = traceConfig.getEntrySampledKeyCountPerSec();        int valueCapacity = traceConfig.getEntrySampledValueCountPerSec();        if (StringUtils.isNotEmpty(headHttpUrl)) &#123;            headHit = HeadEntryFilter.getInstance().hit(headHttpUrl, keyCapacity, valueCapacity);        &#125; else if (StringUtils.isNotEmpty(headRpcService)) &#123;            headHit = HeadEntryFilter.getInstance().hit(headRpcService, keyCapacity, valueCapacity);        &#125;        if (headHit) &#123;            dtc.addSamplingStrategy(SamplingStrategy.HEAD_ENTRY);        &#125;    &#125;&#125;\n\n固定数量采样Skywalking对Span进行计数，决定是否采样。sample_n_per_3_secs配置，每3秒的限制数量，计数器计数进行比较：\n\n对于带有上游报文数据的entry span必定采样\n对于local span、exit span和无上游报文数据的entry span部分采样\n\n@DefaultImplementorpublic class SamplingService implements BootService &#123;    public boolean trySampling(String operationName) &#123;        if (on) &#123;            int factor = samplingFactorHolder.get();            if (factor &lt; samplingRateWatcher.getSamplingRate()) &#123;                return samplingFactorHolder.compareAndSet(factor, factor + 1);            &#125; else &#123;                return false;            &#125;        &#125;        return true;    &#125;&#125;\n\n根据系统容量采样Skywalking中有根据系统CPU利用率判断是否采样的采样器\n@OverrideImplementor(SamplingService.class)public class TraceSamplerCpuPolicyExtendService extends SamplingService &#123;    @Override    public boolean trySampling(final String operationName) &#123;        if (cpuUsagePercentLimitOn) &#123;            double cpuUsagePercent = jvmService.getCpuUsagePercent();            if (cpuUsagePercent &gt; TraceSamplerCpuPolicyPluginConfig.Plugin.CpuPolicy.SAMPLE_CPU_USAGE_PERCENT_LIMIT) &#123;                return false;            &#125;        &#125;        return super.trySampling(operationName);    &#125;&#125;\n\n标签采样可以为Span打上标签，在采样时与配置中需要采样的标签进行匹配，如果匹配上了则采样。\nprivate void addSamplingFlagIfNeed(String key, String value)&#123;    TraceConfig config = m_manager.getConfigManager().getTraceConfig();    TraceContext traceContext = m_manager.getThreadLocalTraceContext();    if (config != null &amp;&amp; traceContext instanceof DefaultTraceContext)&#123;        List&lt;Pair&lt;Pattern, Pattern&gt;&gt; patternList = config.getTagSampledSelectors();        if (tagMatched(patternList, key, value))&#123;  // 如果标签匹配            DefaultTraceContext defaultTraceContext = (DefaultTraceContext)traceContext;            defaultTraceContext.addSamplingStrategy(SamplingStrategy.TAG_RULE);        &#125;    &#125;&#125;\n\n后置采样对于链路中出现需要保留的链路，该节点之后的所有链路都会保留，常见于异常，慢请求，特定用户ID等。\nprivate static void putTraceContext(Context ctx, TraceContext traceContext) &#123;    // ...    if (!messageTree.canDiscard()) &#123; // 后置采样会设置这个canDiscard，概率采样根据canDiscard不会丢弃后置采样的样本        if (config != null &amp;&amp; config.isPostSampledOpen() &amp;&amp; traceContext instanceof DefaultTraceContext) &#123;            DefaultTraceContext defaultTraceContext = (DefaultTraceContext) traceContext;            defaultTraceContext.addSamplingStrategy(SamplingStrategy.POST);        &#125;    &#125;    if (traceContext.getSamplingStrategy() &gt; 0) &#123;        int sampleStrategy = traceContext.getSamplingStrategy();        sampleStrategy &amp;= 0xfffffff7;        ctx.addProperty(TraceContext.SAMPLED, String.valueOf(sampleStrategy));    &#125;&#125;\n\n@Overridepublic void logError(String message, Throwable cause) &#123;    if (Cat.getManager().isCatEnabled()) &#123;        if (shouldLog(cause)) &#123;            StringWriter writer = new StringWriter(2048);            if (message != null) &#123;                writer.write(StringUtils.truncate(message, CatConstants.EXCEPT_LINER_LIMIT));                writer.write(&#x27; &#x27;);            &#125;            if (ProblemFilter.hit(cause)) &#123;                // 有异常的时候会设置canDiscard为false，默认初始化为true                m_manager.getThreadLocalMessageTree().setDiscard(false);                cause.printStackTrace(new ThrowablePrintWriter(writer));            &#125; else &#123;                writer.write(&quot;stacktrace was throttled&quot;);            &#125;        &#125;    &#125;&#125;\n\n尾部采样上面的采样策略都是在客户端决定是否采样，而尾部采样可以在采集侧采集到整条链路数据之后再决定是否需要存储这条链路。Opentelemetry Collector目前支持了该尾部采样策略，同时据我所知阿里云团队目前也支持了该种采样策略，其可以做到在采集侧暂时保存5min全量的链路数据。使用尾部采样策略我们可以对整条链路进行定制化的采集，比如我们可以采集整条链路耗时超过特定阈值的链路，可以采集有特殊状态码的整条链路。\nprocessors:  # 尾部采样器  tail_sampling:    decision_wait: 10s    num_traces: 100    expected_new_traces_per_sec: 100    policies:      [        &#123;          name: policy-1,          type: status_code,          status_code: &#123;status_codes: [ERROR]&#125;        &#125;,        &#123;          name: policy-2,          type: probabilistic,          probabilistic: &#123;sampling_percentage: 20&#125;        &#125;      ]\n\n\ndecision_wait：在做出采样决定之前，从 trace 的第一个跨度开始的等待时间\nnum_traces：内存中保存的 trace 数\nexpected_new_traces_per_sec：预期的新 trace 数\npolicies：采样策略集合\n\nReference\nSkywalking Java Agent代码仓库\nOpentelemetry Java Sdk代码仓库\nOpentelemetry-Collector代码仓库\nOpenTelemetry Sampling\n可观测性专题: 分布式追踪中的采样\nStabilityGuide - 链路追踪（Tracing）其实很简单——链路成本进阶指南\nOpenTelemetry 采样最佳实践\n\n","categories":["可观测"],"tags":["skywalking","链路追踪","采样策略","openTelemetry"]},{"title":"使用启发式算法解决多背包问题","url":"/2021/05/28/%E4%BD%BF%E7%94%A8%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95%E8%A7%A3%E5%86%B3%E5%A4%9A%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/","content":"使用启发式算法解决多背包问题1. 问题介绍要讲多背包问题，我们先来讲一讲单背包问题。单背包问题是关于如何将将不同的物品放入到一个背包中。这些物品有重量和价值这两个属性，并且背包有容量限制这一个属性。这个单背包问题的目标就是最大化放入背包中物品的总价值同时这些物品的重量之和不能超过背包的容量限制。而多背包问题是单背包问题的拓展，该问题考虑多个背包的情况而不是一个背包的情况。但是它可以使用类似解决单背包问题的策略去解决多背包问题。多背包问题的目标是最大化所有背包中所含物品的总价值，同时每一个背包中的物品质量之和不能超过这个背包的容量限制。\n2. 算法2.1 贪心算法（greedy algorithm）\n为了解决多背包问题，我们可以仅仅考虑当前要将什么物品放入背包中。使用贪心算法，我们根据物品的性价比(价值&#x2F;重量)对物品进行排序，在序列前面的物品优先考虑放入某个背包中。此时我们已经决策了关于将什么物品放入背包中，但是我们仍未决策将物品放入哪个背包中，此时有三种策略，分别是best fit，worst fit和first fit（没错，就是操作系统中会学到的那三个概念）。同时如果没有哪个背包能够容纳当前的物品，那么说明该物品无法放入背包中，此时我们考虑序列中的下一个物品，直至遍历完整个序列。\n2.2 邻居搜索（neighborhood search）\n邻居搜索也是一种启发式算法。它将一个解决多背包问题的方案作为一个元素，之后以某个方案作为起点，搜索该方案的邻居中的更优方案（即背包中的物品价值总和更大），直至当前方案的邻居中没有更优的解决方案则认为当前的解决方案为最优的解决方案。\n该算法很重要的一个部分就是如何定义一个解决方案的邻居，在该问题中，我定义了三种邻居：第一种邻居是将一个物品放入一个背包中；第二种邻居是取出一个背包中的物品并将另一个物品放入其中一个背包；第三种邻居相对比较复杂，可以称之为旋转操作，该操作会涉及三个物品，我假设他们分别为A，B，C，物品A在背包m中，物品B在背包n中同时物品C不在任何一个背包中。我们将物品A从背包m中取出，将物品B放入背包m中并且将物品C放入背包n中。通过定义的这三种邻居，我们可以搜索某个方案的邻居并找到局部最优解。\n2.3 禁忌搜索（tabu-search）\n禁忌搜索也是一种启发式算法，它是对邻居搜索的一种改良。在禁忌搜索中，我们也需要去寻找一个解决方案的邻居解法，但是该算法改变了终止搜索的方式以及记录最优解的方式。在该算法中，我们定义一个禁忌列表来记录之前的解法，一个数值来记录最大迭代次数，一个变量来记录当前的最优解。在禁忌搜索中，也是以某个解决方案为起点，搜索该方案A的邻居，找到所有邻居中不被包含在禁忌列表的方案中的最优解B（不需要该解法优于方案A），同时将方案A放入禁忌列表中（禁忌列表其实是一个队列，如果超过列表的容量，就将队列首部的方案移出队列），并且比较方案B是否优于当前记录的最优解法，如果优于，则更新。此时已方案B为新的起点，重复上述过程，直到迭代次数达到规定的上限或者邻居解法中不存在不在禁忌列表中的解法，退出循环。\n3. 代码实现3.1 伪代码\n\n\n3.2 python代码实现我使用python实现这三种算法，为了表达物品和背包，我定义了物品类和背包类。物品类有重量（weight）和价值（value）这两个属性，背包类有当前剩余容量和初始容量这两个属性。在贪心算法中，我模拟模拟物品的放置流程通过改变背包的剩余容量属性（capacity）。但是在邻居搜索和禁忌搜索算法中，我使用矩阵去记录解决方案。如果矩阵中的第i行和第j列等于1，那么代表第i个物品在第j个背包中。为了判断某个背包是否能够包含某个物品，我定义了judgeWeight函数。为了计算当前所有在背包中的物品的总价值，我定义了calValue函数。同时在禁忌搜索中，我定义了check_tabu函数去判断某个解决方案是否在禁忌列表中。所有的函数都是对矩阵进行操作。在禁忌搜索中，我定义了tabu_length变量来控制禁忌列表的长度，这个变量是算法的一个输入。\n接下来，我按顺序实现了三种算法。我使用相同的测试用例来评价这三种算法。贪心算法总是得到总价值为13的解决方案，邻居搜索算法搜索到的解决方案总价值为14，禁忌搜索最终能够找到总价值为15的解决方案。\nimport numpy as npclass goods:    def __init__(self,weight,value):        self.weight=weight        self.value=valueclass bags:    def __init__(self,original_capacity):        self.original_capacity=original_capacity        self.capacity=self.original_capacity    def clearAll(self):        self.capacity=self.original_capacity\n\n贪心算法：\ndef multiple_knapsack_greedy(bags_set=[], goods_set=[]):    goods_set2=goods_set.copy()       goods_set2.sort(key=lambda x: x.value / x.weight, reverse=True)    result = np.zeros(shape=(len(goods_set),len(bags_set)))    total_value = 0    for i in range(len(goods_set2)):        good=goods_set2[i]        res=[] #record the index of bag which can contain the good        for j in range(len(bags_set)):            if good.weight&lt;=bags_set[j].capacity:                res.append(j)        if not res==[]:            min=bags_set[res[0]].capacity            minIndex=res[0]            for k in res[1:]:                if bags_set[k].capacity&lt;min:#best fit                    min=bags_set[k].capacity                    minIndex=k            total_value+=good.value            goodIndex=goods_set.index(good)            result[goodIndex][minIndex]=1            print(&quot;put good&#123;&#125; into bag&#123;&#125;&quot;.format(goodIndex+1,minIndex+1))            bags_set[minIndex].capacity-=good.weight    for bag in bags_set:         bag.clearAll()    print(&quot;------------------------&quot;)    print(&quot;The final result is:&quot;)    print(&quot;the finial total value is: &#123;&#125;&quot;.format(total_value))    print(&quot;the finial puttting matrix is:&quot;)    print(result)    print()    for i in range(len(bags_set)):        print(&quot;bag&#123;&#125; contains:&quot;.format(i+1))        for j in range(len(goods_set)):            if result[j][i]==1:                print(&quot;  good&#123;&#125; has weight of &#123;&#125; and value of &#123;&#125;&quot;.format(j+1,goods_set[j].weight,goods_set[j].value))    print(&quot;The bags&#x27; total value is &#123;&#125;.&quot;.format(total_value))    return result,total_value\n\n邻居搜索：\ndef judgeWeight(result,bagsWeightList,goodsWeightMat):     sumWeightMat=np.multiply(result,goodsWeightMat)     sumWeightVec=np.sum(sumWeightMat,axis=0)     return (sumWeightVec&lt;=bagsWeightList).all()def calValue(result,goodsValueMat):     sumValueMat=np.multiply(result,goodsValueMat)     return np.sum(sumValueMat)#neighborhood searchdef multiple_knapsack_neighbor(bags_set=[], goods_set=[]):    bagsWeightList=[bag.original_capacity  for bag in bags_set]    bagsWeightList=np.array(bagsWeightList)    goodsWeightMat=np.zeros(shape=(len(goods_set),len(bags_set)))    goodsValueMat=np.zeros(shape=(len(goods_set),len(bags_set)))    for i in range(len(goods_set)):         for j in range(len(bags_set)):             goodsWeightMat[i][j]=goods_set[i].weight    for i in range(len(goods_set)):         for j in range(len(bags_set)):             goodsValueMat[i][j]=goods_set[i].value                current_result,current_total_value = np.zeros(shape=(len(goods_set),len(bags_set))),0    iterateNum=1    isEnd=False    print(&quot;--------------------------------&quot;)    print(&quot;the initial total value is: &#123;&#125;&quot;.format(current_total_value))    print(&quot;the initial putting matrix is:&quot;)    print(current_result)    while not isEnd:       next_result,next_total_value  = np.zeros(shape=(len(goods_set),len(bags_set))),0       allZeroIndexList,haveOneIndexList=[],[]       if len(haveOneIndexList)==len(goods_set):             break       for i in range(len(goods_set)):            if np.sum(current_result[i:i+1,::],axis=1)[0]==0:                allZeroIndexList.append(i)            else:                haveOneIndexList.append(i)       if len(haveOneIndexList)==0:            #sameBlock1            for i in allZeroIndexList:                for j in range(len(bags_set)):                    mid_result=current_result.copy()                    mid_result[i][j]=1                    if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                        mid_total_value=calValue(mid_result,goodsValueMat)                        if mid_total_value&gt;next_total_value:                             next_result = mid_result                             next_total_value = mid_total_value                        break       elif len(haveOneIndexList)==1:            #sameBlock1            for i in allZeroIndexList:                for j in range(len(bags_set)):                    mid_result=current_result.copy()                    mid_result[i][j]=1                    if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                        mid_total_value=calValue(mid_result,goodsValueMat)                        if mid_total_value&gt;next_total_value:                             next_result = mid_result                             next_total_value = mid_total_value                        break            #sameBlock2                       for i in allZeroIndexList:                for j in haveOneIndexList:                    mid_result=current_result.copy()                    mid_result[j,::]=current_result[i,::]                    mid_result[i,::]=current_result[j,::]                    if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                         mid_total_value=calValue(mid_result,goodsValueMat)                        if mid_total_value&gt;next_total_value:                            next_result = mid_result                            next_total_value = mid_total_value       else:            #sameBlock1            for i in allZeroIndexList:                for j in range(len(bags_set)):                    mid_result=current_result.copy()                    mid_result[i][j]=1                    if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                        mid_total_value=calValue(mid_result,goodsValueMat)                        if mid_total_value&gt;next_total_value:                             next_result = mid_result                             next_total_value = mid_total_value                        break            #sameBlock2                        for i in allZeroIndexList:                for j in haveOneIndexList:                    mid_result=current_result.copy()                    mid_result[j,::]=current_result[i,::]                    mid_result[i,::]=current_result[j,::]                    if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                         mid_total_value=calValue(mid_result,goodsValueMat)                        if mid_total_value&gt;next_total_value:                            next_result = mid_result                            next_total_value = mid_total_value            #rotate                          for i in  range(len(haveOneIndexList)):                for j in range(i,len(haveOneIndexList)):                    index1=haveOneIndexList[i]                    index2=haveOneIndexList[j]                    for k in allZeroIndexList:                        for case in range(2):                            if(case==1):                                index1,index2=index2,index1                            mid_result=current_result.copy()                            mid_result[k,::]=current_result[index1,::]                            mid_result[index1,::]=current_result[index2,::]                            mid_result[index2,::]=current_result[k,::]                            if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                                 mid_total_value=calValue(mid_result,goodsValueMat)                                if mid_total_value&gt;next_total_value:                                     next_result = mid_result                                     next_total_value = mid_total_value       if next_total_value &gt; current_total_value:            current_total_value=next_total_value            current_result=next_result            print(&quot;--------------------------------&quot;)            print(&quot;iteration &#123;&#125;:&quot;.format(iterateNum))            print(&quot;the current total value is: &#123;&#125;&quot;.format(current_total_value))            print(&quot;the current putting matrix is:&quot;)            print(current_result)       else:            isEnd=True       iterateNum+=1    print(&quot;--------------------------------&quot;)    print(&quot;--------------------------------&quot;)    print(&quot;--------------------------------&quot;)    print(&quot;The final result is:&quot;)    print(&quot;the finial total value is: &#123;&#125;&quot;.format(current_total_value))    print(&quot;the finial puttting matrix is:&quot;)    print(current_result)    print()    for i in range(len(bags_set)):        print(&quot;bag&#123;&#125; contains:&quot;.format(i+1))        for j in range(len(goods_set)):            if current_result[j][i]==1:                print(&quot;  good&#123;&#125; has weight of &#123;&#125; and value of &#123;&#125;&quot;.format(j+1,goods_set[j].weight,goods_set[j].value))    return current_result,current_total_value\n\n禁忌搜索：\ndef check_tabu(tabu_list,mid_result):    if len(tabu_list)&lt;1:        return False    for i in range(len(tabu_list)):        if (tabu_list[i][0]==mid_result).all():            return True    return Falsedef multiple_knapsack_tabu(bags_set=[], goods_set=[],tabu_length=1):#tabu search    bagsWeightList=[bag.original_capacity  for bag in bags_set]    bagsWeightList=np.array(bagsWeightList)    goodsWeightMat=np.zeros(shape=(len(goods_set),len(bags_set)))    goodsValueMat=np.zeros(shape=(len(goods_set),len(bags_set)))    for i in range(len(goods_set)):         for j in range(len(bags_set)):             goodsWeightMat[i][j]=goods_set[i].weight    for i in range(len(goods_set)):         for j in range(len(bags_set)):             goodsValueMat[i][j]=goods_set[i].value                all_zero_result = np.zeros(shape=(len(goods_set),len(bags_set)))    current_result,current_total_value  = np.zeros(shape=(len(goods_set),len(bags_set))),0    best_result,best_total_value =current_result.copy(),current_total_value    iterateNum,isEnd,tabu_list=1,False,[]    if tabu_length&gt;=1:        tabu_list.append((current_result.copy(),current_total_value))    print(&quot;--------------------------------&quot;)    print(&quot;the initial total value is: &#123;&#125;&quot;.format(current_total_value))    print(&quot;the initial putting matrix is:&quot;)    print(current_result)    while not isEnd and iterateNum&lt;15:       next_result,next_total_value  = np.zeros(shape=(len(goods_set),len(bags_set))),0       allZeroIndexList,haveOneIndexList=[],[]       if len(haveOneIndexList)==len(goods_set):             break       for i in range(len(goods_set)):            if np.sum(current_result[i:i+1,::],axis=1)[0]==0:                allZeroIndexList.append(i)            else:                haveOneIndexList.append(i)       if len(haveOneIndexList)==0:            #sameBlock1            for i in allZeroIndexList:                for j in range(len(bags_set)):                    mid_result=current_result.copy()                    mid_result[i][j]=1                    if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                        mid_total_value=calValue(mid_result,goodsValueMat)                        if mid_total_value&gt;next_total_value and not check_tabu(tabu_list,mid_result):                             next_result = mid_result                             next_total_value = mid_total_value                        break       elif len(haveOneIndexList)==1:            #sameBlock1            for i in allZeroIndexList:                for j in range(len(bags_set)):                    mid_result=current_result.copy()                    mid_result[i][j]=1                    if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                        mid_total_value=calValue(mid_result,goodsValueMat)                        if mid_total_value&gt;next_total_value and not check_tabu(tabu_list,mid_result):                             next_result = mid_result                             next_total_value = mid_total_value                        break            #sameBlock2                        for i in allZeroIndexList:                for j in haveOneIndexList:                    mid_result=current_result.copy()                    mid_result[j,::]=current_result[i,::]                    mid_result[i,::]=current_result[j,::]                    if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                         mid_total_value=calValue(mid_result,goodsValueMat)                        if mid_total_value&gt;next_total_value and not check_tabu(tabu_list,mid_result):                            next_result = mid_result                            next_total_value = mid_total_value       else:            #sameBlock1            for i in allZeroIndexList:                for j in range(len(bags_set)):                    mid_result=current_result.copy()                    mid_result[i][j]=1                    if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                        mid_total_value=calValue(mid_result,goodsValueMat)                        if mid_total_value&gt;next_total_value and not check_tabu(tabu_list,mid_result):                             next_result = mid_result                             next_total_value = mid_total_value                        break            #sameBlock2                        for i in allZeroIndexList:                for j in haveOneIndexList:                    mid_result=current_result.copy()                    mid_result[j,::]=current_result[i,::]                    mid_result[i,::]=current_result[j,::]                    if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                         mid_total_value=calValue(mid_result,goodsValueMat)                        if mid_total_value&gt;next_total_value and not check_tabu(tabu_list,mid_result):                            next_result = mid_result                            next_total_value = mid_total_value            #rotate                        for i in  range(len(haveOneIndexList)):                for j in range(i,len(haveOneIndexList)):                    index1=haveOneIndexList[i]                    index2=haveOneIndexList[j]                    for k in allZeroIndexList:                        for case in range(2):                            if(case==1):                                index1,index2=index2,index1                            mid_result=current_result.copy()                            mid_result[k,::]=current_result[index1,::]                            mid_result[index1,::]=current_result[index2,::]                            mid_result[index2,::]=current_result[k,::]                            if judgeWeight(mid_result,bagsWeightList,goodsWeightMat):                                 mid_total_value=calValue(mid_result,goodsValueMat)                                if mid_total_value&gt;next_total_value and not check_tabu(tabu_list,mid_result):                                     next_result = mid_result                                     next_total_value = mid_total_value              if (next_result == all_zero_result).all():            isEnd = True       else:           if tabu_length&gt;=1:               if len(tabu_list)&gt;=tabu_length:                   tabu_list.remove(tabu_list[0])                   tabu_list.append((current_result,current_total_value))               else:                   tabu_list.append((current_result,current_total_value))           current_total_value=next_total_value           current_result=next_result                       if current_total_value&gt;best_total_value:                best_result=current_result.copy()                best_total_value=current_total_value           print(&quot;--------------------------------&quot;)           print(&quot;iteration &#123;&#125;:&quot;.format(iterateNum))           print(&quot;the current total value is: &#123;&#125;&quot;.format(current_total_value))           print(&quot;the current putting matrix is:&quot;)           print(current_result)           iterateNum+=1                print(&quot;--------------------------------&quot;)    print(&quot;--------------------------------&quot;)    print(&quot;--------------------------------&quot;)    print(&quot;The final result is:&quot;)    print(&quot;the finial total value is: &#123;&#125;&quot;.format(best_total_value))    print(&quot;the finial puttting matrix is:&quot;)    print(best_result)    print()    for i in range(len(bags_set)):        print(&quot;bag&#123;&#125; contains:&quot;.format(i+1))        for j in range(len(goods_set)):            if best_result[j][i]==1:                print(&quot;  good&#123;&#125; has weight of &#123;&#125; and value of &#123;&#125;&quot;.format(j+1,goods_set[j].weight,goods_set[j].value))    return best_result,best_total_value\n\n贪心搜索测试：\ngoods_set=[goods(4,3),goods(5,4),goods(6,5),goods(7,5),goods(1,2),goods(3,3)]bags_set=[bags(10),bags(2),bags(1),bags(6)]result,total_value=multiple_knapsack_greedy(bags_set,goods_set)\n\n贪心搜索测试结果：\nput good5 into bag3put good6 into bag4put good3 into bag1put good1 into bag1------------------------The final result is:the finial total value is: 13the finial puttting matrix is:[[1. 0. 0. 0.] [0. 0. 0. 0.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 1. 0.] [0. 0. 0. 1.]]bag1 contains:  good1 has weight of 4 and value of 3  good3 has weight of 6 and value of 5bag2 contains:bag3 contains:  good5 has weight of 1 and value of 2bag4 contains:  good6 has weight of 3 and value of 3The bags&#x27; total value is 13.\n\n邻居搜索测试：\ngoods_set=[goods(4,3),goods(5,4),goods(6,5),goods(7,5),goods(1,2),goods(3,3)]bags_set=[bags(10),bags(2),bags(1),bags(6)]result,total_value=multiple_knapsack_neighbor(bags_set,goods_set)\n\n邻居搜索测试结果：\n--------------------------------the initial total value is: 0the initial putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.]]--------------------------------iteration 1:the current total value is: 5.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 0.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.]]--------------------------------iteration 2:the current total value is: 9.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.]]--------------------------------iteration 3:the current total value is: 12.0the current putting matrix is:[[1. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.]]--------------------------------iteration 4:the current total value is: 14.0the current putting matrix is:[[1. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 1. 0. 0.] [0. 0. 0. 0.]]------------------------------------------------------------------------------------------------The final result is:the finial total value is: 14.0the finial puttting matrix is:[[1. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 1. 0. 0.] [0. 0. 0. 0.]]bag1 contains:  good1 has weight of 4 and value of 3  good3 has weight of 6 and value of 5bag2 contains:  good5 has weight of 1 and value of 2bag3 contains:bag4 contains:  good2 has weight of 5 and value of 4\n\n禁忌搜索测试：\ngoods_set=[goods(4,3),goods(5,4),goods(6,5),goods(7,5),goods(1,2),goods(3,3)]bags_set=[bags(10),bags(2),bags(1),bags(6)]result,total_value=multiple_knapsack_tabu(bags_set,goods_set,1)\n\n禁忌搜索测试结果：\n--------------------------------the initial total value is: 0the initial putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.]]--------------------------------iteration 1:the current total value is: 5.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 0.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.]]--------------------------------iteration 2:the current total value is: 9.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.]]--------------------------------iteration 3:the current total value is: 12.0the current putting matrix is:[[1. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.]]--------------------------------iteration 4:the current total value is: 14.0the current putting matrix is:[[1. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 1. 0. 0.] [0. 0. 0. 0.]]--------------------------------iteration 5:the current total value is: 14.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]--------------------------------iteration 6:the current total value is: 15.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]--------------------------------iteration 7:the current total value is: 14.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 1.] [0. 0. 0. 0.] [1. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]--------------------------------iteration 8:the current total value is: 14.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]--------------------------------iteration 9:the current total value is: 15.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]--------------------------------iteration 10:the current total value is: 14.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 1.] [0. 0. 0. 0.] [1. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]--------------------------------iteration 11:the current total value is: 14.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]--------------------------------iteration 12:the current total value is: 15.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]--------------------------------iteration 13:the current total value is: 14.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 1.] [0. 0. 0. 0.] [1. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]--------------------------------iteration 14:the current total value is: 14.0the current putting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]------------------------------------------------------------------------------------------------The final result is:the finial total value is: 15.0the finial puttting matrix is:[[0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 1.] [1. 0. 0. 0.] [0. 1. 0. 0.] [1. 0. 0. 0.]]bag1 contains:  good4 has weight of 7 and value of 5  good6 has weight of 3 and value of 3bag2 contains:  good5 has weight of 1 and value of 2bag3 contains:bag4 contains:  good3 has weight of 6 and value of 5\n\n4. 结论在这个实验中，我实现这三种算法解决了多背包问题。这三种算法都是贪心算法。他们都不能保证找到全局最优解。在这三种算法中，邻居搜索总是能够比贪心算法做得更好，因为邻居搜索尝试了更多的解决方案（其能否找到更好的解决方案很大程度上取决于起点的解决方案，其次是寻找邻居的方式）。而禁忌搜索是一种对于邻居搜索的改良并总是能找到全局最优解（虽然能否找到和tabu list的长度和最大迭代次数有关）。因为禁忌搜索不会陷入局部最优解并能够去寻找更多的解决方案。\n","categories":["算法"],"tags":["启发式算法","多背包问题"]},{"title":"内核编译、启动以及gdb内核调试环境构建","url":"/2022/05/31/%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E3%80%81%E5%90%AF%E5%8A%A8%E4%BB%A5%E5%8F%8Agdb%E5%86%85%E6%A0%B8%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E6%9E%84%E5%BB%BA/","content":"1. 相关软件包环境以及目录结构Qemu：QEMU emulator version 6.2.0 (Debian 1:6.2+dfsg-2ubuntu6)\nGDB：GNU gdb (Ubuntu 12.0.90-0ubuntu1) 12.0.90\n提示：在编译内核时可能需要安装其它软件包，根据提示安装即可\nmufiye_kernel(workspace)\t---- kernel-OLK-5.10(openEuler kernel source code)\t---- linux-kernel(linux kernel source code)\t---- rootfs(store image)\t\t---- base_img\t\t\t---- create_image.sh\t\t\t---- update-image.sh\t\t\t---- create-qcow2.sh\t\t---- 2.bullseye\t\t---- 3.bullseye3\n2. 编译内核\nlinux kernel git repo：本次编译使用的是该源码，版本为5.18-rc7\n\n应用该patch使debug更方便（直接使用git am或对照修改）\n\nconfig\n\n\n\n清理旧的编译生成的文件及其他配置等文件\nmake mrproper\n\n首先生成.config（运行make menuconfig后直接save）\nmake menuconfig\n\n根据该config修改.config文件\n\n一些关于gdb调试的内核CONFIG选项：\n需要注意的是CONFIG_DEBUG_INFO_DWARF_TOOLCHAIN_DEFAULT配置选项，5.12版本的linux内核新增了DEBUG_INFO_DWARF5配置选项，而5.18版本后DEBUG_INFO配置需要设置开启DEBUG_INFO_DWARF4和DEBUG_INFO_DWARF5中的一个。DWARF为调试信息格式，而DEBUG_INFO_DWARF4配置选项和DEBUG_INFO_DWARF5配置选项的区别是使用哪个版本的调试信息格式，v5版本拥有更优的数据压缩、更快的符号搜索能力以及其调试信息可以从可执行文件中分离出来，但是v5版本相比v4版本需要更高版本的工具链(gcc，gdb等)支持，因此我们设置DEBUG_INFO_DWARF_TOOLCHAIN_DEFAULT配置选项使其根据工具链决定使用的DWARF版本。\nCONFIG_KGDB=yCONFIG_DEBUG_BUGVERBOSE=yCONFIG_DEBUG_SECTION_MISMATCH=y  # 防止内联CONFIG_DEBUG_INFO=yCONFIG_DEBUG_INFO_DWARF_TOOLCHAIN_DEFAULT=y  # 新版本特性CONFIG_DEBUG_KERNEL=yCONFIG_FRAME_POINTER=y  # Makefile中选择GCC编译选项CONFIG_GDB_SCRIPTS=y  # gdb python# 关闭CONFIG_DEBUG_RODATA# 关闭CONFIG_DEBUG_INFO_REDUCED# 关闭CONFIG_RANDOMIZE_BASE\n\n\n进行编译，先编译内核镜像\nmake bzImage -j16\n\n编译模块\nmake modules -j16\n\n进行模块安装\n# INSTALL_MOD_PATH表示模块安装的位置make modules_install INSTALL_MOD_PATH=mod -j16\n\n3. 制作根文件系统该节主要讲述如何制作根文件系统。\n\n安装debootstrap\nsudo apt install debootstrap\n\n使用create-image.sh创建镜像，create-image.sh用于创建一个适合syzkaller的最小Debian镜像。由于create-image.sh脚本文件过长，我提炼出其中的核心语句列出并做了注释（适用于x86_64）。\nbash ./create-image.sh\n\n#!/usr/bin/env bash# 一些预安装的软件包PREINSTALL_PKGS=openssh-server,curl,tar,gcc，...# 默认的安装变量ARCH=x86_64DEBARCH=amd64RELEASE=bullseyeFEATURE=minimalSEEK=16383PERF=false# 略过了读取参数和一些相关设置，直接采用默认设置尽快进入主体代码# 安装目录DIR=chrootsudo rm -rf $DIRsudo mkdir -p $DIRsudo chmod 0755 $DIR# debootstrap将Debian基础系统安装到另一个已安装系统的子目录中  DEBOOTSTRAP_PARAMS=&quot;--arch=$DEBARCH --include=$PREINSTALL_PKGS -components=main,contrib,non-free $RELEASE $DIR&quot;sudo debootstrap $DEBOOTSTRAP_PARAMS https://repo.huaweicloud.com/debian/# 这堆echo用于设定debian系统的一些参数，tee用于重定向# 找到root对应的行并将密码设置为空，x表示密码，但是这里不显示sudo sed -i &#x27;/^root/ &#123; s/:x:/::/ &#125;&#x27; $DIR/etc/passwd# 内核初始化时会读取/etc/inittab文件，每个条目的格式为id:runlevels:action:process，其中id为条目编号，runlevels表示运行级别，action表示要执行的动作，process表示要执行的程序，respawn的意思就是当后面的要执行的程序终止了，init进程会自动重启该进程。该命令使系统启动getty并提供登录提示到终端。echo &#x27;T0:23:respawn:/sbin/getty -L ttyS0 115200 vt100&#x27; | sudo tee -a $DIR/etc/inittab# 设置网络printf &#x27;\\nauto eth0\\niface eth0 inet dhcp\\n&#x27; | sudo tee -a $DIR/etc/network/interfaces# 设置挂载信息echo &#x27;/dev/root / ext4 defaults 0 0&#x27; | sudo tee -a $DIR/etc/fstabecho &#x27;debugfs /sys/kernel/debug debugfs defaults 0 0&#x27; | sudo tee -a $DIR/etc/fstabecho &#x27;securityfs /sys/kernel/security securityfs defaults 0 0&#x27; | sudo tee -a $DIR/etc/fstabecho &#x27;configfs /sys/kernel/config/ configfs defaults 0 0&#x27; | sudo tee -a $DIR/etc/fstabecho &#x27;binfmt_misc /proc/sys/fs/binfmt_misc binfmt_misc defaults 0 0&#x27; | sudo tee -a $DIR/etc/fstab# 设置域名解析文件echo -en &quot;127.0.0.1\\tlocalhost\\n&quot; | sudo tee $DIR/etc/hosts# 设置域名解析服务器号echo &quot;nameserver 8.8.8.8&quot; | sudo tee -a $DIR/etc/resolve.conf# 设置主机名为syzkallerecho &quot;syzkaller&quot; | sudo tee $DIR/etc/hostname# 创建并设置ssh密钥ssh-keygen -f $RELEASE.id_rsa -t rsa -N &#x27;&#x27;sudo mkdir -p $DIR/root/.ssh/cat $RELEASE.id_rsa.pub | sudo tee $DIR/root/.ssh/authorized_keys# 为vim2m驱动程序管理的设备创建一个/dev/vim2m符号链接，与syzkaller有关echo &#x27;ATTR&#123;name&#125;==&quot;vim2m&quot;, SYMLINK+=&quot;vim2m&quot;&#x27; | sudo tee -a $DIR/etc/udev/rules.d/50-udev-default.rules# 创建虚拟化硬盘，块大小为1M，seek指定把块输出到文件时要跳过多少个块，count指定拷贝的块数，此时img中为空字符（因为/dev/zero）dd if=/dev/zero of=$RELEASE.img bs=1M seek=$SEEK count=1# 将镜像格式化为ext4文件系统sudo mkfs.ext4 -F $RELEASE.imgsudo mkdir -p /mnt/$DIR# 挂载环回设备，此时该img被挂载，就像普通设备一样sudo mount -o loop $RELEASE.img /mnt/$DIR# 将之前创建的系统的内容拷贝到img中sudo cp -a $DIR/. /mnt/$DIR/.# 取消挂载sudo umount /mnt/$DIR\n\n移除生成的一些无用文件（密钥文件）\nrm bullseye.id_rsa*\n\n将img文件转换为.qcow2文件\nqemu-img convert -p -f raw -O qcow2 bullseye.img bullseye.qcow2\n\n4. 安装并且配置qemu\n安装qemu\nsudo apt install qemu-system\n\n启动qemu前的准备（可以先直接到第3步试一试，不行再做这里的尝试）\n# 安装一些网络相关的包：sudo apt-get install qemu-kvm virt-manager bridge-utils\n# 修改/etc/qemu/bridge.confmkdir -p /etc/qemu #如果没有qemu文件夹sudo vim /etc/qemu/bridge.conf #第一行加入 allow virbr0\n# 对/etc/ssh/sshd_config修改以下内容:PermitRootLogin yes #允许root用户登录PasswordAuthentication yes #开启密码认证PermitEmptyPasswords yes #允许密码为空\n\n# 非root用户没有权限的解决办法# 不同qemu可能qemu-bridge-helper位置不一样sudo find / -name qemu-bridge-helper # 先用这个命令确定文件的位置sudo chown root /usr/lib/qemu/qemu-bridge-helper # 将该文件的所有者改为rootsudo chmod u+s /usr/lib/qemu/qemu-bridge-helper # setuid位为1表示设置使文件在执行阶段具有文件所有者的权限，该命令设置setuid位为1，setuid位占用属主执行位\n\n运行update_image.sh来启动qemu\n# kernel version表示的是内核源码的目录kernel_version=linux-kernel# -enable-kvm表示允许启用KVM,linux内核和硬件必须支持KVM并且加载kvm内核模块# -smp设置虚拟机的cpu数量，这里设置为16# -m表示设置虚拟机内存大小，这里设置为2G# -kernel指向启动qemu的内核镜像# -virtfs用于创建共享目录（虚拟机与物理机之间）# -nographic表示禁用图形输出并将串行I/O重定向到控制台，vga用于选择显卡类型# -append设置Linux内核命令行、启动参数，“console=ttyS0”表示把QEMU的输入输出定向到当前终端上，“root”指示根文件系统，&quot;nokaslr&quot;表示关闭KASRL，KASRL使内核地址空间布局随机化，这会让gdb难以调试# -device为设备设置驱动程序属性，-drive指定和标识该设备。如在该虚拟机启动项中，virtio-blk表示了驱动属性；用于此驱动设备的磁盘映像的路径为bullseye.qcow2，其文件格式为qcow2；缓存方式使用回写，也就是调用write写入数据时只将数据写入到磁盘缓存中，当数据被换出缓存时才写入到后端存储中；id为root，-device drive使连接到该id为root的设备。# -net nic创建一个网卡，并设置mac地址# -net bridge创建一个网桥qemu-system-x86_64 \\-enable-kvm \\-smp 16 \\-m 2G \\-kernel /home/mufiye/mufiye_kernel/$&#123;kernel_version&#125;/arch/x86/boot/bzImage \\-virtfs local,id=kmod_dev,path=/home/mufiye/mufiye_kernel/$&#123;kernel_version&#125;/mod,readonly,mount_tag=9p,security_model=none \\-vga none \\-nographic \\-append &quot;nokaslr console=ttyS0 root=/dev/vda rw kmemleak=on&quot; \\-device virtio-scsi-pci \\-drive file=bullseye.qcow2,if=none,format=qcow2,cache=writeback,file.locking=off,id=root \\-device virtio-blk,drive=root,id=d_root \\-net nic,model=virtio,macaddr=00:11:22:33:44:55 \\-net bridge,br=virbr0 \\\n\n5. 创建根文件系统的拷贝\n首先进入rootfs文件夹，之后创建base_img并且将其它脚本文件移入到base_img文件夹。\ncd ./rootfsmkdir base_imgmv * ./base_img\n\n创建两个新的文件夹用于装载新的镜像\nmkdir 2.bullseyemkdir 3.bullseye\n\n启动create-qcow2.sh创建两个新的镜像并生成对应镜像的启动脚本start.sh（下面的代码块对脚本内容进行了提炼）\nbash create-qcow2.sh\n\n# create-qcow2.sharray=(2 3)image_type=bullseyedst_path=$(pwd)/../for element in $&#123;array[@]&#125;do\t# 创建新的qcow2文件，相当于做了拷贝\tqemu-img create -F qcow2 -b $(pwd)/$&#123;image_type&#125;.qcow2 -f qcow2  \\ \t                  \t\t\t\t\t$&#123;dst_path&#125;$&#123;element&#125;.$&#123;image_type&#125;/image.qcow2\t\t# 复制启动虚拟机的文件并做了一些修改\tcp update-image.sh $&#123;dst_path&#125;/$&#123;element&#125;.$&#123;image_type&#125;/start.sh\t\t# 修改mac地址\tformat_num=$(printf &quot;%02d\\n&quot; $&#123;element&#125;)\tsed -i &quot;s/00:11:22:33:44:55/00:11:22:33:44:$&#123;format_num&#125;/g&quot; \\      \t\t\t\t                      $&#123;dst_path&#125;/$&#123;element&#125;.$&#123;image_type&#125;/start.sh\t# 修改-drive file后跟的虚拟磁盘参数\tsed -i &quot;s/$&#123;image_type&#125;.qcow2/image.qcow2/g&quot; \\                                                        $&#123;dst_path&#125;/$&#123;element&#125;.$&#123;image_type&#125;/start.sh\t# 启动虚拟机时使其挂载两份额外的文件(放到之后介绍)\t...\t# 启动用于gdb调试的端口\tgdb_port=`expr 5550 + $element`\techo &quot;-gdb tcp::$&#123;gdb_port&#125; \\\\&quot; &gt;&gt; $&#123;dst_path&#125;/$&#123;element&#125;.$&#123;image_type&#125;/start.shdone\n\n进入到2.bullseye文件夹和3.bullseye文件夹并且为文件预分配空间\nfallocate -l 5G 1fallocate -l 5G nvme\n\n运行start.sh文件启动qemu虚拟机\nbash start.sh\n关于新的设备以及驱动设置\n# -drive和-device参数在上面的update_image.sh已经进行了介绍# 相当于新创建的虚拟机连接有两个新的设备，分别是scsi协议的硬盘和nvme协议的硬盘，设备的磁盘映像分别为之前分配的1文件和nvme文件-drive file=1,if=none,format=raw,cache=writeback,file.locking=off,id=dd_1 \\-device scsi-hd,drive=dd_1,id=disk_1 \\-drive file=nvme,if=none,format=raw,cache=writeback,file.locking=off,id=b_nvme_1 \\-device nvme,drive=b_nvme_1,serial=d_b_nvme_1 \\\n\n6. gdb调试环境配置6.1 配置gdb辅助调试功能方法一\n向该文件~&#x2F;.gdbinit输入内容\necho &quot;source /home/mufiye/.gdb-linux/vmlinux-gdb.py&quot; &gt; ~/.gdbinit\n\n创建文件夹\nmkdir ~/.gdb-linux/\n\n在linux源码文件夹中运行make命令\nmake scripts_gdb\n\n复制文件到gdb-linux目录下\ncp -r scripts/gdb/* ~/.gdb-linux/\n\n向该文件输入内容\n# 输入的内容：sys.path.insert(0, &quot;/home/mufiye/.gdb-linux&quot;)vim ~/.gdb-linux/vmlinux-gdb.py\n\n验证GDB辅助调试功能是否配置成功，用gdb vmlinux启动gdb后输入下面命令会有相关的提示\n(gdb) apropos lx\n\n方法二\n向该文件~&#x2F;.gdbinit输入内容\necho &quot;add-auto-load-safe-path /home/mufiye/mufiye_kernel/linux-kernel/scripts/gdb/vmlinux-gdb.py&quot; &gt; ~/.gdbinit\n\n在linux源码文件夹中运行make命令\nmake scripts_gdb\n\n6.2 启动gdb调试\ngdb调试启动（在物理机上启动，之后远程连接虚拟机）\ngdb vmlinux\n\ngdb远程连接qemu虚拟机（5552为端口号，这与启动qemu虚拟机时的设置有关）\ntarget remote:5552\n\n之后就可以使用gdb进行调试了\n\n\n6.3 gdb调试遇到的问题以及成功截图问题1第一个问题是不管何时都无法插入断点，无法读取内存内容，插入断点后函数内容为??()。该问题在gdb界面的错误提示为cannot insert breakpoint，cannot access memory adresss，我是在用break命令插入断点执行continue时遇到的该错误提示，同时插入断点时函数内容为??()。遇到该问题首先要考虑是否配置对了内核配置选项（见上面内核编译config配置），之后看看是否在用qemu启动内核时加入了nokaslr选项。\n问题2第二个问题是在内核启动前无法插入断点，无法读取内存内容。在这种情况下，插入断点函数内容不为??()，在内核启动后插入断点一切正常，但是在内核启动前插入断点并continue，仍然出现cannot insert breakpoint，cannot access memory adresss的错误提示。此时我尝试使用hbreak，我发现使用hbreak不会发生错误并能够正常断点。\n关于hbreak和break的区别，我查阅资料得知：break设置的是软件断点，由非法指令异常实现（软件实现），其中断的程序位于内存中；hbreak设置的是硬件端点，由硬件特性实现，其中断的程序位于只读寄存器中。当代码位于只读寄存器时，只能通过硬件断点调试。所以我猜测是内核启动过程中，start_kernel这段程序被加载到只读寄存器中，因此只能通过hbreak进行断点。\ngdb配置成功截图\n\ngdb调试，成功断点start_kernel函数\n\n\n参考\nhttps://github.com/chenxiaosonggithub/blog\n《Linux内核设计与实现》\nhttps://www.kernel.org/doc/htmldocs/kgdb/CompilingAKernel.html\nqemu官方文档\nGetting started with qemu\nDebugging kernel and modules via gdb\nGDB官方文档\nQEMU+gdb调试Linux内核全过程\nlinux kernel调试环境\nlinux内存子系统 - qemu调试linux 内核启动\nhttps://sourceware.org/legacy-ml/gdb/2016-08/msg00014.html\n关于linux内核kgdb调试\n关于hbreak和break\n\n","categories":["操作系统内核"],"tags":["gdb","环境搭建","内核编译","qemu"]},{"title":"链路追踪常见协议实现","url":"/2024/09/20/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E5%B8%B8%E8%A7%81%E5%8D%8F%E8%AE%AE%E5%AE%9E%E7%8E%B0/","content":"1. Skywalking1.1 SegmentSegment是一批span的集合，它表示一个线程上下文，如果跨线程则需要重新记录为一个segment；跨进程可以表示发起了一个跨线程调用，更多地情况（也是链路追踪最大的意义）是表示了两个服务之间的调用。\n\ntraceId：一条调用链路的唯一id，用其串联起一条链路\ntraceSegmentId：一个segment的id\nspans：该segment上下文中所有的span\nservice：表示该segment所在的服务\nserviceInstance：表示该segment所在的服务实例（在kubernetes中对应一个pod，服务基本都是多实例部署的）\nisSizeLimited：是否有一些span因为过大被丢弃了\n\nmessage SegmentObject &#123;    string traceId = 1;    string traceSegmentId = 2;    repeated SpanObject spans = 3;    string service = 4;    string serviceInstance = 5;    bool isSizeLimited = 6;&#125;\n\n1.2 Spanspan是segment下层的概念，它的含义是一个更细粒度的方法调用\n\nspanId：该span的id，从0开始，在一个segment中保证唯一\n\nparentSpanId：该span在这个segment中的父亲span的id，如果是-1表示没有父亲span，则该span是根span\n\nstartTime：开始时间\n\nendTime：结束时间，开始时间和结束时间可以得到耗时信息\n\nrefs：如果发生了跨线程&#x2F;进程，记录上个segment的信息；如果是MQ或者批量操作的情况下，会有多个ref\n\noperationName：span的操作名称\n\npeer：如果是exit span，记录要调用的接口或http请求\n\nspanType：\n\nentry span：一个segment的头部span\nlocal span：一个segment本地操作的span\nexit span：一个segment的尾部span，标志一个跨线程调用的发起\n\n\nspanLayer：span所在的服务的类型，rpc，db，cache等\n\ncomponentId：预定义的id，根据埋点的组件决定，比如spring等\n\nisError：该span是否错误\n\ntags：键值对，给span打标签\n\nlogs：记录该span中发生的事件，记录键值对和时间\n\nskipAnalysis：是否跳过分析\n\n\nmessage SpanObject &#123;    int32 spanId = 1;    int32 parentSpanId = 2;    int64 startTime = 3;    int64 endTime = 4;    repeated SegmentReference refs = 5;    string operationName = 6;    string peer = 7;    SpanType spanType = 8;    SpanLayer spanLayer = 9;    int32 componentId = 10;    bool isError = 11;    repeated KeyStringValuePair tags = 12;    repeated Log logs = 13;    bool skipAnalysis = 14;&#125;\n\n1.2.1 SpanType// Map to the type of spanenum SpanType &#123;    // Server side of RPC. Consumer side of MQ.    Entry = 0;    // Client side of RPC. Producer side of MQ.    Exit = 1;    // A common local code execution.    Local = 2;&#125;\n\n1.2.2 SpanLayer// Map to the layer of spanenum SpanLayer &#123;    // Unknown layer. Could be anything.    Unknown = 0;    // A database layer, used in tracing the database client component.    Database = 1;    // A RPC layer, used in both client and server sides of RPC component.    RPCFramework = 2;    // HTTP is a more specific RPCFramework.    Http = 3;    // A MQ layer, used in both producer and consuer sides of the MQ component.    MQ = 4;    // A cache layer, used in tracing the cache client component.    Cache = 5;    // A FAAS layer, used in function-as-a-Service platform.    FAAS = 6;&#125;\n\n1.2.3 Logmessage Log &#123;    // The timestamp in milliseconds of this event.,    // measured between the current time and midnight, January 1, 1970 UTC.    int64 time = 1;    // String key, String value pair.    repeated KeyStringValuePair data = 2;&#125;\n\n1.3 Segment Referencesegment reference用于连接两个segment，把他们串起来。使用segment reference可以根据服务侧的entry span方便地生成拓扑，具体拓扑生成的方式可以看wusheng的这篇STAM分析方法。\n\nrefType：父亲segment到儿子segment的调用关系，是跨进程还是跨线程\ntraceId：父亲segment的trace id\nparentTraceSegmentId：父亲segment的segment id\nparentSpanId：父亲segment的exit span id\nparentService：父亲segment的服务名称\nparentServiceInstance：父亲segment的服务实例\nparentEndpoint：父亲segment的enpoint信息，如果父亲服务是http服务，那么就是一个父亲服务的url；如果父亲服务是rpc服务，那么就是它的服务名+接口。这个也对应父亲segment的entry span的operation name。\nnetworkAddressUsedAtPeer：客户端调用服务端，服务端的网络地址；这个等同于exit span的peer\n\nmessage SegmentReference &#123;    RefType refType = 1;    string traceId = 2;    string parentTraceSegmentId = 3;    int32 parentSpanId = 4;    string parentService = 5;    string parentServiceInstance = 6;    string parentEndpoint = 7;    string networkAddressUsedAtPeer = 8;&#125;\n\n2. OpenTelemetry其实总的来说链路追踪的协议设计上都比较接近，但是opentelemetry没有直接的segment的概念\n2.1  一批trace数据的集合message TracesData &#123;  repeated ResourceSpans resource_spans = 1;&#125;\n\n2.2 对应一条trace的概念// A collection of ScopeSpans from a Resource.message ResourceSpans &#123;  reserved 1000;  // The resource for the spans in this message.  // If this field is not set then no resource info is known.  opentelemetry.proto.resource.v1.Resource resource = 1;  // A list of ScopeSpans that originate from a resource.  repeated ScopeSpans scope_spans = 2;  // The Schema URL, if known. This is the identifier of the Schema that the resource data  // is recorded in. To learn more about Schema URL see  // https://opentelemetry.io/docs/specs/otel/schemas/#schema-url  // This schema_url applies to the data in the &quot;resource&quot; field. It does not apply  // to the data in the &quot;scope_spans&quot; field which have their own schema_url field.  string schema_url = 3;&#125;\n\n2.3 对应一个segment// A collection of Spans produced by an InstrumentationScope.message ScopeSpans &#123;  // The instrumentation scope information for the spans in this message.  // Semantically when InstrumentationScope isn&#x27;t set, it is equivalent with  // an empty instrumentation scope name (unknown).  opentelemetry.proto.common.v1.InstrumentationScope scope = 1;  // A list of Spans that originate from an instrumentation scope.  repeated Span spans = 2;  // The Schema URL, if known. This is the identifier of the Schema that the span data  // is recorded in. To learn more about Schema URL see  // https://opentelemetry.io/docs/specs/otel/schemas/#schema-url  // This schema_url applies to all spans and span events in the &quot;spans&quot; field.  string schema_url = 3;&#125;\n\n2.4 基本单元，Span\ntrace_id\nspan_id\ntrace_state：它用于在分布式跟踪的环境中传递有关当前 Trace 的数据，可以是键值对的形式组成string\nparent_span_id\nflags：标识位表示该span是否是远程调用\nname\nkind：span的类型，不过使用了server、client、internal、producer、consumer和unspecified\nstart_time_unix_nano\nend_time_unix_nano\nattributes：属性键值对，对当前span打了标签\ndropped_attributes_count\nevents：更细粒度的事件\ndropped_events_count\nlinks：用于将span进行串联\ndropped_links_count\nstatus：span的状态\n\n// A Span represents a single operation performed by a single component of the system.//// The next available field id is 17.message Span &#123;  // A unique identifier for a trace. All spans from the same trace share  // the same `trace_id`. The ID is a 16-byte array. An ID with all zeroes OR  // of length other than 16 bytes is considered invalid (empty string in OTLP/JSON  // is zero-length and thus is also invalid).  //  // This field is required.  bytes trace_id = 1;  // A unique identifier for a span within a trace, assigned when the span  // is created. The ID is an 8-byte array. An ID with all zeroes OR of length  // other than 8 bytes is considered invalid (empty string in OTLP/JSON  // is zero-length and thus is also invalid).  //  // This field is required.  bytes span_id = 2;  // trace_state conveys information about request position in multiple distributed tracing graphs.  // It is a trace_state in w3c-trace-context format: https://www.w3.org/TR/trace-context/#tracestate-header  // See also https://github.com/w3c/distributed-tracing for more details about this field.  string trace_state = 3;  // The `span_id` of this span&#x27;s parent span. If this is a root span, then this  // field must be empty. The ID is an 8-byte array.  bytes parent_span_id = 4;  // Flags, a bit field.  //  // Bits 0-7 (8 least significant bits) are the trace flags as defined in W3C Trace  // Context specification. To read the 8-bit W3C trace flag, use  // `flags &amp; SPAN_FLAGS_TRACE_FLAGS_MASK`.  //  // See https://www.w3.org/TR/trace-context-2/#trace-flags for the flag definitions.  //  // Bits 8 and 9 represent the 3 states of whether a span&#x27;s parent  // is remote. The states are (unknown, is not remote, is remote).  // To read whether the value is known, use `(flags &amp; SPAN_FLAGS_CONTEXT_HAS_IS_REMOTE_MASK) != 0`.  // To read whether the span is remote, use `(flags &amp; SPAN_FLAGS_CONTEXT_IS_REMOTE_MASK) != 0`.  //  // When creating span messages, if the message is logically forwarded from another source  // with an equivalent flags fields (i.e., usually another OTLP span message), the field SHOULD  // be copied as-is. If creating from a source that does not have an equivalent flags field  // (such as a runtime representation of an OpenTelemetry span), the high 22 bits MUST  // be set to zero.  // Readers MUST NOT assume that bits 10-31 (22 most significant bits) will be zero.  //  // [Optional].  fixed32 flags = 16;  // A description of the span&#x27;s operation.  //  // For example, the name can be a qualified method name or a file name  // and a line number where the operation is called. A best practice is to use  // the same display name at the same call point in an application.  // This makes it easier to correlate spans in different traces.  //  // This field is semantically required to be set to non-empty string.  // Empty value is equivalent to an unknown span name.  //  // This field is required.  string name = 5;  // Distinguishes between spans generated in a particular context. For example,  // two spans with the same name may be distinguished using `CLIENT` (caller)  // and `SERVER` (callee) to identify queueing latency associated with the span.  SpanKind kind = 6;  // start_time_unix_nano is the start time of the span. On the client side, this is the time  // kept by the local machine where the span execution starts. On the server side, this  // is the time when the server&#x27;s application handler starts running.  // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.  //  // This field is semantically required and it is expected that end_time &gt;= start_time.  fixed64 start_time_unix_nano = 7;  // end_time_unix_nano is the end time of the span. On the client side, this is the time  // kept by the local machine where the span execution ends. On the server side, this  // is the time when the server application handler stops running.  // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.  //  // This field is semantically required and it is expected that end_time &gt;= start_time.  fixed64 end_time_unix_nano = 8;  // attributes is a collection of key/value pairs. Note, global attributes  // like server name can be set using the resource API. Examples of attributes:  //  //     &quot;/http/user_agent&quot;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&quot;  //     &quot;/http/server_latency&quot;: 300  //     &quot;example.com/myattribute&quot;: true  //     &quot;example.com/score&quot;: 10.239  //  // The OpenTelemetry API specification further restricts the allowed value types:  // https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/common/README.md#attribute  // Attribute keys MUST be unique (it is not allowed to have more than one  // attribute with the same key).  repeated opentelemetry.proto.common.v1.KeyValue attributes = 9;  // dropped_attributes_count is the number of attributes that were discarded. Attributes  // can be discarded because their keys are too long or because there are too many  // attributes. If this value is 0, then no attributes were dropped.  uint32 dropped_attributes_count = 10;    // events is a collection of Event items.  repeated Event events = 11;  // dropped_events_count is the number of dropped events. If the value is 0, then no  // events were dropped.  uint32 dropped_events_count = 12;      // links is a collection of Links, which are references from this span to a span  // in the same or different trace.  repeated Link links = 13;  // dropped_links_count is the number of dropped links after the maximum size was  // enforced. If this value is 0, then no links were dropped.  uint32 dropped_links_count = 14;  // An optional final status for this span. Semantically when Status isn&#x27;t set, it means  // span&#x27;s status code is unset, i.e. assume STATUS_CODE_UNSET (code = 0).  Status status = 15;&#125;\n\n2.4.1 SpanKind表示span的类型，不同于skywalking中的entry span、local span和exit span，其使用internal对应了local span，使用server、client表示了调用关系的entry span和exit span，但是其特别标识了不明确类型的span，以及区分出了消费者和生产者的span，对应于MQ的场景。\n// SpanKind is the type of span. Can be used to specify additional relationships between spans// in addition to a parent/child relationship.enum SpanKind &#123;  // Unspecified. Do NOT use as default.  // Implementations MAY assume SpanKind to be INTERNAL when receiving UNSPECIFIED.  SPAN_KIND_UNSPECIFIED = 0;  // Indicates that the span represents an internal operation within an application,  // as opposed to an operation happening at the boundaries. Default value.  SPAN_KIND_INTERNAL = 1;  // Indicates that the span covers server-side handling of an RPC or other  // remote network request.  SPAN_KIND_SERVER = 2;  // Indicates that the span describes a request to some remote service.  SPAN_KIND_CLIENT = 3;  // Indicates that the span describes a producer sending a message to a broker.  // Unlike CLIENT and SERVER, there is often no direct critical path latency relationship  // between producer and consumer spans. A PRODUCER span ends when the message was accepted  // by the broker while the logical processing of the message might span a much longer time.  SPAN_KIND_PRODUCER = 4;  // Indicates that the span describes consumer receiving a message from a broker.  // Like the PRODUCER kind, there is often no direct critical path latency relationship  // between producer and consumer spans.  SPAN_KIND_CONSUMER = 5;&#125;\n\n2.4.2 Event是对更细粒度的操作的记录，比如一个Rpc操作可以用Event记录调用下游的ip、zone是什么，以及操作类型等\n// Event is a time-stamped annotation of the span, consisting of user-supplied// text description and key-value pairs.message Event &#123;  // time_unix_nano is the time the event occurred.  fixed64 time_unix_nano = 1;  // name of the event.  // This field is semantically required to be set to non-empty string.  string name = 2;  // attributes is a collection of attribute key/value pairs on the event.  // Attribute keys MUST be unique (it is not allowed to have more than one  // attribute with the same key).  repeated opentelemetry.proto.common.v1.KeyValue attributes = 3;  // dropped_attributes_count is the number of dropped attributes. If the value is 0,  // then no attributes were dropped.  uint32 dropped_attributes_count = 4;&#125;\n\n2.4.3 Link相当于skywalking中segment reference的概念，可以将服务等信息存在键值对结构的attributes中，表示了span之间的调用、串联关系\n// A pointer from the current span to another span in the same trace or in a// different trace. For example, this can be used in batching operations,// where a single batch handler processes multiple requests from different// traces or when the handler receives a request from a different project.message Link &#123;  // A unique identifier of a trace that this linked span is part of. The ID is a  // 16-byte array.  bytes trace_id = 1;  // A unique identifier for the linked span. The ID is an 8-byte array.  bytes span_id = 2;  // The trace_state associated with the link.  string trace_state = 3;  repeated opentelemetry.proto.common.v1.KeyValue attributes = 4;  uint32 dropped_attributes_count = 5;  fixed32 flags = 6;&#125;\n\n2.4.4 Status用于表示Span的状态，skywalking中直接用isError表示为是否是错误的\nmessage Status &#123;  reserved 1;  // A developer-facing human readable error message.  string message = 2;  // For the semantics of status codes see  // https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/api.md#set-status  enum StatusCode &#123;    // The default status.    STATUS_CODE_UNSET               = 0;    // The Span has been validated by an Application developer or Operator to     // have completed successfully.    STATUS_CODE_OK                  = 1;    // The Span contains an error.    STATUS_CODE_ERROR               = 2;  &#125;;  // The status code.  StatusCode code = 3;&#125;\n\n2.4.5 Span Flag标识位表示该span是否是远程调用\nenum SpanFlags &#123;  // The zero value for the enum. Should not be used for comparisons.  // Instead use bitwise &quot;and&quot; with the appropriate mask as shown above.  SPAN_FLAGS_DO_NOT_USE = 0;  // Bits 0-7 are used for trace flags.  SPAN_FLAGS_TRACE_FLAGS_MASK = 0x000000FF;  // Bits 8 and 9 are used to indicate that the parent span or link span is remote.  // Bit 8 (`HAS_IS_REMOTE`) indicates whether the value is known.  // Bit 9 (`IS_REMOTE`) indicates whether the span or link is remote.  SPAN_FLAGS_CONTEXT_HAS_IS_REMOTE_MASK = 0x00000100;  SPAN_FLAGS_CONTEXT_IS_REMOTE_MASK = 0x00000200;  // Bits 10-31 are reserved for future use.&#125;\n\n3. Xray","categories":["可观测"],"tags":["skywalking","链路追踪","协议","opentelemetry"]},{"title":"CAT源码解析","url":"/2024/09/22/CAT%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","content":"CAT是大众点评开源的监控项目，这是它的整体架构图，接下来我将从CAT Client、CAT Consumer两部分做源码解析，帮助你了解CAT的原理。\n\n一、CAT ClientCAT使用API的形式进行埋点，暴露给外部的方法都在CAT这个类中。其中核心的方法都列在下面，主要是：\n\nCat.newTransaction：标识一个事件，关心该事件的耗时信息，或者希望展示嵌套的调用消息树\nCat.logError：标识一个错误，通常与log.error一起使用，本质上也是一个event\nCat.logEvent：标识一个事件\n\npublic class Cat &#123;    private static Cat CAT = new Cat();    public static Transaction newTransaction(String type, String name) &#123;        try &#123;            return TraceContextHelper.threadLocal().newTransaction(type, name);        &#125; catch (Exception e) &#123;            errorHandler(e);            return NullMessage.TRANSACTION;        &#125;    &#125;    public static void logError(Throwable cause) &#123;        logError(null, cause);    &#125;    public static void logError(String message, Throwable cause) &#123;        try &#123;            Event event = TraceContextHelper.threadLocal().newEvent(message, cause);            event.complete();        &#125; catch (Exception e) &#123;            errorHandler(e);        &#125;    &#125;    public static void logEvent(String type, String name, String status, String nameValuePairs) &#123;        try &#123;            Event event = TraceContextHelper.threadLocal().newEvent(type, name);            event.addData(nameValuePairs);            event.setStatus(status);            event.complete();        &#125; catch (Exception e) &#123;            errorHandler(e);        &#125;    &#125;&#125;\n这三个方法本质上都是创建了一种message，newTransaction对应transaction这种类型的message，logError和logEvent对应event这种类型的message。transaction与event相比，transaction会记录耗时信息，同时其可以嵌套transaction或者event构成一棵消息树。\nMessage接口和AbstractMessage抽象类，通用属性包括m_type（类型）、m_name（名称）、m_completed（是否结束）、m_timestampInMillis（耗时）、m_data（数据）；通用方法包括对于数据的读写。\npublic interface Message &#123;    /**\t * add one key-value pair to the message.\t * \t * @param key\t * @param value\t */    public void addData(String key, Object value);    /**\t * Complete the message construction.\t */    public void complete();    /**\t * Set the message status.\t * \t * @param status\t *           message status. &quot;0&quot; means success, otherwise error code.\t */    public void setStatus(String status);    // 只展示了部分方法，还有get方法以及兼容参数的set方法&#125;\npublic abstract class AbstractMessage implements Message &#123;\tprivate String m_type;\tprivate String m_name;\tprotected String m_status = &quot;unset&quot;;\tprivate long m_timestampInMillis;\tprivate CharSequence m_data;\tprivate boolean m_completed;\tpublic AbstractMessage(String type, String name) &#123;\t\tm_type = String.valueOf(type);\t\tm_name = String.valueOf(name);\t\tm_timestampInMillis = MilliSecondTimer.currentTimeMillis();\t&#125;\t@Override\tpublic void addData(String keyValuePairs) &#123;\t\tif (m_data == null) &#123;\t\t\tm_data = keyValuePairs;\t\t&#125; else if (m_data instanceof StringBuilder) &#123;\t\t\t((StringBuilder) m_data).append(&#x27;&amp;&#x27;).append(keyValuePairs);\t\t&#125; else &#123;\t\t\tStringBuilder sb = new StringBuilder(m_data.length() + keyValuePairs.length() + 16);\t\t\tsb.append(m_data).append(&#x27;&amp;&#x27;);\t\t\tsb.append(keyValuePairs);\t\t\tm_data = sb;\t\t&#125;\t&#125;\t@Override\tpublic void addData(String key, Object value) &#123;\t\tif (m_data instanceof StringBuilder) &#123;\t\t\t((StringBuilder) m_data).append(&#x27;&amp;&#x27;).append(key).append(&#x27;=&#x27;).append(value);\t\t&#125; else &#123;\t\t\tString str = String.valueOf(value);\t\t\tint old = m_data == null ? 0 : m_data.length();\t\t\tStringBuilder sb = new StringBuilder(old + key.length() + str.length() + 16);\t\t\tif (m_data != null) &#123;\t\t\t\tsb.append(m_data).append(&#x27;&amp;&#x27;);\t\t\t&#125;\t\t\tsb.append(key).append(&#x27;=&#x27;).append(str);\t\t\tm_data = sb;\t\t&#125;\t&#125;\t@Override\tpublic CharSequence getData() &#123;\t\tif (m_data == null) &#123;\t\t\treturn &quot;&quot;;\t\t&#125; else &#123;\t\t\treturn m_data;\t\t&#125;\t&#125;\t@Override\tpublic String getName() &#123;\t\treturn m_name;\t&#125;\t@Override\tpublic String getStatus() &#123;\t\treturn m_status;\t&#125;\t@Override\tpublic long getTimestamp() &#123;\t\treturn m_timestampInMillis;\t&#125;\t@Override\tpublic String getType() &#123;\t\treturn m_type;\t&#125;\t@Override\tpublic boolean isCompleted() &#123;\t\treturn m_completed;\t&#125;\t@Override\tpublic boolean isSuccess() &#123;\t\treturn Message.SUCCESS.equals(m_status);\t&#125;\tpublic void setCompleted() &#123;\t\tm_completed = true;\t&#125;\tprotected void setData(CharSequence data) &#123;\t\tm_data = data;\t&#125;\tpublic void setName(String name) &#123;\t\tm_name = name;\t&#125;\t@Override\tpublic void setStatus(String status) &#123;\t\tm_status = status;\t&#125;\t@Override\tpublic void setStatus(Throwable e) &#123;\t\tif (this instanceof Transaction) &#123;\t\t\tCat.logError(e);\t\t&#125;\t\tm_status = e.getClass().getName();\t&#125;\tpublic void setTimestamp(long timestamp) &#123;\t\tm_timestampInMillis = timestamp;\t&#125;\tpublic void setType(String type) &#123;\t\tm_type = type;\t&#125;\t@Override\tpublic Message success() &#123;\t\tm_status = SUCCESS;\t\treturn this;\t&#125;\t@Override\tpublic String toString() &#123;\t\tByteBuf buf = PooledByteBufAllocator.DEFAULT.buffer(10 * 1024); // 10K\t\tnew PlainTextMessageTreeEncoder().encodeMessage(this, buf);\t\treturn buf.toString(Charset.forName(&quot;utf-8&quot;));\t&#125;&#125;\nnewTransaction方法newTransaction的处理逻辑包括了主要的客户端message处理链路，因此分析其来熟悉CAT Client的处理逻辑。\npublic class Cat &#123;    public static Transaction newTransaction(String type, String name) &#123;        try &#123;            return TraceContextHelper.threadLocal().newTransaction(type, name);        &#125; catch (Exception e) &#123;            errorHandler(e);            return NullMessage.TRANSACTION;        &#125;    &#125;&#125;\n使用Threadlocal记录一个线程中的cat message上下文，cat的message线程之间隔离（除了可以通过forkTransaction进行message的复制传递）。\npublic class TraceContextHelper &#123;    private static ThreadLocal&lt;TraceContext&gt; s_threadLocalContext = new ThreadLocal&lt;TraceContext&gt;();    public static TraceContext threadLocal() &#123;        initialize();        TraceContext ctx = s_threadLocalContext.get();        if (ctx == null) &#123;            ctx = new DefaultTraceContext(s_pipeline, s_factory);            s_threadLocalContext.set(ctx);        &#125;        return ctx;    &#125;&#125;\nTraceContext接口中包含了对于message的基本操作\npublic interface TraceContext &#123;    void add(Message message);    void end(Transaction transaction);    MessageTree getMessageTree();        boolean hasPeekTransaction();        Transaction newTransaction(String type, String name);    Transaction peekTransaction();    void start(Transaction transaction);&#125;\nDefaultTransaction是Transaction的默认实现类：\n\n初始化：记录开始时间，同时调用context的start方法\naddChild()：如果是子Transaction或者是Event，作为子节点添加到父Transaction中\ncomplete()：表示当前Transaction已经结束，记录结束时间并将子节点也设置为结束，同时调用context的end方法\n\npublic class DefaultTransaction extends AbstractMessage implements Transaction &#123;    public DefaultTransaction(TraceContext ctx, String type, String name) &#123;        super(type, name);        m_ctx = ctx;        m_durationInMicros = System.nanoTime() / 1000L;        m_ctx.start(this);    &#125;    @Override    public DefaultTransaction addChild(Message message) &#123;        if (m_children == null) &#123;            m_children = new ArrayList&lt;Message&gt;();        &#125;        if (message != null) &#123;            m_children.add(message);        &#125; else &#123;            Cat.logError(new Exception(&quot;Null child message.&quot;));        &#125;        return this;    &#125;    @Override    public void complete() &#123;        if (m_durationInMicros &gt; 1e9) &#123; // duration is not set            long end = System.nanoTime();            m_durationInMicros = end / 1000L - m_durationInMicros;        &#125;        super.setCompleted();        if (m_children != null) &#123;            List&lt;Message&gt; children = new ArrayList&lt;Message&gt;(m_children);            for (Message child : children) &#123;                if (!child.isCompleted() &amp;&amp; child instanceof ForkableTransaction) &#123;                    child.complete();                &#125;            &#125;        &#125;        m_ctx.end(this);    &#125;&#125;\nDefaultTraceContext是核心的代码逻辑，其使用m_tree记录当前的根节点消息，使用m_stack记录消息之间的层级关系：\n\nstart()：如果当前没有消息，则将m_tree设置为当前要开始的这条消息，并将该消息入栈；如果有消息，则将当前要开始的这条消息加入到根节点消息的子节点，也将该消息入栈\nend()：不断将消息弹出栈，直到匹配到当前要结束的消息，保证要结束消息的子节点也全部结束了，之后对于这条要结束的消息，其与其嵌套的子消息构成了一棵消息树，对这棵消息树进行处理（上报）\n\npublic class DefaultTraceContext implements TraceContext &#123;\tprivate MessagePipeline m_pipeline;\tprivate DefaultMessageTree m_tree;\tprivate Stack&lt;Transaction&gt; m_stack = new Stack&lt;Transaction&gt;();\tprivate Set&lt;Integer&gt; m_exceptions = new HashSet&lt;Integer&gt;();        @Override    public Transaction newTransaction(String type, String name) &#123;        return new DefaultTransaction(this, type, name);    &#125;    private void deliver(DefaultMessageTree tree) &#123;        m_pipeline.headContext(tree).fireMessage(tree);        tree.reset();    &#125;    @Override    public void end(Transaction transaction) &#123;        Transaction child = m_stack.pop();        // in case of child transactions are not completed explicitly        while (transaction != child &amp;&amp; !m_stack.isEmpty()) &#123;            Transaction parent = m_stack.pop();            child = parent;        &#125;        if (m_stack.isEmpty()) &#123;            deliver(m_tree);        &#125;    &#125;    @Override    public Transaction peekTransaction() &#123;        if (m_stack.isEmpty()) &#123;            throw new RuntimeException(&quot;Stack is empty!&quot;);        &#125; else &#123;            return m_stack.peek();        &#125;    &#125;    @Override    public void start(Transaction transaction) &#123;        if (m_stack.isEmpty()) &#123;            m_tree.setMessage(transaction);        &#125; else &#123;            m_stack.peek().addChild(transaction);        &#125;        m_stack.push(transaction);    &#125;&#125;\nmessage的上报上报逻辑是对于采样到的数据会被放到一个本地内存的队列中，定时读取该队列使用netty进行上报。\n@Sharablepublic class MessageTransporter extends ChannelInboundHandlerAdapter implements Initializable, LogEnabled, Task &#123;    private ByteBufQueue m_queue;    private List&lt;Channel&gt; m_channels = new CopyOnWriteArrayList&lt;&gt;();    private ByteBuf m_buf;    private AtomicBoolean m_enabled = new AtomicBoolean(true);    private CountDownLatch m_latch = new CountDownLatch(1);    @Override    public void channelActive(ChannelHandlerContext ctx) throws Exception &#123;        Channel channel = ctx.channel();        m_channels.add(channel);        m_logger.info(&quot;Connected to CAT server %s, %s&quot;, channel.remoteAddress(), channel);        super.channelActive(ctx);    &#125;    @Override    public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123;        Channel channel = ctx.channel();        m_channels.remove(channel);        m_logger.info(&quot;Disconnected from CAT server %s, %s&quot;, channel.remoteAddress(), channel);        super.channelInactive(ctx);    &#125;    @Override    public void initialize(ComponentContext ctx) &#123;        m_queue = ctx.lookup(ByteBufQueue.class);    &#125;    private ByteBuf next() throws InterruptedException &#123;        if (m_buf == null) &#123;            m_buf = m_queue.poll();        &#125;        return m_buf;    &#125;    @Override    public void run() &#123;        try &#123;            while (m_enabled.get()) &#123;                ByteBuf buf = next();                if (buf != null) &#123;                    boolean success = write(buf);                    if (success) &#123;                        m_buf = null;                        continue;                    &#125;                &#125;                TimeUnit.MILLISECONDS.sleep(5);            &#125;            // if shutdown in progress            if (!m_enabled.get()) &#123;                ByteBuf buf = next();                while (buf != null) &#123;                    boolean success = write(buf);                    if (success) &#123;                        buf = next();                    &#125; else &#123;                        break;                    &#125;                &#125;            &#125;        &#125; catch (InterruptedException e) &#123;            // ignore it        &#125; finally &#123;            m_latch.countDown();        &#125;    &#125;    @Override    public void shutdown() &#123;        m_enabled.set(false);        try &#123;            m_latch.await();        &#125; catch (InterruptedException e) &#123;            // ignore it        &#125;    &#125;    private boolean write(ByteBuf tree) &#123;        if (!m_channels.isEmpty()) &#123;            Channel channel = m_channels.get(0);            if (channel.isActive() &amp;&amp; channel.isWritable()) &#123;                channel.writeAndFlush(tree);                return true;            &#125;        &#125;        return false;    &#125;&#125;\npublic class DefaultByteBufQueue implements ByteBufQueue, Initializable &#123;\tprivate BlockingQueue&lt;ByteBuf&gt; m_queue;\t@Override\tpublic boolean offer(ByteBuf buf) &#123;\t\treturn m_queue.offer(buf);\t&#125;\t@Override\tpublic ByteBuf poll() &#123;\t\ttry &#123;\t\t\treturn m_queue.poll(5, TimeUnit.MILLISECONDS);\t\t&#125; catch (InterruptedException e) &#123;\t\t\treturn null;\t\t&#125;\t&#125;\t@Override\tpublic void initialize(ComponentContext ctx) &#123;\t\tConfigureManager configureManager = ctx.lookup(ConfigureManager.class);\t\tint size = configureManager.getIntProperty(ConfigureProperty.SENDER_MESSAGE_QUEUE_SIZE, 5000);\t\tm_queue = new ArrayBlockingQueue&lt;ByteBuf&gt;(size);\t&#125;&#125;\npublic class MessageConveyer extends MessageHandlerAdaptor implements Initializable &#123;\tpublic static String ID = &quot;message-conveyer&quot;;\t// Inject\tprivate ByteBufQueue m_queue;\t// Inject\tprivate MessageStatistics m_statistics;\t@Override\tpublic int getOrder() &#123;\t\treturn 400;\t&#125;\t@Override\tpublic void handleMessage(MessageHandlerContext ctx, Object msg) &#123;\t\tif (msg instanceof ByteBuf) &#123;\t\t\tByteBuf buf = (ByteBuf) msg;\t\t\tm_statistics.onBytes(buf.readableBytes());\t\t\tif (!m_queue.offer(buf)) &#123;\t\t\t\tm_statistics.onOverflowed();\t\t\t&#125;\t\t&#125; else &#123;\t\t\tctx.fireMessage(msg);\t\t&#125;\t&#125;\t@Override\tpublic void initialize(ComponentContext ctx) &#123;\t\tm_queue = ctx.lookup(ByteBufQueue.class);\t\tm_statistics = ctx.lookup(MessageStatistics.class);\t&#125;&#125;\nmessage id的生成对于一颗message tree（消息树）其有一个唯一的消息id，该message id由 服务名+ip地址+小时时间戳+序列号构成。\npublic class MessageIdFactory implements Initializable &#123;    public static final long HOUR = 3600 * 1000L;    // ...        public String getNextId(String domain) &#123;        if (m_initialized.get()) &#123;            Builder builder = findOrCreateBuilder(domain);            if (builder != null) &#123;                return builder.buildNextId();            &#125; else &#123;                return &quot;&quot;;            &#125;        &#125; else &#123;            throw new IllegalStateException(&quot;Please call MessageIdFactory.initialize(String) first!&quot;);        &#125;    &#125;    class Builder &#123;        private String m_domain;        private AtomicLong m_lastHour = new AtomicLong();        private AtomicInteger m_batchStart;        private AtomicInteger m_batchOffset;        private RandomAccessFile m_markFile;        private MappedByteBuffer m_byteBuffer;        public Builder(String domain) &#123;            File file = new File(m_baseDir, domain + &quot;.mark&quot;);            m_domain = domain;            m_batchStart = new AtomicInteger();            m_batchOffset = new AtomicInteger();            try &#123;                m_markFile = new RandomAccessFile(file, &quot;rw&quot;);                m_byteBuffer = m_markFile.getChannel().map(MapMode.READ_WRITE, 0, 20);            &#125; catch (Throwable e) &#123;                throw new IllegalStateException(String.format(&quot;Unable to access mark file(%s)!&quot;, file), e);            &#125;        &#125;        public String buildNextId() &#123;            StringBuilder sb = new StringBuilder(m_domain.length() + 32);            long hour = getHour();            sb.append(m_domain);            sb.append(&#x27;-&#x27;);            sb.append(getIpAddress());            sb.append(&#x27;-&#x27;);            sb.append(hour);            sb.append(&#x27;-&#x27;);            sb.append(getIndex(hour));            return sb.toString();        &#125;        private synchronized int getIndex(long hour) &#123;            int offset = m_batchOffset.incrementAndGet();            if (m_lastHour.get() != hour || offset &gt;= getBatchSize()) &#123;                FileLock lock = null;                try &#123;                    // lock could be null in case of CAT is stopping in progress                    lock = lock();                    int limit = m_byteBuffer.limit();                    long lastHour = limit &gt;= 12 ? m_byteBuffer.getLong(4) : 0;                    if (lastHour == hour) &#123; // same hour                        int start = limit &gt;= 4 ? m_byteBuffer.getInt(0) : 0;                        m_batchStart.set(start);                    &#125; else &#123;                        m_batchStart.set(0);                    &#125;                    offset = 0;                    m_lastHour.set(hour);                    m_batchOffset.set(0);                    m_byteBuffer.putInt(0, m_batchStart.get() + getBatchSize());                    m_byteBuffer.putLong(4, hour);                    if (lock != null) &#123;                        m_markFile.getChannel().force(false);                    &#125;                &#125; catch (InterruptedException e) &#123;                    // ignore it                &#125; catch (Throwable e) &#123;                    e.printStackTrace();                &#125; finally &#123;                    if (lock != null) &#123;                        try &#123;                            lock.release();                        &#125; catch (Exception e) &#123;                            // ignore it                        &#125;                    &#125;                &#125;            &#125;            return m_batchStart.get() + offset;        &#125;    &#125;&#125;\n\n\n二、CAT ConsumerCAT Consumer采集、处理、存储CAT Client上报的数据。\n对于收到的消息，CAT Consumer对于这些消息做分时间段处理，对于同一个时间段的消息统一处理，比如对于同一个小时、同一天的数据，其会启动一个小时&#x2F;天Period，在startPeriod和endPeriod时执行特定的逻辑，比如对于小时period，在结束时生成一个小时报表。每一个Period下会生成无数个Period task，period task会对应一种message analyzer，对特定消息进行处理。\npublic class PeriodManager implements Task &#123;    public static long EXTRATIME = 3 * 60 * 1000L;    private PeriodStrategy m_strategy;    private List&lt;Period&gt; m_periods = new ArrayList&lt;Period&gt;();    private boolean m_active;    @Inject    private MessageAnalyzerManager m_analyzerManager;    @Inject    private ServerStatisticManager m_serverStateManager;    @Inject    private Logger m_logger;    public PeriodManager(long duration, MessageAnalyzerManager analyzerManager,\tServerStatisticManager serverStateManager,                         Logger logger) &#123;        m_strategy = new PeriodStrategy(duration, EXTRATIME, EXTRATIME);        m_active = true;        m_analyzerManager = analyzerManager;        m_serverStateManager = serverStateManager;        m_logger = logger;    &#125;    private void endPeriod(long startTime) &#123;        int len = m_periods.size();        for (int i = 0; i &lt; len; i++) &#123;            Period period = m_periods.get(i);            if (period.isIn(startTime)) &#123;                period.finish();                m_periods.remove(i);                break;            &#125;        &#125;    &#125;    public Period findPeriod(long timestamp) &#123;        for (Period period : m_periods) &#123;            if (period.isIn(timestamp)) &#123;                return period;            &#125;        &#125;        return null;    &#125;    @Override    public String getName() &#123;        return &quot;RealtimeConsumer-PeriodManager&quot;;    &#125;    public void init() &#123;        long startTime = m_strategy.next(System.currentTimeMillis());        startPeriod(startTime);    &#125;    @Override    public void run() &#123;        while (m_active) &#123;            try &#123;                long now = System.currentTimeMillis();                long value = m_strategy.next(now);                if (value &gt; 0) &#123;                    startPeriod(value);                &#125; else if (value &lt; 0) &#123;                    // last period is over,make it asynchronous                    Threads.forGroup(&quot;cat&quot;).start(new EndTaskThread(-value));                &#125;            &#125; catch (Throwable e) &#123;                Cat.logError(e);            &#125;            try &#123;                Thread.sleep(1000L);            &#125; catch (InterruptedException e) &#123;                break;            &#125;        &#125;    &#125;    @Override    public void shutdown() &#123;        m_active = false;    &#125;    private void startPeriod(long startTime) &#123;        long endTime = startTime + m_strategy.getDuration();        Period period = new Period(startTime, endTime, m_analyzerManager, m_serverStateManager, m_logger);        m_periods.add(period);        period.start();    &#125;    private class EndTaskThread implements Task &#123;        private long m_startTime;        public EndTaskThread(long startTime) &#123;            m_startTime = startTime;        &#125;        @Override        public String getName() &#123;            return &quot;End-Consumer-Task&quot;;        &#125;        @Override        public void run() &#123;            endPeriod(m_startTime);        &#125;        @Override        public void shutdown() &#123;        &#125;    &#125;&#125;\n\npublic class Period &#123;    private static final int QUEUE_SIZE = 30000;    private long m_startTime;    private long m_endTime;    private Map&lt;String, List&lt;PeriodTask&gt;&gt; m_tasks;    @Inject    private MessageAnalyzerManager m_analyzerManager;    @Inject    private ServerStatisticManager m_serverStateManager;    @Inject    private Logger m_logger;    public Period(long startTime, long endTime, MessageAnalyzerManager analyzerManager,                  ServerStatisticManager serverStateManager, Logger logger) &#123;        m_startTime = startTime;        m_endTime = endTime;        m_analyzerManager = analyzerManager;        m_serverStateManager = serverStateManager;        m_logger = logger;        List&lt;String&gt; names = m_analyzerManager.getAnalyzerNames();        m_tasks = new HashMap&lt;String, List&lt;PeriodTask&gt;&gt;();        for (String name : names) &#123;            List&lt;MessageAnalyzer&gt; messageAnalyzers = m_analyzerManager.getAnalyzer(name, startTime);            for (MessageAnalyzer analyzer : messageAnalyzers) &#123;                MessageQueue queue = new DefaultMessageQueue(QUEUE_SIZE);                PeriodTask task = new PeriodTask(analyzer, queue, startTime);                task.enableLogging(m_logger);                List&lt;PeriodTask&gt; analyzerTasks = m_tasks.get(name);                if (analyzerTasks == null) &#123;                    analyzerTasks = new ArrayList&lt;PeriodTask&gt;();                    m_tasks.put(name, analyzerTasks);                &#125;                analyzerTasks.add(task);            &#125;        &#125;    &#125;    public void distribute(MessageTree tree) &#123;        m_serverStateManager.addMessageTotal(tree.getDomain(), 1);        boolean success = true;        String domain = tree.getDomain();        for (Entry&lt;String, List&lt;PeriodTask&gt;&gt; entry : m_tasks.entrySet()) &#123;            List&lt;PeriodTask&gt; tasks = entry.getValue();            int length = tasks.size();            int index = 0;            boolean manyTasks = length &gt; 1;            if (manyTasks) &#123;                index = Math.abs(domain.hashCode()) % length;            &#125;            PeriodTask task = tasks.get(index);            boolean enqueue = task.enqueue(tree);            if (!enqueue) &#123;                if (manyTasks) &#123;                    task = tasks.get((index + 1) % length);                    enqueue = task.enqueue(tree);                    if (!enqueue) &#123;                        success = false;                    &#125;                &#125; else &#123;                    success = false;                &#125;            &#125;        &#125;        if ((!success) &amp;&amp; (!tree.isProcessLoss())) &#123;            m_serverStateManager.addMessageTotalLoss(tree.getDomain(), 1);            tree.setProcessLoss(true);        &#125;    &#125;    public void finish() &#123;        SimpleDateFormat df = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);        Date startDate = new Date(m_startTime);        Date endDate = new Date(m_endTime - 1);        m_logger.info(String.format(&quot;Finishing %s tasks in period [%s, %s]&quot;, m_tasks.size(), df.format(startDate),\tdf.format(endDate)));        try &#123;            for (Entry&lt;String, List&lt;PeriodTask&gt;&gt; tasks : m_tasks.entrySet()) &#123;                for (PeriodTask task : tasks.getValue()) &#123;                    task.finish();                &#125;            &#125;        &#125; catch (Throwable e) &#123;            Cat.logError(e);        &#125; finally &#123;            m_logger.info(String.format(&quot;Finished %s tasks in period [%s, %s]&quot;, m_tasks.size(), df.format(startDate),\tdf.format(endDate)));        &#125;    &#125;    public List&lt;MessageAnalyzer&gt; getAnalyzer(String name) &#123;        List&lt;MessageAnalyzer&gt; analyzers = new ArrayList&lt;MessageAnalyzer&gt;();        List&lt;PeriodTask&gt; tasks = m_tasks.get(name);        if (tasks != null) &#123;            for (PeriodTask task : tasks) &#123;                analyzers.add(task.getAnalyzer());            &#125;        &#125;        return analyzers;    &#125;    public List&lt;MessageAnalyzer&gt; getAnalyzers() &#123;        List&lt;MessageAnalyzer&gt; analyzers = new ArrayList&lt;MessageAnalyzer&gt;(m_tasks.size());        for (Entry&lt;String, List&lt;PeriodTask&gt;&gt; tasks : m_tasks.entrySet()) &#123;            for (PeriodTask task : tasks.getValue()) &#123;                analyzers.add(task.getAnalyzer());            &#125;        &#125;        return analyzers;    &#125;    public long getStartTime() &#123;        return m_startTime;    &#125;    public boolean isIn(long timestamp) &#123;        return timestamp &gt;= m_startTime &amp;&amp; timestamp &lt; m_endTime;    &#125;    public void start() &#123;        SimpleDateFormat df = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);        m_logger.info(String.format(&quot;Starting %s tasks in period [%s, %s]&quot;, m_tasks.size(),\tdf.format(new Date(m_startTime)),                                    df.format(new Date(m_endTime - 1))));        for (Entry&lt;String, List&lt;PeriodTask&gt;&gt; tasks : m_tasks.entrySet()) &#123;            List&lt;PeriodTask&gt; taskList = tasks.getValue();            for (int i = 0; i &lt; taskList.size(); i++) &#123;                PeriodTask task = taskList.get(i);                task.setIndex(i);                Threads.forGroup(&quot;Cat-RealtimeConsumer&quot;).start(task);            &#125;        &#125;    &#125;&#125;\n\npublic class PeriodTask implements Task, LogEnabled &#123;    private MessageAnalyzer m_analyzer;    private MessageQueue m_queue;    private long m_startTime;    private int m_queueOverflow;    private Logger m_logger;    private int m_index;    public PeriodTask(MessageAnalyzer analyzer, MessageQueue queue, long startTime) &#123;        m_analyzer = analyzer;        m_queue = queue;        m_startTime = startTime;    &#125;    public void setIndex(int index) &#123;        m_index = index;    &#125;    @Override    public void enableLogging(Logger logger) &#123;        m_logger = logger;    &#125;    public boolean enqueue(MessageTree tree) &#123;        if (m_analyzer.isEligable(tree)) &#123;            boolean result = m_queue.offer(tree);            if (!result) &#123; // trace queue overflow                m_queueOverflow++;                if (m_queueOverflow % (10 * CatConstants.ERROR_COUNT) == 0) &#123;                    String date = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm&quot;).format(new Date(m_analyzer.getStartTime()));                    m_logger                    .warn(m_analyzer.getClass()                          .getSimpleName() + &quot; queue overflow number &quot; + m_queueOverflow + &quot; analyzer time:&quot;                          + date);                &#125;            &#125;            return result;        &#125; else &#123;            return true;        &#125;    &#125;    public void finish() &#123;        try &#123;            m_analyzer.doCheckpoint(true);            m_analyzer.destroy();        &#125; catch (Exception e) &#123;            Cat.logError(e);        &#125;    &#125;    public MessageAnalyzer getAnalyzer() &#123;        return m_analyzer;    &#125;    @Override    public String getName() &#123;        Calendar cal = Calendar.getInstance();        cal.setTimeInMillis(m_startTime);        return m_analyzer.getClass().getSimpleName() + &quot;-&quot; + cal.get(Calendar.HOUR_OF_DAY) + &quot;-&quot; + m_index;    &#125;    @Override    public void run() &#123;        try &#123;            m_analyzer.analyze(m_queue);        &#125; catch (Exception e) &#123;            Cat.logError(e);        &#125;    &#125;    @Override    public void shutdown() &#123;        if (m_analyzer instanceof AbstractMessageAnalyzer) &#123;            ((AbstractMessageAnalyzer&lt;?&gt;) m_analyzer).shutdown();        &#125;    &#125;&#125;\n\nMessageAnalyzer接口有针对多种消息分析器的实现，比如Transaction、Event、Problem（错误的Event、Transaction，长耗时的特定类型Transaction）、Logview（原始的消息树数据）、Dependency（服务拓扑关系）等等。\npublic interface MessageAnalyzer &#123;\tpublic boolean isEligable(MessageTree tree);\tpublic void analyze(MessageQueue queue);\tpublic void destroy();\tpublic void doCheckpoint(boolean atEnd);\tpublic long getStartTime();\tpublic void initialize(long startTime, long duration, long extraTime);\tpublic int getAnanlyzerCount(String name);\tpublic void setIndex(int index);\tpublic ReportManager&lt;?&gt; getReportManager();&#125;\nTransaction AnalyzerTransaction报表分为四个维度，分别是domain（服务名）、machine（ip地址）、type、name，在这四个维度上计算聚合后的指标数据。\npublic class TransactionReport extends BaseEntity&lt;TransactionReport&gt; &#123;    private String m_domain;    private java.util.Date m_startTime;    private java.util.Date m_endTime;    private Set&lt;String&gt; m_domainNames = new LinkedHashSet&lt;String&gt;();    private Map&lt;String, Machine&gt; m_machines = new ConcurrentHashMap&lt;String, Machine&gt;();&#125;\npublic class Machine extends BaseEntity&lt;Machine&gt; &#123;   private String m_ip;   private Map&lt;String, TransactionType&gt; m_types = new ConcurrentHashMap&lt;String, TransactionType&gt;();&#125;\npublic class TransactionType extends BaseEntity&lt;TransactionType&gt; &#123;    private String m_id;    private long m_totalCount;    private long m_failCount;    private double m_failPercent;    private double m_min = 86400000d;    private double m_max = -1d;    private double m_avg;    private double m_sum;    private double m_sum2;    private double m_std;    private String m_successMessageUrl;    private String m_failMessageUrl;    private Map&lt;String, TransactionName&gt; m_names = new ConcurrentHashMap&lt;String, TransactionName&gt;();    private double m_tps;    private double m_line95Value;    private double m_line99Value;    private double m_line999Value;    private double m_line90Value;    private Map&lt;Integer, Graph2&gt; m_graph2s = new ConcurrentHashMap&lt;Integer, Graph2&gt;();    private transient Map&lt;Integer, AllDuration&gt; m_allDurations = new ConcurrentHashMap&lt;Integer, AllDuration&gt;();    private GraphTrend m_graphTrend;    private Map&lt;Integer, Range2&gt; m_range2s = new ConcurrentHashMap&lt;Integer, Range2&gt;();    private double m_line50Value;    private double m_line9999Value;    private String m_longestMessageUrl;    private Map&lt;String, String&gt; m_dynamicAttributes = new LinkedHashMap&lt;String, String&gt;();&#125;\npublic class TransactionName extends BaseEntity&lt;TransactionName&gt; &#123;    // 属性与TransactionType类似&#125;\npublic class TransactionAnalyzer extends AbstractMessageAnalyzer&lt;TransactionReport&gt; implements LogEnabled &#123;    @Inject(ID)    private ReportManager&lt;TransactionReport&gt; m_reportManager;    @Override    public void process(MessageTree tree) &#123;        String domain = tree.getDomain();        TransactionReport report = m_reportManager.getHourlyReport(getStartTime(), domain, true);        List&lt;Transaction&gt; transactions = tree.findOrCreateTransactions();        for (Transaction t : transactions) &#123;            String data = String.valueOf(t.getData());            if (data.length() &gt; 0 &amp;&amp; data.charAt(0) == CatConstants.BATCH_FLAG) &#123;                processBatchTransaction(tree, report, t, data);            &#125; else &#123;                processTransaction(report, tree, t);            &#125;        &#125;        if (System.currentTimeMillis() &gt; m_nextClearTime) &#123;            m_nextClearTime = m_nextClearTime + TimeHelper.ONE_MINUTE;            Threads.forGroup(&quot;cat&quot;).start(new Runnable() &#123;                @Override                public void run() &#123;                    cleanUpReports();                &#125;            &#125;);        &#125;    &#125;    private void processBatchTransaction(MessageTree tree, TransactionReport report, Transaction t, String data) &#123;        String[] tabs = data.substring(1).split(CatConstants.SPLIT);        int total = Integer.parseInt(tabs[0]);        int fail = Integer.parseInt(tabs[1]);        long sum = Long.parseLong(tabs[2]);        String type = t.getType();        String name = t.getName();        String ip = tree.getIpAddress();        TransactionType transactionType = findOrCreateType(report.findOrCreateMachine(ip), type);        TransactionName transactionName = findOrCreateName(transactionType, name, report.getDomain());        DurationMeta durations = computeBatchDuration(t, tabs, transactionType, transactionName, report.getDomain());        processTypeAndName(tree, t, transactionType, transactionName, total, fail, sum, durations);    &#125;    private void processTransaction(TransactionReport report, MessageTree tree, Transaction t) &#123;        String type = t.getType();        String name = t.getName();        if (!m_filterConfigManager.discardTransaction(type, name)) &#123;            boolean valid = checkForTruncatedMessage(tree, t);            if (valid) &#123;                String ip = tree.getIpAddress();                TransactionType transactionType = findOrCreateType(report.findOrCreateMachine(ip), type);                TransactionName transactionName = findOrCreateName(transactionType, name, report.getDomain());                processTypeAndName(t, transactionType, transactionName, tree, t.getDurationInMillis());            &#125;        &#125;    &#125;    private void processTypeAndName(Transaction t, TransactionType type, TransactionName name, MessageTree tree,                                    double duration) &#123;        String messageId = tree.getMessageId();        type.incTotalCount();        name.incTotalCount();        type.setSuccessMessageUrl(messageId);        name.setSuccessMessageUrl(messageId);        if (!t.isSuccess()) &#123;            type.incFailCount();            name.incFailCount();            String statusCode = formatStatus(t.getStatus());            findOrCreateStatusCode(name, statusCode).incCount();        &#125;        int allDuration = computeDuration((int) duration);        double sum = duration * duration;        if (type.getMax() &lt;= duration) &#123;            type.setLongestMessageUrl(messageId);        &#125;        if (name.getMax() &lt;= duration) &#123;            name.setLongestMessageUrl(messageId);        &#125;        name.setMax(Math.max(name.getMax(), duration));        name.setMin(Math.min(name.getMin(), duration));        name.setSum(name.getSum() + duration);        name.setSum2(name.getSum2() + sum);        name.findOrCreateAllDuration(allDuration).incCount();        type.setMax(Math.max(type.getMax(), duration));        type.setMin(Math.min(type.getMin(), duration));        type.setSum(type.getSum() + duration);        type.setSum2(type.getSum2() + sum);        type.findOrCreateAllDuration(allDuration).incCount();        long current = t.getTimestamp() / 1000 / 60;        int min = (int) (current % (60));        boolean statistic = m_statisticManager.shouldStatistic(type.getId(), tree.getDomain());        processNameGraph(t, name, min, duration, statistic, allDuration);        processTypeRange(t, type, min, duration, statistic, allDuration);    &#125;&#125;\nDump Analyzerdump analyzer对于上报的message tree会判断是否需要丢弃，如果不需要丢弃将其放到队列中，对于该队列会有定期线程对于message tree执行批量写入逻辑。\npublic class DumpAnalyzer extends AbstractMessageAnalyzer&lt;Object&gt; implements LogEnabled &#123;    @Override    public void process(MessageTree tree) &#123;        try &#123;            MessageId messageId = MessageId.parse(tree.getMessageId());            if (!shouldDiscard(messageId)) &#123;                processWithStorage(tree, messageId, messageId.getHour());            &#125;        &#125; catch (Exception ignored) &#123;        &#125;    &#125;    private void processWithStorage(MessageTree tree, MessageId messageId, int hour) &#123;        MessageDumper dumper = m_dumperManager.find(hour);        tree.setFormatMessageId(messageId);        if (dumper != null) &#123;            dumper.process(tree);        &#125; else &#123;            m_serverStateManager.addPigeonTimeError(1);        &#125;    &#125;&#125;\n\npublic interface MessageDumper &#123;\tpublic void awaitTermination(int hour) throws InterruptedException;\tpublic void initialize(int hour);\tpublic void process(MessageTree tree);&#125;\npublic class DefaultMessageDumper extends ContainerHolder implements MessageDumper, LogEnabled &#123;    @Override    public void process(MessageTree tree) &#123;        MessageId id = tree.getFormatMessageId();        String domain = id.getDomain();        // hash by ip address and block hash by domain        // int index = getIndex(id.getDomain());        int index = getIndex(id.getIpAddressInHex());        BlockingQueue&lt;MessageTree&gt; queue = m_queues.get(index);        boolean success = queue.offer(tree);        if (!success) &#123;            m_statisticManager.addMessageDumpLoss(1);            if ((m_failCount.incrementAndGet() % 100) == 0) &#123;                Cat.logError(new MessageQueueFullException(&quot;Error when adding message to queue, fails: &quot; + m_failCount));                m_logger.info(&quot;message tree queue is full &quot; + m_failCount + &quot; index &quot; + index);                // tree.getBuffer().release();            &#125;        &#125; else &#123;            m_statisticManager.addMessageSize(domain, tree.getBuffer().readableBytes());            if ((++m_total) % CatConstants.SUCCESS_COUNT == 0) &#123;                m_statisticManager.addMessageDump(CatConstants.SUCCESS_COUNT);            &#125;        &#125;    &#125;&#125;\n\nReference\nCAT源码仓库\n深度剖析开源分布式监控CAT\n\n","categories":["可观测"],"tags":["CAT","源码"]}]